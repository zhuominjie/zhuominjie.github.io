<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Nginx:安装和常用命令]]></title>
    <url>%2Fposts%2F8747ea0e%2F</url>
    <content type="text"><![CDATA[下载安装包从官网下载nginx压缩包，官网地址：https://nginx.org/en/download.html。最好选择稳定版本。 安装假设下载的安装包位于/root/用户根目录下。 1、解压文件tar -zxvf nginx-1.15.2.tar.gz 2、自定义nginx安装位置 #创建文件夹cd /usr/localmkdir nginx-1.15.2#回到解压文件夹cd /root/nginx-1.15.2指定安装路径./configure --prefix=/usr/local/nginx-1.15.2编译安装makemake install 常用命令先进入到nginx的安装路径，可以看到目录结构如下： drwx------ 2 root root 6 7月 30 19:05 client_body_tempdrwxr-xr-x 2 root root 4096 7月 30 19:16 confdrwx------ 2 root root 6 7月 30 19:05 fastcgi_tempdrwxr-xr-x 5 root root 141 7月 30 19:15 htmldrwxr-xr-x 2 root root 58 7月 30 19:12 logsdrwx------ 2 root root 6 7月 30 19:05 proxy_tempdrwxr-xr-x 2 root root 19 7月 30 19:04 sbindrwx------ 2 root root 6 7月 30 19:05 scgi_tempdrwx------ 2 root root 6 7月 30 19:05 uwsgi_temp 其中，conf是配置文件，html是静态文件目录，logs是错误日志目录，sbin是执行文件目录 1、启动 ./sbin/nginx 2、停止 ./sbin/nginx -s stop 3、重载配置文件 ./sbin/nignx -s reload 4、指定配置文件启动 ./sbin/nginx -c /conf/nginx.conf]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Appium:分布式测试环境搭建]]></title>
    <url>%2Fposts%2F4e971816%2F</url>
    <content type="text"><![CDATA[需求同时向大量的跨平台机器推送脚本，执行测试。 环境搭建1.Selenium Standalone Server1、下载jar包，地址为：https://www.seleniumhq.org/download/ 2、启动服务 java -jar selenium-server-standalone-&lt;version&gt;.jar -role hub 服务启动后，访问：localhost：4444验证。 3、编辑节点配置文件 &#123; &quot;capabilities&quot;: [ &#123; &quot;browserName&quot;: &quot;&lt;e.g._iPhone5_or_iPad4&gt;&quot;, &quot;version&quot;:&quot;&lt;version_of_iOS_e.g._7.1&gt;&quot;, &quot;maxInstances&quot;: 1, &quot;platform&quot;:&quot;&lt;platform_e.g._MAC_or_ANDROID&gt;&quot; &#125; ], &quot;configuration&quot;: &#123; &quot;cleanUpCycle&quot;:2000, &quot;timeout&quot;:30000, &quot;proxy&quot;: &quot;org.openqa.grid.selenium.proxy.DefaultRemoteProxy&quot;, &quot;url&quot;:&quot;http://&lt;host_name_appium_server_or_ip-address_appium_server&gt;:&lt;appium_port&gt;/wd/hub&quot;, &quot;host&quot;: &lt;host_name_appium_server_or_ip-address_appium_server&gt;, &quot;port&quot;: &lt;appium_port&gt;, &quot;maxSession&quot;: 1, &quot;register&quot;: true, &quot;registerCycle&quot;: 5000, &quot;hubPort&quot;: &lt;grid_port&gt;, &quot;hubHost&quot;: &quot;&lt;Grid_host_name_or_grid_ip-address&gt;&quot; &#125;&#125; 如果没有给出 url、host 和 port，配置会自动指向 localhost:whatever-port-Appium-started-on。 如果你的 Appium Server 和 Selenium Grid 没有运行在同一台机器上，为确保 Selenium Grid 连接正常，请在你的 host &amp; url 上使用外部域名或 IP 地址，而不是 localhost 和 127.0.0.1 4、指定配置文件启动Appuium节点appium -p 4724 -bp 4714 --nodeconfig &quot;json文件路径&quot; 其中，-p与配置文件中的port一致，即指定appium启动的端口号，-bp是手机客户端bootStrap监听的端口号 启动后，控制台输出如下： [Appium] Appium support for versions of node &lt; 8 has been deprecated and will be removed in a future version. Please upgrade![Appium] Welcome to Appium v1.8.1[Appium] Non-default server args:[Appium] port: 4724[Appium] bootstrapPort: 4714[Appium] nodeconfig: SM-G9550[debug] [Appium] Starting auto register thread for grid. Will try to register every 5000 ms.[Appium] Appium REST http interface listener started on 0.0.0.0:4724[debug] [Appium] Appium successfully registered with the grid on http://localhost:4444 问题Selenium Grid会发生阻塞，如果上一个测试任务因为异常无法继续执行会发生阻塞，后面的测试任务无法继续执行]]></content>
      <categories>
        <category>Appium</category>
      </categories>
      <tags>
        <tag>Appium</tag>
        <tag>Grid</tag>
        <tag>Selenium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Quartz：Listener注入Spring对象]]></title>
    <url>%2Fposts%2F1b401ae4%2F</url>
    <content type="text"><![CDATA[我们知道，由于listener启动会先于spring容器。况且quratz 中的bean是独立于spring外运行的，也就是说spring把创建bean的生命周期权限托管给了quratz所以要想在job 或者job的listener中注入spring的bean肯定是不行的 但是我们可以使用别的方法。下面我写一个自己认为最简单的方法： 先创建一个spring的SpringUtil的工具类，该工具类主要是利用实现了ApplicationContextAware接口，利用set方法先实例化一个ApplicationContext，然后就可以获取对应的bean源码如下: import org.springframework.beans.BeansException;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.stereotype.Component;@Componentpublic class SpringUtil implements ApplicationContextAware&#123; private static ApplicationContext applicationContext; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; if(SpringUtil.applicationContext == null) &#123; SpringUtil.applicationContext = applicationContext; &#125; &#125; //获取applicationContext public static ApplicationContext getApplicationContext() &#123; return applicationContext; &#125; //通过name获取 Bean. public static Object getBean(String name)&#123; return getApplicationContext().getBean(name); &#125; //通过class获取Bean. public static &lt;T&gt; T getBean(Class&lt;T&gt; clazz)&#123; return getApplicationContext().getBean(clazz); &#125; //通过name,以及Clazz返回指定的Bean public static &lt;T&gt; T getBean(String name,Class&lt;T&gt; clazz)&#123; return getApplicationContext().getBean(name, clazz); &#125;&#125; 使用方法 @Componentpublic class MySchedulerListener implements SchedulerListener&#123; ... @Override public void jobScheduled(Trigger trigger) &#123; MyBatisMapper myBatisMapper = (MyBatisMapper)SpringUtil.getBean(MyBatisMapper.class); myBatisMapper.updateByPrimaryKey(0); System.out.println("任务被部署时被执行"); &#125; ...&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库：MySQL常用语句]]></title>
    <url>%2Fposts%2Fa81bce10%2F</url>
    <content type="text"><![CDATA[查询字段为null或者不为null在mysql中，查询某字段为空时，切记不可用= null，而是 is null，不为空则是is not null，示例如下： select * from table where column is null;select * from table where column is not null; group by 异常MySQL5.7 后将sql_mode的ONLY_FULL_GROUP_BY模式默认设置为打开状态，这样一来，很多之前的sql语句可能会出现错误，错误信息如下： Error Code: 1055. Expression #3 of SELECT list is not in GROUP BY clause and contains nonaggregated column &apos;×××&apos; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by 解决方法： 1、查看sql_mode select @@sql_mode 查询出来的值为： ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION 2、去掉ONLY_FULL_GROUP_BY，重新设置值 set @@sql_mode =&apos;STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION&apos;; 3、上面是改变了全局sql_mode，对于新建的数据库有效。对于已存在的数据库，则需要在对应的数据下执行 set sql_mode =&apos;STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION&apos;; 4、以上的改表方式只能临时生效，在MySQL重启之后就失效了，想要一劳永逸的办法，就是修改配置文件。RPM的安装方式，配置文件位于/etc/my.cnf，增加如下配置： sql_mode=STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION 忽略表名大小写在配置文件my.cnf在增加如下配置： #默认是0，区分大小写；1忽略大小写lower_case_table_names=1 如果原有的数据库表中有大写的表名，在配置生效后，会出现该表查找不到的异常。在配置之前，将含有大写的表导出，在配置生效之后，重新导入，可以消除异常。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务：Zuul转发后文件名乱码]]></title>
    <url>%2Fposts%2Fe7f3dec2%2F</url>
    <content type="text"><![CDATA[最近在使用 SpringCloud 搭建微服务的过程中，发现上传文件经过 Zuul 网关转发的时候，因为上传文件名中文乱码，导致文件的写操作失败。但是不经过 Zuul 转发的时候，文件上传正常，因此猜测是 Zuul 对上传的请求的编码进行了处理。 原文件名：file中文.txt上传后：file__.txt 解决方法如下：一、增加请求前缀在上传文件的请求路径之前添加字符串zuul声明。网关将所有带/zuul请求的请求都走zuulServlet，不带zuul的请求都走spring mvc的dispatchServlet，避免多余的编码处理。 原请求路径：http://localhost:8080/uploadFile修改后：http://localhost:8080/zuul/uploadFile 二、增加 application.property 属性在方案一的基础上，主要修改前端代码，也可以在application.property声明属性来处理。 zuul.servlet-path=/ 但是，如果前端文件部署在网关上，会由于所有的请求都跳过spring mvc处理，而无法正常渲染前端页面。因此，请根据实际需求选择解决方案。]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>zuul</tag>
        <tag>文件上传</tag>
        <tag>乱码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[版本管理：Git代码冲突常见解决方法]]></title>
    <url>%2Fposts%2Ffbabd5d1%2F</url>
    <content type="text"><![CDATA[如果系统中有一些配置文件在服务器上做了配置修改,然后后续开发又新添加一些配置项的时候，在发布这个配置文件的时候,会发生代码冲突: error: Your local changes to the following files would be overwritten by merge: protected/config/main.phpPlease, commit your changes or stash them before you can merge. 如果希望保留生产服务器上所做的改动,仅仅并入新配置项, 处理方法如下: git stashgit pullgit stash pop 然后可以使用git diff -w +文件名来确认代码自动合并的情况. 反过来,如果希望用代码库中的文件完全覆盖本地工作版本. 方法如下: git reset --hardgit pull 其中git reset是针对版本,如果想针对文件回退本地修改,使用 git checkout HEAD file/to/restore]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JAVA：流]]></title>
    <url>%2Fposts%2F9c74640c%2F</url>
    <content type="text"><![CDATA[*Java核心技术卷二-读书笔记 流输入流：可以从其中读入字节序列的对象；输出流：可以向其中写入字节序列的对象； 抽象类InputStream和OutputStream构成输入/输出(I/O)类层次结构基础。 Unicode中每个字符都使用多个字节表示，以上面向字节的流不便处理，因此，从抽象类Reader和Writer中继承出专用于处理Unicode字符的类层次结构，且读写操作都基于两字节的Unicode码元。 读写字节adstract int read() InputStream类的抽象方法，作用是：读入一个字节，并返回读入的字节，或者在遇到输入源结尾时返回-1。具体的输入流类必须覆盖此方法以提供适用的功能。 abstract void write(int b) OutputStream的抽象方法，用于向某个输出位置写出一个字节。 read和write方法在执行时都将阻塞，直至字节确实被读入或写出。 available方法用于检查当前可读入的字节数量。以下的代码写法就不可能被阻塞，因为字节数组的长度被确定。 int bytesAvailable = in.available();if (bytesAvailable &gt; 0) &#123; byte[] data = new byte[bytesAvailable]; in.read(data);&#125; 完成对流的读写后，应调用close方法关闭它，释放系统资源。关闭输出流的同时，还会冲刷用于该输出流的缓冲区（buffer）：字节输出时，先被置于临时缓冲区中，再以更大的包（block）的形式写出，当关闭输出流时，会将缓冲区内容输出。如果不关闭，那么写出字节的最后一个包可能永远也无法输出。当然，也可以用flush方法强制输出。 组合流过滤器FileInputStream和FileOutputStream可以通过文件路径读取磁盘文件上的输入/输出流，并且只能从fin对象中读入字节和字节数组。 FileInputStream fin = new FileInputStream("employee.dat")byte b = (byte)fin.read(); 提示：java.io的相对路径以用户工作目录开始，调用System.getProperty(&quot;user.dir&quot;)来获取。 DataInputStream只能读入数值类型，而不能从文件获取数据。 DataInputStream din = ...;double s = din.readDouble(); 如果希望从文件或者其他外部位置获取字节，再将其组装到更有用的数据类型中（如数字类型），则必须对二者进行组合。 FileInputStream fin = new FileInputStream(&quot;employee.dat&quot;);DataInputStream din = new DataInputStream(fin);double s = din.readDouble(); 再例如，默认情况下流的读取时不被缓冲区缓存的，每调用一次read会请求操作系统再分发一个字节。要想使用缓冲机制，并从文件获取数据，就需要如下的构造器序列。 DataInputStream din = new DataInputStream( new BufferInputStream( new FileInputStream(&quot;employee.dat&quot;))); 文本输入与输出保存数据时，可以选择二进制格式或者文本格式。尽管二进制格式的I/O高效且高速，但是难以阅读。 在存储文本字符串时，需要考虑字符编码（character encoding）方式，如UTF-16、ISO 8859-1等。 OutputStreamWriter类使用选定的字符编码方式，把Unicode字符流转换为字节流。而InputStreamReader类将字节输入流转为可以产生Unicode码元的读入器。 例如，从控制台读入键盘敲击信息，并转为Unicode： InputStreamReader in = new InputStreamReader(System.in); 这个InputStreamReader使用系统默认字符编码方式，如需指定不同的编码方式，则可用以下方式： InputStreamReader in = new InputStreamReader( new FileInputStream("kremlin.dat"), "ISO8859_5"); 如何写出文本输出PrintWriter类拥有以文本格式打印字符串和数字的方法，再使用与System.out相同的print、println和printf方法打印数字、字符、布尔值、字符串和对象到文件中。例如： PrintWriter out = new PrintWriter("employee.txt");String name = "Harry Hacker";double salary = 75000;out.print(name);out.print(' ');out.println(salary); 输出以下内容到 employee.txt 中： Harry Hacker 75000.0 如何读入文本输入在 Java SE 5.0 之前，通过BufferedReader类的readLine方法读入一行文本。readLine在没有输入时返回 null。以下示例集成缓冲功能： BufferedReader in = new BufferedReader( new InputStreamReader(new FileInputStream("employee.txt"), "UTF-8")); String line;while ((line - in.readLine()) != null) &#123; do something with line&#125; 然而，BufferedReader不能读入数字，建议使用Scanner来处理。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>InputStream</tag>
        <tag>OutputStream</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA：[转]深入理解abstract class和interface]]></title>
    <url>%2Fposts%2Fa494d8f4%2F</url>
    <content type="text"><![CDATA[理解抽象类abstract class和interface在Java语言中都是用来进行抽象类（本文中的抽象类并非从abstract class翻译而来，它表示的是一个抽象体，而abstract class为Java语言中用于定义抽象类的一种方法，请读者注意区分）定义的，那么什么是抽象类，使用抽象类能为我们带来什么好处呢？ 在面向对象的概念中，我们知道所有的对象都是通过类来描绘的，但是反过来却不是这样。并不是所有的类都是用来描绘对象的，如果一个类中没有包含足够的信息来描绘一个具体的对象，这样的类就是抽象类。抽象类往往用来表征我们在对问题领域进行分析、设计中得出的抽象概念，是对一系列看上去不同，但是本质上相同的具体概念的抽象。比如：如果我们进行一个图形编辑软件的开发，就会发现问题领域存在着圆、三角形这样一些具体概念，它们是不同的，但是它们又都属于形状这样一个概念，形状这个概念在问题领域是不存在的，它就是一个抽象概念。正是因为抽象的概念在问题领域没有对应的具体概念，所以用以表征抽象概念的抽象类是不能够实例化的。 在面向对象领域，抽象类主要用来进行类型隐藏。我们可以构造出一个固定的一组行为的抽象描述，但是这组行为却能够有任意个可能的具体实现方式。这个抽象描述就是抽象类，而这一组任意个可能的具体实现则表现为所有可能的派生类。模块可以操作一个抽象体。由于模块依赖于一个固定的抽象体，因此它可以是不允许修改的；同时，通过从这个抽象体派生，也可扩展此模块的行为功能。熟悉OCP的读者一定知道，为了能够实现面向对象设计的一个最核心的原则OCP( Open-Closed Principle)，抽象类是其中的关键所在。 从语法定义层面看abstract class和interface在语法层面，Java语言对于abstract class和interface给出了不同的定义方式，下面以定义一个名为Demo的抽象类为例来说明这种不同。 使用abstract class的方式定义Demo抽象类的方式如下： abstract class Demo ｛ abstract void method1(); abstract void method2(); …｝ 使用interface的方式定义Demo抽象类的方式如下： interface Demo &#123; void method1(); void method2(); …&#125; 在abstract class方式中，Demo可以有自己的数据成员，也可以有非abstarct的成员方法，而在interface方式的实现中，Demo只能够有静态的不能被修改的数据成员（也就是必须是static final的，不过在interface中一般不定义数据成员），所有的成员方法都是abstract的。从某种意义上说，interface是一种特殊形式的abstract class。 对于abstract class和interface在语法定义层面更多的细节问题，不是本文的重点，不再赘述，读者可以参阅参考文献〔1〕获得更多的相关内容。 从编程层面看abstract class和interface从编程的角度来看，abstract class和interface都可以用来实现”design by contract”的思想。但是在具体的使用上面还是有一些区别的。 首先，abstract class在Java语言中表示的是一种继承关系，一个类只能使用一次继承关系。但是，一个类却可以实现多个interface。也许，这是Java语言的设计者在考虑Java对于多重继承的支持方面的一种折中考虑吧。 其次，在abstract class的定义中，我们可以赋予方法的默认行为。但是在interface的定义中，方法却不能拥有默认行为，为了绕过这个限制，必须使用委托，但是这会 增加一些复杂性，有时会造成很大的麻烦。 在抽象类中不能定义默认行为还存在另一个比较严重的问题，那就是可能会造成维护上的麻烦。因为如果后来想修改类的界面（一般通过abstract class或者interface来表示）以适应新的情况（比如，添加新的方法或者给已用的方法中添加新的参数）时，就会非常的麻烦，可能要花费很多的时间（对于派生类很多的情况，尤为如此）。但是如果界面是通过abstract class来实现的，那么可能就只需要修改定义在abstract class中的默认行为就可以了。 同样，如果不能在抽象类中定义默认行为，就会导致同样的方法实现出现在该抽象类的每一个派生类中，违反了”one rule，one place”原则，造成代码重复，同样不利于以后的维护。因此，在abstract class和interface间进行选择时要非常的小心。 从设计理念层面看abstract class和interface上面主要从语法定义和编程的角度论述了abstract class和interface的区别，这些层面的区别是比较低层次的、非本质的。本小节将从另一个层面：abstract class和interface所反映出的设计理念，来分析一下二者的区别。作者认为，从这个层面进行分析才能理解二者概念的本质所在。 前面已经提到过，abstarct class在Java语言中体现了一种继承关系，要想使得继承关系合理，父类和派生类之间必须存在”is a”关系，即父类和派生类在概念本质上应该是相同的（参考文献〔3〕中有关于”is a”关系的大篇幅深入的论述，有兴趣的读者可以参考）。对于interface 来说则不然，并不要求interface的实现者和interface定义在概念本质上是一致的，仅仅是实现了interface定义的契约而已。为了使论述便于理解，下面将通过一个简单的实例进行说明。 考虑这样一个例子，假设在我们的问题领域中有一个关于Door的抽象概念，该Door具有执行两个动作open和close，此时我们可以通过abstract class或者interface来定义一个表示该抽象概念的类型，定义方式分别如下所示： 使用abstract class方式定义Door： abstract class Door &#123; abstract void open(); abstract void close()；&#125; 使用interface方式定义Door： interface Door &#123; void open(); void close();&#125; 其他具体的Door类型可以extends使用abstract class方式定义的Door或者implements使用interface方式定义的Door。看起来好像使用abstract class和interface没有大的区别。 如果现在要求Door还要具有报警的功能。我们该如何设计针对该例子的类结构呢（在本例中，主要是为了展示abstract class和interface反映在设计理念上的区别，其他方面无关的问题都做了简化或者忽略）？下面将罗列出可能的解决方案，并从设计理念层面对这些不同的方案进行分析。 解决方案一：简单的在Door的定义中增加一个alarm方法，如下： abstract class Door &#123; abstract void open(); abstract void close()； abstract void alarm();&#125; 或者 interface Door &#123; void open(); void close(); void alarm();&#125; 那么具有报警功能的AlarmDoor的定义方式如下： class AlarmDoor extends Door &#123; void open() &#123; … &#125; void close() &#123; … &#125; void alarm() &#123; … &#125;&#125; 或者 class AlarmDoor implements Door ｛ void open() &#123; … &#125; void close() &#123; … &#125; void alarm() &#123; … &#125;｝ 这种方法违反了面向对象设计中的一个核心原则ISP（Interface Segregation Priciple），在Door的定义中把Door概念本身固有的行为方法和另外一个概念”报警器”的行为方法混在了一起。这样引起的一个问题是那些仅仅依赖于Door这个概念的模块会因为”报警器”这个概念的改变（比如：修改alarm方法的参数）而改变，反之依然。 解决方案二：既然open、close和alarm属于两个不同的概念，根据ISP原则应该把它们分别定义在代表这两个概念的抽象类中。定义方式有：这两个概念都使用abstract class方式定义；两个概念都使用interface方式定义；一个概念使用abstract class方式定义，另一个概念使用interface方式定义。 显然，由于Java语言不支持多重继承，所以两个概念都使用abstract class方式定义是不可行的。后面两种方式都是可行的，但是对于它们的选择却反映出对于问题领域中的概念本质的理解、对于设计意图的反映是否正确、合理。我们一一来分析、说明。 如果两个概念都使用interface方式来定义，那么就反映出两个问题：1、我们可能没有理解清楚问题领域，AlarmDoor在概念本质上到底是Door还是报警器？2、如果我们对于问题领域的理解没有问题，比如：我们通过对于问题领域的分析发现AlarmDoor在概念本质上和Door是一致的，那么我们在实现时就没有能够正确的揭示我们的设计意图，因为在这两个概念的定义上（均使用interface方式定义）反映不出上述含义。 如果我们对于问题领域的理解是：AlarmDoor在概念本质上是Door，同时它有具有报警的功能。我们该如何来设计、实现来明确的反映出我们的意思呢？前面已经说过，abstract class在Java语言中表示一种继承关系，而继承关系在本质上是”is a”关系。所以对于Door这个概念，我们应该使用abstarct class方式来定义。另外，AlarmDoor又具有报警功能，说明它又能够完成报警概念中定义的行为，所以报警概念可以通过interface方式定义。如下所示： abstract class Door &#123; abstract void open(); abstract void close()； &#125;interface Alarm &#123; void alarm();&#125;class AlarmDoor extends Door implements Alarm &#123; void open() &#123; … &#125; void close() &#123; … &#125; void alarm() &#123; … &#125;&#125; 这种实现方式基本上能够明确的反映出我们对于问题领域的理解，正确的揭示我们的设计意图。其实abstract class表示的是”is a”关系，interface表示的是”like a”关系，大家在选择时可以作为一个依据，当然这是建立在对问题领域的理解上的，比如：如果我们认为AlarmDoor在概念本质上是报警器，同时又具有Door的功能，那么上述的定义方式就要反过来了。 结论abstract class和interface是Java语言中的两种定义抽象类的方式，它们之间有很大的相似性。但是对于它们的选择却又往往反映出对于问题领域中的概念本质的理解、对于设计意图的反映是否正确、合理，因为它们表现了概念间的不同的关系（虽然都能够实现需求的功能）。这其实也是语言的一种的惯用法，希望读者朋友能够细细体会。]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Quartz:常见异常]]></title>
    <url>%2Fposts%2F6ed02c97%2F</url>
    <content type="text"><![CDATA[持久化模式常见异常无数据源完成持久化的配置之后，仍然无法连接到数据库，报错的内容是：C3P0的connectionProvider初始化失败。查了很多资料，再结合错误信息，花了半天时间，才发现：原来quartz默认使用了C3P0的数据源，然而quartz的依赖包中并没有C3P0的依赖，因此无法初始化连接器。解决方法：只要在maven管理的POM.xml中把C3P0的依赖加上就可以了。 连接超时MySQL服务器默认的“wait_timeout”是28800秒即8小时，意味着如果一个连接的空闲时间超过8个小时，MySQL将自动断开该连接，而连接池却认为该连接还是有效的(因为并未校验连接的有效性)，当应用申请使用该连接时，就会导致异常发生。 在本文，由于我们的C3P0连接池没有配置连接有效性检查，导致quartz使用的连接线程可能超时无效。错误如下：JobStoreTX - MisfireHandler: Error handling misfires: Database error recovering from misfires.Another error has occurred [ com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: No operations allowed after connection closed. ] which will not be reported to listeners! 解决这个问题的办法有三种，但是推荐第二种——减少连接池内连接的生命周期。 1. 增加 MySQL 的 wait_timeout 属性的值修改mysql安装目录下的配置文件 my.ini文件（如果没有此文件， 复制“my-default.ini”文件，生成“复件 my-default.ini”文件。 将“复件 my-default.ini”文件重命名成“my.ini” ），在文件中设置： wait_timeout=31536000 interactive_timeout=31536000 2. 减少连接池内连接的生存周期减少连接池内连接的生存周期， 使之小于 上一项中所设置的 wait_timeout 的值。此处修改Quartz的c3p0配置信息，内容如下： org.quartz.dataSource.NAME.validationQuery增加用于验证连接有效性的数据库查询语句，如select count(*) from QRTZ_CALENDARS org.quartz.dataSource.NAME.validateOnCheckout只有配置了validationQuery之后，才能设置为true org.quartz.dataSource.NAME.idleConnectionValidationSeconds只有配置了validationQuery之后，才能配置有效性查询的时间间隔，默认50s org.quartz.dataSource.NAME.discardIdleConnectionsSeconds废弃空闲连接的时间，默认是0s 参考：Quartz官方文档 3. 定期使用连接池内的连接定期使用连接池内的连接，使得它们不会因为闲置超时而被 MySQL 断开。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven:管理本地jar包]]></title>
    <url>%2Fposts%2F46b8b7d2%2F</url>
    <content type="text"><![CDATA[Maven依赖管理，可以很方便的帮助我们添加所需的jar包。但是，大部分情况，这些jar包都是Maven项目。如果我们需要引入自定义的jar包，又该如何处理呢？ 起初，我在项目中新建lib文件夹，并把自定义的jar包放进去，然后，在pom.xml中进行如下配置：&lt;dependency&gt; &lt;groupId&gt;dd-plist&lt;/groupId&gt; &lt;artifactId&gt;dd-plist&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;project.basedir&#125;/lib/dd-plist.jar&lt;/systemPath&gt;&lt;/dependency&gt; 结果，本地使用IDE运行调试时没有问题，但是打成jar包上传到服务器却找不到该jar包中的类文件。 为了解决这个问题，我找到了如下的方案。 1 在项目的目录下创建lib文件夹2 使用Maven安装自定义jar包在命令行执行以下命令，可以安装自定义jar包到我们指定的lib文件夹。注意配置好自定义jar包的路径。 mvn install:install-file -Dfile=path_to_mylib.jar -DgroupId=com.mylib -DartifactId=jar_name -Dversion=1.0 -Dpackaging=jar -DlocalRepositoryPath=path_to_my_project/lib 执行成功后，终端显示内容如下： [INFO] Scanning for projects...[INFO] [INFO] ------------------------------------------------------------------------[INFO] Building Maven Stub Project (No POM) 1[INFO] ------------------------------------------------------------------------[INFO] [INFO] --- maven-install-plugin:2.4:install-file (default-cli) @ standalone-pom ---[INFO] Installing path_to_mylib.jar to path_to_my_project/lib/com/mylib/jar_name/1.0/dd-plist-1.0.jar[INFO] Installing /var/folders/r5/86whqmls4y36p5qgnhwstr6w0000gn/T/mvninstall2596441059296695813.pom to path_to_my_project/lib/com/mylib/jar_name/1.0/dd-plist-1.0.pom[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 0.413 s[INFO] Finished at: 2018-06-01T10:13:20+08:00[INFO] Final Memory: 9M/309M[INFO] ------------------------------------------------------------------------ 3 配置POM文件按如下文件配置POM.xml，配置完成之后，重新执行Maven Reimport，即可生效。&lt;repositories&gt; &lt;repository&gt; &lt;!-- DO NOT set id to &quot;local&quot; because it is reserved by Maven --&gt; &lt;id&gt;lib&lt;/id&gt; &lt;url&gt;file://$&#123;project.basedir&#125;/lib&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.mylib&lt;/groupId&gt; &lt;artifactId&gt;mylib&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 结语通过以上方式配置的自定义jar包，在工程打包部署后仍然可以生效。具体的原理，可以留言给我。我很乐意多学习一些Maven的知识。]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[足迹：富春桃源]]></title>
    <url>%2Fposts%2Fec6986a1%2F</url>
    <content type="text"><![CDATA[2018年5月19日和S一起来到富春桃园，参加她们公司的TB。当天淫雨霏霏，初晴乍雨，空气清新潮湿。 大巴先到了图中的码头，放眼望去，确实有一种古时吴越之地那种“沉舟侧畔千帆过，病树前头万木春“的意境。一日的行程，终止于此。期间历经登山、穿越溶洞、轨道滑行、农家乐、竹筏漂流。登岸时，仰望天际，有种”激流勇进，放浪天涯“的冲动。]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo：常用命令]]></title>
    <url>%2Fposts%2Fc8dcc28b%2F</url>
    <content type="text"><![CDATA[草稿草稿相当于很多博客都有的“私密文章”功能。 hexo new draft &quot;new draft&quot; 会在source/_drafts目录下生成一个new-draft.md文件。但是这个文件不被显示在页面上，链接也访问不到。也就是说如果你想把某一篇文章移除显示，又不舍得删除，可以把它移动到_drafts目录之中。 如果你希望强行预览草稿，更改配置文件： render_drafts: true 或者，如下方式启动server： hexo server --drafts 下面这条命令可以把草稿变成文章，或者页面： hexo publish [layout] &lt;filename&gt;]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>草稿</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务[Exception]：Zuul无法访问负载均衡服务]]></title>
    <url>%2Fposts%2F8e887edc%2F</url>
    <content type="text"><![CDATA[问题描述使用zuul的负载均衡功能时，无法访问负载均衡服务 先决条件 使用Eureka作为服务注册 zuul配置路由匹配规则为服务化的路由规则 异常如下15:50:18.013 Gateway [http-nio-9090-exec-6] WARN o.s.c.n.z.f.post.SendErrorFilter - Error during filteringcom.netflix.zuul.exception.ZuulException: Forwarding error at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.handleException(RibbonRoutingFilter.java:189) at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:164) at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.run(RibbonRoutingFilter.java:111) at com.netflix.zuul.ZuulFilter.runFilter(ZuulFilter.java:112) at com.netflix.zuul.FilterProcessor.processZuulFilter(FilterProcessor.java:193) at com.netflix.zuul.FilterProcessor.runFilters(FilterProcessor.java:157) at com.netflix.zuul.FilterProcessor.route(FilterProcessor.java:118) at com.netflix.zuul.ZuulRunner.route(ZuulRunner.java:96) at com.netflix.zuul.http.ZuulServlet.route(ZuulServlet.java:116) at com.netflix.zuul.http.ZuulServlet.service(ZuulServlet.java:81) at org.springframework.web.servlet.mvc.ServletWrappingController.handleRequestInternal(ServletWrappingController.java:157) at org.springframework.cloud.netflix.zuul.web.ZuulController.handleRequest(ZuulController.java:44) at org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:50) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:635) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at com.cmcc.cmct.gateway.auth.AuthenticationTokenProcessingFilter.doFilter(AuthenticationTokenProcessingFilter.java:47) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:478) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)Caused by: com.netflix.client.ClientException: null at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:118) at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:152) at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:49) at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:302) at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:298) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:46) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:51) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:51) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeMap.call(OnSubscribeMap.java:48) at rx.internal.operators.OnSubscribeMap.call(OnSubscribeMap.java:33) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:51) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.subscribe(Observable.java:10247) at rx.Observable.subscribe(Observable.java:10214) at rx.internal.operators.BlockingOperatorToFuture.toFuture(BlockingOperatorToFuture.java:51) at rx.observables.BlockingObservable.toFuture(BlockingObservable.java:411) at com.netflix.hystrix.HystrixCommand.queue(HystrixCommand.java:378) at com.netflix.hystrix.HystrixCommand.execute(HystrixCommand.java:344) at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:158) ... 105 common frames omittedCaused by: java.lang.RuntimeException: java.net.UnknownHostException: xntest02.gzhl.quality: 未知的名称或服务 at rx.exceptions.Exceptions.propagate(Exceptions.java:58) at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:464) at rx.observables.BlockingObservable.single(BlockingObservable.java:341) at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:112) ... 167 common frames omittedCaused by: java.net.UnknownHostException: xntest02.gzhl.quality: 未知的名称或服务 at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method) at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928) at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1323) at java.net.InetAddress.getAllByName0(InetAddress.java:1276) at java.net.InetAddress.getAllByName(InetAddress.java:1192) at java.net.InetAddress.getAllByName(InetAddress.java:1126) at org.apache.http.impl.conn.SystemDefaultDnsResolver.resolve(SystemDefaultDnsResolver.java:45) at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:112) at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:359) at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381) at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237) at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185) at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89) at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111) at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108) at org.springframework.cloud.netflix.ribbon.apache.RibbonLoadBalancingHttpClient.execute(RibbonLoadBalancingHttpClient.java:82) at org.springframework.cloud.netflix.ribbon.apache.RibbonLoadBalancingHttpClient.execute(RibbonLoadBalancingHttpClient.java:42) at com.netflix.client.AbstractLoadBalancerAwareClient$1.call(AbstractLoadBalancerAwareClient.java:104) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:303) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:287) at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:231) at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:228) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.drain(OnSubscribeConcatMap.java:286) at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.onNext(OnSubscribeConcatMap.java:144) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:185) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:180) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:94) at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:42) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber$1.call(OperatorRetryWithPredicate.java:127) at rx.internal.schedulers.TrampolineScheduler$InnerCurrentThreadScheduler.enqueue(TrampolineScheduler.java:73) at rx.internal.schedulers.TrampolineScheduler$InnerCurrentThreadScheduler.schedule(TrampolineScheduler.java:52) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber.onNext(OperatorRetryWithPredicate.java:79) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber.onNext(OperatorRetryWithPredicate.java:45) at rx.internal.util.ScalarSynchronousObservable$WeakSingleProducer.request(ScalarSynchronousObservable.java:276) at rx.Subscriber.setProducer(Subscriber.java:209) at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:138) at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:129) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.subscribe(Observable.java:10247) at rx.Observable.subscribe(Observable.java:10214) at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:444) ... 169 common frames omitted 分析根据如下两部分的异常内容，通常会认为是Ribbon和Hystrix的超时问题。 异常一： com.netflix.zuul.exception.ZuulException: Forwarding error at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.handleException(RibbonRoutingFilter.java:189) at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:164) at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.run(RibbonRoutingFilter.java:111) ...... 异常二： Caused by: com.netflix.client.ClientException: null at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:118) at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:152) at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:49) at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:302) at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:298) 相应的解决方案： ribbon.ConnectTimeout=60000ribbon.ReadTimeout=60000hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=120000 然而 不幸的是，我加了这两个超时配置之后，并没有改变zuul负载均衡转发异常。唯一改变的是：在每次异常发生时，请求的等待时间被大大延长。抓狂~~~~ 通过多次的本地实验，我才开始对异常三产生了重视，内容如下：异常三： Caused by: java.net.UnknownHostException: xntest02.gzhl.quality: 未知的名称或服务 at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method) at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928) at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1323) 是的，重点在这里。尽管负载均衡器在启动的时候就发现了可以用于分担压力的三个节点，然而，这些节点信息都是Eureka提供的。我们的当地主机虽然获得了这些节点的hostname，却根本不知道如何去访问它们。 zuul启动时获取的服务注册信息 16:07:42.327 Gateway [main] INFO c.n.l.DynamicServerListLoadBalancer - DynamicServerListLoadBalancer for client CloudAPI initialized: DynamicServerListLoadBalancer:&#123;NFLoadBalancer:name=CloudAPI,current list of Servers=[xntest02.gzhl.quality:9000, xntest03.gzhl.quality:9000, xntest01.gzhl.quality:9000],Load balancer stats=Zone stats: &#123;defaultzone=[Zone:defaultzone; Instance count:3; Active connections count: 0; Circuit breaker tripped count: 0; Active connections per server: 0.0;]&#125;,Server stats: [[Server:xntest03.gzhl.quality:9000; Zone:defaultZone; Total Requests:0; Successive connection failure:0; Total blackout seconds:0; Last connection made:Thu Jan 01 08:00:00 CST 1970; First connection made: Thu Jan 01 08:00:00 CST 1970; Active Connections:0; total failure count in last (1000) msecs:0; average resp time:0.0; 90 percentile resp time:0.0; 95 percentile resp time:0.0; min resp time:0.0; max resp time:0.0; stddev resp time:0.0], [Server:xntest01.gzhl.quality:9000; Zone:defaultZone; Total Requests:0; Successive connection failure:0; Total blackout seconds:0; Last connection made:Thu Jan 01 08:00:00 CST 1970; First connection made: Thu Jan 01 08:00:00 CST 1970; Active Connections:0; total failure count in last (1000) msecs:0; average resp time:0.0; 90 percentile resp time:0.0; 95 percentile resp time:0.0; min resp time:0.0; max resp time:0.0; stddev resp time:0.0], [Server:xntest02.gzhl.quality:9000; Zone:defaultZone; Total Requests:0; Successive connection failure:0; Total blackout seconds:0; Last connection made:Thu Jan 01 08:00:00 CST 1970; First connection made: Thu Jan 01 08:00:00 CST 1970; Active Connections:0; total failure count in last (1000) msecs:0; average resp time:0.0; 90 percentile resp time:0.0; 95 percentile resp time:0.0; min resp time:0.0; max resp time:0.0; stddev resp time:0.0]]&#125; 看到这儿，解决方案也就出来了。那就是，确保每一个服务所在的服务器节点都能通过hostname和zuul网关互通。从操作角度来说，就是要在每一台服务节点上配置其他所有服务节点的hostname，使得这些服务集群互通。 Liunx解决方案：第一步 打开配置文件 vi /etc/hosts 第二步 增加服务所在主机ip对应的hostname 172.23.25.1 xntest01172.23.25.2 xntest02172.23.25.3 xntest03 大功告成~~~]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>zuul</tag>
        <tag>eureka</tag>
        <tag>micro service</tag>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务：Zuul代理转发]]></title>
    <url>%2Fposts%2Fb778229b%2F</url>
    <content type="text"><![CDATA[Zuul代理转发zuul代理转发的方式有两种： URL映射：优点是不用对被代理的服务做任务修改，适合旧系统迁移到微服务架构时采用。过渡状态中，通常会保留旧代码继续使用，同时逐步将功能一点点迁移到新平台。旧功能的访问便可以采用这种方法，使得项目可以在用户毫无感知的情况下迁移到微服务架构。缺点是每增加一个服务就需要配置一条内容，不支持动态提供后端的服务。服务化映射：在实现微服务架构时，服务名与服务实例地址的关系在eureka server中已经存在了，所以只需要将Zuul注册到eureka server上去发现其他服务，就可以实现对serviceId的映射。 URL映射客户端存在context-path客户端application.property配置 spring.application.name=service-cloudappserver.context-path=/SPLD 说明: 直接访问路径为——http://ip:port/SPLD/api zuulapplication.property配置 #注册Eureka服务发现eureka.client.serviceUrl.defaultZone: http://localhost:8060/eureka/#转发zuul.routes.app.path=/SPLD/**zuul.routes.app.serviceId=service-cloudapp 那么访问路径是：http://ip:port/SPLD/SPLD/api 如何去掉重复的前缀呢？可以在zuul中，路由后面增加配置如下： zuul.routes.app.stripPrefix=false 原理 当stripPrefix=true的时候，代理前缀默认会从请求路径中移除。访问http://zuul-ip:port/SPLD/api重定向到http://spld-ip:port/api 当stripPrefix=false的时候，会保留代理前缀。访问http://zuul-ip:port/SPLD/api会重定向到http://spld-ip:port/SPLD/api。 参考文章：springcloud(十)：服务网关zuul]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>zuul</tag>
        <tag>micro service</tag>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Liunx：常用命令]]></title>
    <url>%2Fposts%2Fcbdebe31%2F</url>
    <content type="text"><![CDATA[SCP-文件传输从服务器下载文件scp username@servername:/remote_path/filename ~/local_destination 从服务器下载整个目录scp -r username@servername:/remote_path/remote_dir/ ~/local_destination 上传本地文件到服务器scp ~/local_path/local_filename username@servername:/remote_path 上传目录到服务器scp -r ~/local_dir username@servername:/remote_path/remote_dir 查看内存free命令 total used free shared buff/cache availableMem: 8010180 1027572 454540 74152 6528068 6504456Swap: 0 0 0 total:总计物理内存的大小。used:已使用多大。free:可用有多少。Shared:多个进程共享的内存总额。Buffers/cached:磁盘缓存的大小。 Mem的used/free是从OS的角度来看，因为对于OS，buffers/cached都是属于被使用的 修改密码 登录账户后，输入passwd 输入一遍旧密码，输入两遍新密码，密码不能太简单 软连接通常数据文件会和应用部署所在系统盘分开。此时，为了既能保持整体一致性，又不会占用系统盘资源，通常会在应用部署的文件夹下建立一个指向数据盘的软连接。 命令：ln -s abc(源文件) efg(目标快捷方式) ln -s /data/upload/ ./upload 效果：当前目录产生如下文件目录 lrwxrwxrwx 1 root root 13 6月 20 15:35 upload -&gt; /data/upload/ 注意：必须使用绝对路径，否则会出现符号连接的层数过多的错误。 查看进程的完整路径在使用ps -ef查看当前进程时，看到的路径通常是不完整的，比如： #查看命令ps -aux |grep nginx#显示内容root 12996 1 0 19:44 ? 00:00:00 nginx: master process ../sbin/nginx 其中，最后的../sbin/nginx就是启动进程的命令。那么如何才能查看到完整路径呢？ linux为每一个启动的进程都建立了一个文件夹，目录位于/proc/，以上面的进程为例： #输入命令cd /proc/12996ll#查看结果lrwxrwxrwx 1 root root 0 7月 30 20:04 cwd -&gt; /usr/local/nginx-1.15.2/conflrwxrwxrwx 1 root root 0 7月 30 20:04 exe -&gt; /usr/local/nginx-1.15.2/sbin/nginx 由此可见，完整路径为：/usr/local/nginx-1.15.2/sbin/nginx]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>scp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库：MyBatis常用语法]]></title>
    <url>%2Fposts%2F5a838215%2F</url>
    <content type="text"><![CDATA[Else判断分支使用MyBatis写动态SQL查询相比Hiberntate是非常方便的。select不仅能够根据mapper接口中的返回值自动匹配 查询selectOne还是selectList，而且在查询中还可以灵活的定制查询的方式，添加if 或者 choose等标签进行查询。mybaits中没有else要用“chose when otherwise”代替 &lt;!--批量插入用户--&gt;&lt;select id="getItems" parameterType="com.ipro.shopping.to.IntegerEntity" resultType="itemsType"&gt; select * from itemsType &lt;where&gt; &lt;!--方式一使用choose的方式查询--&gt; &lt;!-- &lt;choose&gt; &lt;when test="parentId !=0 "&gt;parentTypeId=#&#123;parentId&#125;&lt;/when&gt; &lt;when test="parentId==0"&gt;parentTypeId is null&lt;/when&gt; &lt;/choose&gt; --&gt; &lt;!--方式二使用if的方式查询--&gt; &lt;if test="parentId!=0"&gt; parentTypeId=#&#123;parentId&#125; &lt;/if&gt; &lt;if test="parentId==0"&gt; parentTypeId is null &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; 导出表结构和数据使用mysqldump命令，具体用法如下： mysqldump -u用戶名 -p密码 -d 数据库名 表名 &gt; 脚本名; 导出整个数据库结构和数据 mysqldump -h localhost -uroot -p123456 database &gt; dump.sql 导出单个数据表结构和数据 mysqldump -h localhost -uroot -p123456 database table &gt; dump.sql 导出整个数据库结构（不包含数据） mysqldump -h localhost -uroot -p123456 -d database &gt; dump.sql 导出单个数据表结构（不包含数据） mysqldump -h localhost -uroot -p123456 -d database table &gt; dump.sql 可能异常可能在执行导出命令时，会遇到如下异常： mysqldump: Error: &apos;Got error 28 from storage engine&apos; when trying to dump tablespacesmysqldump: Couldn&apos;t execute &apos;show fields from `consumption`&apos;: Got error 28 from storage engine (1030) 原因 是系统空间不足，可以清理一下缓存。 数据库外键关联外键关联有四种模式，分别如下： CASCADE: 从父表中删除或更新对应的行，同时自动的删除或更新子表中匹配的行。ON DELETE CANSCADE和ON UPDATE CANSCADE都被InnoDB所支持。 SET NULL: 从父表中删除或更新对应的行，同时将子表中的外键列设为空。注意，这些在外键列没有被设为NOT NULL时才有效。ON DELETE SET NULL和ON UPDATE SET SET NULL都被InnoDB所支持。 NO ACTION: InnoDB拒绝删除或者更新父表。 RESTRICT: 拒绝删除或者更新父表。指定RESTRICT（或者NO ACTION）和忽略ON DELETE或者ON UPDATE选项的效果是一样的 按天分组查询 username create_time 张三 2018-03-13 09:48:34 李四 2018-03-14 09:24:32 查询某天： SELECT DATE_FORMAT( create_time, &quot;%Y-%m-%d) as date, COUNT( * ) as countFROM testGROUP BY DATE_FORMAT( create_time, &quot;%Y-%m-%d) 结果： date count 2018-03-13 1 2018-03-14 1 如果想要查询某时的统计信息，可以修改DATE_FORMAT内容： create_time, &quot;%Y-%m-%d %H&quot; 依次类推，其实就是对create_time进行处理，然后再对处理后的数据分组。 模糊匹配like CONCAT(&apos;%&apos;, #&#123;port&#125;, &apos;%&apos;)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>scp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Quartz：Cron表达式详解]]></title>
    <url>%2Fposts%2Ff507bee4%2F</url>
    <content type="text"><![CDATA[CronExpression：用于配置cronTrigger的实例，由七个子表达式组成。这些表达式之间用空格分隔。 Seconds（秒） Minutes（分） Hours（小时） Day-of-Month（天） Month（月） Day-of-Week（周） Year（年） 例：”0 0 12 ? * WED” 意思是：每个星期三的中午12点执行。 个别子表达式可以包含范围或者列表。例如：上面例子中的WED可以换成”MON-FRI”，”MON,WED,FRI”，甚至”MON-WED,SAT”。 子表达式范围 Seconds (0~59) Minutes (0~59) Hours (0~23) Day-of-Month (1~31,但是要注意有些月份没有31天) Month (0~11，或者”JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV,DEC”) Day-of-Week (1~7,1=SUN 或者”SUN, MON, TUE, WED, THU, FRI, SAT”) Year (1970~2099) 字段名 允许的值 允许的特殊字符 秒 0-59 , - * / 分 0-59 , - * / 小时 0-23 , - * / 日 1-31 , - * ? / L W C 月 1-12 or JAN-DEC , - * / 周几 1-7 or SUN-SAT , - * ? / L C # 年(可选字段) empty 1970-2099 , - * / 字符含义* ：代表所有可能的值。因此，“*”在Month中表示每个月，在Day-of-Month中表示每天，在Hours表示每小时 - ：表示指定范围。 , ：表示列出枚举值。例如：在Minutes子表达式中，“5,20”表示在5分钟和20分钟触发。 / ：被用于指定增量。例如：在Minutes子表达式中，“0/15”表示从0分钟开始，每15分钟执行一次。”3/20”表示从第三分钟开始，每20分钟执行一次。和”3,23,43”（表示第3，23，43分钟触发）的含义一样。 ? ：用在Day-of-Month和Day-of-Week中，指“没有具体的值”。当两个子表达式其中一个被指定了值以后，为了避免冲突，需要将另外一个的值设为“?”。例如：想在每月20日触发调度，不管20号是星期几，只能用如下写法：0 0 0 20 ?，其中最后以为只能用“?”，而不能用“”。 L ：用在day-of-month和day-of-week字串中。它是单词“last”的缩写。它在两个子表达式中的含义是不同的。在day-of-month中，“L”表示一个月的最后一天，一月31号，3月30号。在day-of-week中，“L”表示一个星期的最后一天，也就是“7”或者“SAT”如果“L”前有具体内容，它就有其他的含义了。例如：“6L”表示这个月的倒数第六天。“FRIL”表示这个月的最后一个星期五。注意：在使用“L”参数时，不要指定列表或者范围，这样会出现问题。 W ：“Weekday”的缩写。只能用在day-of-month字段。用来描叙最接近指定天的工作日（周一到周五）。例如：在day-of-month字段用“15W”指“最接近这个月第15天的工作日”，即如果这个月第15天是周六，那么触发器将会在这个月第14天即周五触发；如果这个月第15天是周日，那么触发器将会在这个月第 16天即周一触发；如果这个月第15天是周二，那么就在触发器这天触发。注意一点：这个用法只会在当前月计算值，不会越过当前月。“W”字符仅能在 day-of-month指明一天，不能是一个范围或列表。也可以用“LW”来指定这个月的最后一个工作日，即最后一个星期五。 # ：只能用在day-of-week字段。用来指定这个月的第几个周几。例：在day-of-week字段用”6#3” or “FRI#3”指这个月第3个周五（6指周五，3指第3个）。如果指定的日期不存在，触发器就不会触发。 表达式例子 表达式 含义 0 ? 每1分钟触发一次 0 0 * ? 每天每1小时触发一次 0 0 10 ? 每天10点触发一次 0 14 * ? 在每天下午2点到下午2:59期间的每1分钟触发 0 30 9 1 * ? 每月1号上午9点半 0 15 10 15 * ? 每月15日上午10:15触发 /5 * ? 每隔5秒执行一次 0 /1 ? 每隔1分钟执行一次 0 0 5-15 ? 每天5-15点整点触发 0 0/3 * ? 每三分钟触发一次 0 0-5 14 ? 在每天下午2点到下午2:05期间的每1分钟触发 0 0/5 14 ? 在每天下午2点到下午2:55期间的每5分钟触发 0 0/5 14,18 ? 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发 0 0/30 9-17 ? 朝九晚五工作时间内每半小时 0 0 10,14,16 ? 每天上午10点，下午2点，4点 0 0 12 ? * WED 表示每个星期三中午12点 0 0 17 ? * TUES,THUR,SAT 每周二、四、六下午五点 0 10,44 14 ? 3 WED 每年三月的星期三的下午2:10和2:44触发 0 15 10 ? * MON-FRI 周一至周五的上午10:15触发 0 0 23 L * ? 每月最后一天23点执行一次 0 15 10 L * ? 每月最后一日的上午10:15触发 0 15 10 ? * 6L 每月的最后一个星期五上午10:15触发 0 15 10 ? 2005 2005年的每天上午10:15触发 0 15 10 ? * 6L 2002-2005 2002年至2005年的每月的最后一个星期五上午10:15触发 0 15 10 ? * 6#3 每月的第三个星期五上午10:15触发]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>Quartz</tag>
        <tag>持久化</tag>
        <tag>对象注入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo：Nginx独立部署方法]]></title>
    <url>%2Fposts%2F3a8571de%2F</url>
    <content type="text"><![CDATA[前言在自己的生产环境中部署hexo静态博客，通常有两种方法：nohup命令：通过nohup执行hexo s实现。由于hexo s是框架提供的调试方法，不是部署方式，因此在生产环境会存在性能问题，不建议使用；Nginx服务器：通过nginx部署静态资源，将本地调试好的hexo工程打包生成的public目录部署到nginx上。nginx性能好，访问速度快。 Hexo配置处理二级目录：当生产环境中，静态博客部署在二级目录下（如：“http://域名(ip)/blog”这种情况），需要修改hexo工程下的_config.yml配置文件，否则打包生成的css、js文件目录会缺失（默认在根目录），导致无法加载样式。一般修改root和url,增加二级目录 # URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' ## and root as '/child/'url: http://yoursite.com/blogroot: /blogpermalink: :year/:month/:day/:title/permalink_defaults: 部署在根目录无需处理 打包：通常在调试环境无需打包，修改后使用hexo s，即可生效，可以直接在本地查看效果。但是，以静态资源的方式部署需要打包生成静态资源，命令为：hexo generate。 Nginx配置静态资源路由示例：hexo打包完成之后，以静态资源的方式部署到nginx，增加一个location模块。路由的细节有两种：root和alias，主要区别就是怎么解析location后面的uri。以下代码以root为例： location /blog &#123; root html; index index.html;&#125; root规则: 以上的示例，说明访问的实际路由为：html/blog/index.html alias规则: 同样的路径，alias需要按下面这么写，location后面的blog不会接到alias后面，而且alias指定的目录名后面一定要加上”/“。（^~表示uri以某个常规字符串开头，用于匹配url路径（而且不对url做编码处理，例如请求/static/20%/aa，可以被规则^~ /static/ /aa 匹配到（注意是空格））。下面是alias示例： location ^~ /blog/ &#123; alias html/blog/; index index.html;&#125; Nginx常用命令 启动：nginx 停止：nginx -s stop 重启：nginx -s restart 指定配置文件启动：nginx -c 路径 参考： nginx之location（root/alias）]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo：Github部署站点的SEO优化教程]]></title>
    <url>%2Fposts%2Fundefined%2F</url>
    <content type="text"><![CDATA[个人博客搭建完成，就算在互联网的世界里安了一个家。从阿里云的万网申请到了域名，我们的家也就有了门牌号。然而，要在茫茫人海中被人发现，仅仅靠口口相传是不够的。我们需要在黄页上登记自己的住址和成员，这样，有缘人才能登门拜访。 百度1.生成sitemap针对百度和谷歌，分别有两种hexo插件，hexo-generator-sitemap是传统的sitemap，可供谷歌使用；hexo-generator-baidu-sitemap则是针对百度。 npm install hexo-generator-sitemap --save-devnpm install hexo-generator-baidu-sitemap --save-dev 安装完成后，重启hexo，执行hexo g后，在public目录下生成对应的xml文件。本地可以通过http://127.0.0.4000/sitemap.xml和 http://127.0.0.4000/baidusitemap.xml访问到sitemap文件。 2.注册百度站长平台有百度账号即可 3.添加个人站点进入站点管理，添加网站，主要障碍在第二步的验证，方式有三：文件、html标签和cname。由于hexo会在生成编译文件的过程中，修改html文件内容，导致百度验证失败，因此，不建议再踩一遍这个坑。 由于域名是我在万网上注册的，所以选择cname的方式。过程如下： 进入万网云解析管理平台； 添加解析&gt;记录类型（CNAME），填写表单，两项必填： 主机：就是他给你的带有自身网站后缀的域名 记录值：ziyuan.baidu.com 4.提交sitemap回到链接提交处，选择自己的站点网址。找到自动提交，选择sitemap，按照提示的格式添加自己的sitemap文件 5.新增蜘蛛协议新建robots.txt文件，添加以下文件内容，把robots.txt放在hexo站点的source文件下。 # hexo robots.txtUser-agent: * Allow: /Allow: /archives/Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: http://dadroid.cn/sitemap.xmlSitemap: http://dadroid.cn/baidusitemap.xml 然后去百度站长平台检测robots文件是否生效。 However挂了好几天，发现百度依然收录不了我的站点，登录平台查看抓取诊断-&gt;抓取一次，错误信息如下： HTTP/1.1 403 ForbiddenCache-Control: no-cacheContent-Type: text/htmlTransfer-Encoding: chunkedAccept-Ranges: bytesDate: Thu, 03 May 2018 05:57:37 GMTVia: 1.1 varnishConnection: closeX-Served-By: cache-hnd18744-HNDX-Cache: MISSX-Cache-Hits: 0X-Timer: S1525327058.780403,VS0,VE113Vary: Accept-EncodingX-Fastly-Request-ID: 7333aaaa3853b41672517dffa1a85e843dcbcdb4 可以看出该错误是拒绝访问，根据百度提供的信息可知 【访问遭拒绝】一般情况下，百度会通过跟踪网页间的链接来查找内容。百度spider必须能够访问某个网页才能抓取该网页。如果您意外地看到了“访问遭拒”错误，可能是由于以下几种原因导致的：（1）百度spider无法访问您网站上的网址，因为您网站上的所有或部分内容要求用户登录后才能查看。（2）您的服务器要求用户使用代理进行身份验证，或者您的托管服务提供商阻止百度spider访问您的网站。 说明我们托管在github pages上的博客禁止百度爬虫的访问。那么我们有什么办法能让百度收录我们的页面呢？ 托管在国内平台，如coding 采用主动/手动提交链接 由于coding绑定自定义域名免费模式会被拦截，显示coding的广告，既影响爬虫抓取站点内容，也影响美观，因此尝试过后便放弃了。下面介绍使用hexo自动提交链接的插件。 前提注册百度站长工具，然后在工具-&gt;网页抓取-&gt;链接提交里找到你的密匙。 hexo-baidu-url-submit首先，在Hexo根目录下，安装本插件：npm install hexo-baidu-url-submit --save 然后，同样在根目录下，把以下内容配置到_config.yml文件中: baidu_url_submit: count: 1 ## 提交最新的一个链接 host: www.hui-wang.info ## 在百度站长平台中注册的域名 token: your_token ## 请注意这是您的秘钥，所以请不要把博客源代码发布在公众仓库里! path: baidu_urls.txt ## 文本文档的地址， 新链接会保存在此文本文档里 其次，记得查看_config.ym文件中url的值， 必须包含是百度站长平台注册的域名（一般有www）， 比如: # URLurl: http://www.dadroid.cnroot: /permalink: 最后，加入新的deployer: deploy:- type: git ## 这是我原来的deployer- type: baidu_url_submitter ## 这是新加的 实现原理 新链接的产生，hexo generate会产生一个文本文件，里面包含最新的链接 新链接的提交，hexo deploy会从上述文件中读取链接，提交至百度搜索引擎 谷歌步骤1——5与百度大同小异，以下介绍一些不同点： 1.注册Google Search Console链接：https://www.google.com/webmasters/ 2.抓取方式完成robost检测后，点击左侧的Google抓取方式。 在这里我们填上我们需要抓取的url，不填这表示抓取首页，抓取方式可以选择桌面，智能手机，自行根据需要选择。填好url之后，点击抓取。然后可能会出现几种情况，如:完成、部分完成、重定向等，自由这三种情况是可以提交的。 提交完成后，提交至索引，根据提示操作就可以了 hexo优化修改文章链接Hexo默认的文章链接形式是一个四级url——domain/year/month/day/postname，可能造成url过长，对搜索引擎是十分不友好。我们可以改成domain/postname的形式，编辑站点_config.yml文件，修改permalink字段改为permalink: :title.html即可。 keywords 和 description在hexo工程根目录下的\scaffolds\post.md中添加如下代码，用于生成的文章中添加关键字和描述。 keywords:description: 给出站链接添加 “nofollow” 标签网络爬虫可能在搜索当前页面的所有链接时，跳到别的网站回不来了。因此，需要nofollow标签发挥作用。 nofollow标签是由谷歌领头创新的一个“反垃圾链接”的标签，并被百度、yahoo等各大搜索引擎广泛支持，引用nofollow标签的目的是：用于指示搜索引擎不要追踪（即抓取）网页上带有nofollow属性的任何出站链接，以减少垃圾链接的分散网站权重。 Hexo的Next主题需要改以下几个地方： 找到footer.swig，路径在your-hexo-site\themes\next\layout\_partials，将下面代码中的a标签加上rel=&quot;external nofollow&quot;属性； &#123;&#123; __(&apos;footer.powered&apos;, &apos;&lt;a class=&quot;theme-link&quot; href=&quot;http://hexo.io&quot;&gt;Hexo&lt;/a&gt;&apos;) &#125;&#125; &lt;a class=&quot;theme-link&quot; href=&quot;https://github.com/iissnan/hexo-theme-next&quot;&gt; 修改sidebar.swig文件，路径在your-hexo-site\themes\next\layout_macro，将下面代码中的a标签加上rel=&quot;external nofollow&quot;属性； &lt;a href=&quot;&#123;&#123; link &#125;&#125;&quot; target=&quot;_blank&quot;&gt;&#123;&#123; name &#125;&#125;&lt;/a&gt; &lt;a href=&quot;http://creativecommons.org/licenses/&#123;&#123; theme.creative_commons &#125;&#125;/4.0&quot; class=&quot;cc-opacity&quot; target=&quot;_blank&quot;&gt; 首页title的优化更改index.swig文件，文件路径是your-hexo-site\themes\next\layout，将下面代码：&#123;% block title %&#125; &#123;&#123; config.title &#125;&#125; &#123;% endblock %&#125; 改为：&#123;% block title %&#125; &#123;&#123; config.title &#125;&#125; - &#123;&#123; theme.description &#125;&#125; &#123;% endblock %&#125;]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>SEO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Quartz：基本用法总结]]></title>
    <url>%2Fposts%2Ff6df2318%2F</url>
    <content type="text"><![CDATA[OpenSymphony所提供的Quartz是任务调度领域享誉盛名的开源框架。Spring提供了集成Quartz的功能，可以让开发人员以更面向Spring的方式创建基于Quartz的任务调度应用。任务调度本身设计多线程并发、运行时间规则制定及解析、运行现场保持与恢复、线程池维护等诸多方面的工作。如果以自定义线程池的原始方法开发，难点很大。 1.普通JAVA任务启动基本的Quartz任务包含一下流程： 创建任务类：实现Job接口的void execute(JobExecutionContext context)方法，定义被执行任务的执行逻辑； 生成JobDetail对象：通过加载任务类（不是实例）来绑定任务逻辑与任务信息； 生成Trigger对象：定时器的触发时间有两种方式可以定义，分别是CronSchedule和simpleSchedule()。前者使用正则表达式，后者则是简单封装后的定时器。 获取Scheduler对象：通过StdSchedulerFactory工厂方法初始化scheduler对象，把任务和定时器绑定在一起，并启动任务。 完整实例代码import org.quartz.*;import org.quartz.impl.StdSchedulerFactory;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.Date;public class RAMQuartz &#123; private static Logger logger = LoggerFactory.getLogger(RAMQuartz.class); public static void main(String[] args) throws SchedulerException &#123; //创建scheduler SchedulerFactory sf = new StdSchedulerFactory(); Scheduler scheduler = sf.getScheduler(); //定义一个JobDetail //定义Job类为RAMJob类，这是真正的执行逻辑所在 JobDetail jb = JobBuilder.newJob(RAMJob1.class) .withDescription("this is a ram job") .withIdentity("ramJob", "ramGroup")//定义name/group .build(); //通过JobDataMap传递参数 jb.getJobDataMap().put("Test", "This is test parameter value"); long time = System.currentTimeMillis() + 3*1000L; Date startTime = new Date(time); //定义一个Trigger Trigger trigger = TriggerBuilder.newTrigger() .withDescription("") .withIdentity("ramTrigger", "ramTriggerGroup")//定义name/group .startAt(startTime)//加入scheduler后，在指定时间启动 //使用CronTrigger .withSchedule(CronScheduleBuilder.cronSchedule("0/2 * * * * ?")) .build(); //绑定任务和定时器到调度器 scheduler.scheduleJob(jb,trigger); //启动 scheduler.start(); logger.info("启动时间 ： " + new Date()); &#125;&#125; import org.quartz.Job;import org.quartz.JobDataMap;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import java.util.Date;public class RAMJob1 implements Job&#123; private static Logger logger = LoggerFactory.getLogger(RAMJob.class); @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; try &#123; JobDataMap dataMap = jobExecutionContext.getJobDetail().getJobDataMap(); String str = dataMap.getString("Test"); logger.info("Quartz dataMap : " + new Date() + "\n" + str); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.对象注入在Spring的WEB应用中使用定时器，通常都会用到spring的特性——对象注入。前面的代码虽然能够很好地执行简单的定时器任务，但是遇到复杂的执行逻辑（如数据库读写等），就不能应付了。 下面代码可以看出，任务2需要执行myBatis的数据库插入语句： public class RAMJob2 implements Job&#123; @Autowired private TestQuartzMapper testQuartzMapper; private static Logger logger = LoggerFactory.getLogger(RAMJob.class); @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; try &#123; testQuartzMapper.insertSelective(testQuartz); logger.info("Insert MyBatis Success!"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 执行这个业务逻辑，就不得不注入对象。如果仍然延用上面的方法，我们会发现执行的时候，testQuartzMapper的对象为null，结果自然毫无悬念地不断报错。 如何为我们的定时器注入Spring的对象，下面介绍一下思路： 自定义JobFactory工厂方法，扩展AdaptableJobFactory，重写其createJobInstance方法； 声明SchedulerFactoryBean，传入自定义的JobFactory工厂方法； 通过新的SchedulerFactoryBean获取scheduler实例，用注入的方式在需要的地方使用。 完整示例import org.quartz.spi.TriggerFiredBundle;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.config.AutowireCapableBeanFactory;import org.springframework.scheduling.quartz.AdaptableJobFactory;import org.springframework.stereotype.Component;@Componentpublic class MyJobFactory extends AdaptableJobFactory &#123; @Autowired private AutowireCapableBeanFactory capableBeanFactory; @Override protected Object createJobInstance(TriggerFiredBundle bundle) throws Exception &#123; // 调用父类的方法 Object jobInstance = super.createJobInstance(bundle); // 进行注入 capableBeanFactory.autowireBean(jobInstance); return jobInstance; &#125;&#125; @Configurationpublic class QuartzConfig &#123; @Autowired private MyJobFactory myJobFactory; @Bean public SchedulerFactoryBean schedulerFactoryBean() throws IOException &#123; SchedulerFactoryBean factory = new SchedulerFactoryBean(); // 加载quartz数据源配置 factory.setQuartzProperties(quartzProperties()); // 自定义Job Factory，用于Spring注入 factory.setJobFactory(myJobFactory); return factory; &#125; @Bean public Scheduler scheduler() throws IOException, SchedulerException &#123; Scheduler scheduler = schedulerFactoryBean().getScheduler(); scheduler.start(); return scheduler; &#125;&#125; 3.Spring简单任务Spring对Quartz进行了封装，方便开发者调用。下面以Spring Boot为例，介绍一下简单任务在Spring的执行方式。 任务类定义仔细观察可以发现，与普通Java任务的区别在于使用了@Component和@EnableScheduling的注释，相应的，就不用声明implements Job，以及重写execute方法。这是Spring提供的一种便利。 @Component@EnableSchedulingpublic class SpringJob &#123; @Autowired WriteService writeService; private Logger logger = LoggerFactory.getLogger(this.getClass()); public void myJobBusinessMethod() &#123; this.logger.info("MyFirstExerciseJob哇被触发了哈哈哈哈哈"); writeService.writeMSG("张三"); &#125;&#125; 配置JobDetail和Trigger的BeanMethodInvokingJobDetailFactoryBean是Spring提供的JobDetail工厂方法，使用它可以快速地定义JobDetail。然而，缺点是生成的任务无法持久化保存，也就是说，无法管理任务的启动、暂停、恢复、停止等操作。CronTriggerFactoryBean为表达式型触发器。 @Configurationpublic class QuartzJobConfig &#123; /** * 方法调用任务明细工厂Bean */ @Bean(name = "SpringJobBean") public MethodInvokingJobDetailFactoryBean myFirstExerciseJobBean(SpringJob springJob) &#123; MethodInvokingJobDetailFactoryBean jobDetail = new MethodInvokingJobDetailFactoryBean(); jobDetail.setConcurrent(false); // 是否并发 jobDetail.setName("general-springJob"); // 任务的名字 jobDetail.setGroup("general"); // 任务的分组 jobDetail.setTargetObject(springJob); // 被执行的对象 jobDetail.setTargetMethod("myJobBusinessMethod"); // 被执行的方法 return jobDetail; &#125; /** * 表达式触发器工厂Bean */ @Bean(name = "SpringJobTrigger") public CronTriggerFactoryBean myFirstExerciseJobTrigger(@Qualifier("SpringJobBean") MethodInvokingJobDetailFactoryBean springJobBean) &#123; CronTriggerFactoryBean tigger = new CronTriggerFactoryBean(); tigger.setJobDetail(springJobBean.getObject()); tigger.setCronExpression("0/10 * * * * ?"); // 什么是否触发，Spring Scheduler Cron表达式 tigger.setName("general-springJobTrigger"); return tigger; &#125;&#125; 调度器下面将任务和触发器注册到调度器 @Configurationpublic class QuartzConfig &#123; /** * 调度器工厂Bean */ @Bean(name = "schedulerFactory") public SchedulerFactoryBean schedulerFactory(@Qualifier("SpringJobTrigger") Trigger springJobTrigger) &#123; SchedulerFactoryBean bean = new SchedulerFactoryBean(); // 覆盖已存在的任务 bean.setOverwriteExistingJobs(true); // 延时启动定时任务，避免系统未完全启动却开始执行定时任务的情况 bean.setStartupDelay(15); // 注册触发器 bean.setTriggers(SpringJobTrigger); return bean; &#125;&#125; 完成上述配置后，启动spring boot就可以出发定时器任务了。而且，仔细观察上面的代码，在执行过程中有WriteService的spring对象注入，而无需我们自己去自定义JobFactory的Spring对象。 4.持久化任务持久化需要用到数据库，而初始化数据库的SQL可以从下载的发布版的文件中找到，比如，我在官网的Download页下载了当前版本的Full Distribution：Quartz 2.2.3 .tar.gz，解压后在quartz-2.2.3\docs\dbTables能找到初始化脚本，因我用的是MySQL的Innodb引擎，所以我用此脚本tables_mysql_innodb.sql。 配置默认情况下，调度器的详情信息会被存储在内存，模式为：RAMJobStore，而且也不需要填写quartz.properties的配置。然而，如果是持久化的模式，那么quartz.properties就必须填写，因为文件中制定了信息存储模式和数据源信息。 # 线程调度器实例名org.quartz.scheduler.instanceName = quartzScheduler# 线程池的线程数，即最多3个任务同时跑org.quartz.threadPool.threadCount = 3# 如何存储任务和触发器等信息org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX# 驱动代理org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate# 表前缀org.quartz.jobStore.tablePrefix = qrtz_ # 数据源org.quartz.jobStore.dataSource = quartzDataSource# 是否集群org.quartz.jobStore.isClustered = false# 数据源# 驱动org.quartz.dataSource.quartzDataSource.driver = com.mysql.cj.jdbc.Driver# 连接URLorg.quartz.dataSource.quartzDataSource.URL = jdbc:mysql://localhost:3306/quartz?characterEncoding=utf-8&amp;useSSL=true&amp;&amp;serverTimezone=Asia/Shanghai# 用户名org.quartz.dataSource.quartzDataSource.user = root# 密码org.quartz.dataSource.quartzDataSource.password = 123456# 最大连接数org.quartz.dataSource.quartzDataSource.maxConnections = 5 其他内容和RAMJobStore模式相同。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>Quartz</tag>
        <tag>持久化</tag>
        <tag>对象注入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA：文件下载]]></title>
    <url>%2Fposts%2Fc0372a48%2F</url>
    <content type="text"><![CDATA[如何通过Java（模拟浏览器）发送HTTP请求，下载文件是WEB应用经常处理的场景。Java有原生的API可用于发送HTTP请求，即：java.net.URL、java.net.URLConnection。这些API本身已经足够好用，但不够简便。所以，也流行有许多Java HTTP请求的framework，如Apache的HttpClient等。 目前项目主要用到Java原生的方式，所以，这里主要介绍此方式。 1.Get请求和Post请求HTTP请求简单分为GET请求和POST请求（详见：Hypertext Transfer Protocol – HTTP/1.1 - Method Definitions）。 使用Java发送这两种请求的代码大同小异，只是一些参数设置的不同。步骤如下： 通过统一资源定位器（java.net.URL）获取连接器（java.net.URLConnection） 设置请求的参数 发送请求 以输入流的形式获取返回内容 关闭输入流 HttpURLConnection继承自URLConnection，常用它下面几个方法： -setRequestMethod：设置URL请求的方法， 如GET、POST、HEAD、OPTIONS、PUT、DELETE、TRACE。其中，GET方法是默认的，可以不写； -setRequestProperty：设置一般请求属性，如”Accept-Charset”、”Content-Type”、”User-Agent”等； -getResponseCode：从HTTP响应消息获取状态码； -getResponseMessage：获取与来自服务器的响应代码一起返回的HTTP响应消息（如果有）。 2.下载文件文件下载请求，本质上也是一个POST请求，因此，流程大体相同。下面的示例正是按照流程顺序进行了处理。如果项目中有多处地方使用HTTP请求，我们可以适当对其进行封装。 封装文件下载器/** * 从网络Url中下载文件 * @param urlStr * @param fileName * @param savePath * @throws IOException */public static void downLoadFromUrl(String urlStr,String fileName,String savePath) throws IOException&#123; URL url = new URL(urlStr); HttpURLConnection conn = (HttpURLConnection)url.openConnection(); //设置超时间为3秒 conn.setConnectTimeout(3*1000); //防止屏蔽程序抓取而返回403错误 conn.setRequestProperty("User-Agent", "Mozilla/4.0 (compatible; MSIE 5.0; Windows NT; DigExt)"); //得到输入流 InputStream inputStream = conn.getInputStream(); //转储文件 saveToLocal(inputStream, savePath, fileName); System.out.println("info:"+url+" download success");&#125; 执行文件转储/** * 文件转储 * @param in * @param fileName * @param savePath * @throws IOException */public static void saveToLocal(InputStream in, String fileName, String savePath) throws IOException &#123; //获取字节流 byte[] getData = readInputStream(in); //父文件夹位置 File saveDir = new File(savePath); if(!saveDir.exists())&#123; saveDir.mkdir(); &#125; File file = new File(saveDir+File.separator+fileName); FileOutputStream fos = new FileOutputStream(file); fos.write(getData); //关闭输入输出流 if(fos!=null)&#123; fos.close(); &#125; if(in!=null)&#123; in.close(); &#125;&#125; 输入流转字节流/** * 从输入流中获取字节数组 * @param inputStream * @return * @throws IOException */public static byte[] readInputStream(InputStream inputStream) throws IOException &#123; byte[] buffer = new byte[1024]; int len = 0; ByteArrayOutputStream bos = new ByteArrayOutputStream(); while((len = inputStream.read(buffer)) != -1) &#123; bos.write(buffer, 0, len); &#125; bos.close(); return bos.toByteArray();&#125; 参考：如果想学习如何用URLConnection发送Get请求和Post请求，可参考这篇好文：通过java.net.URLConnection发送HTTP请求的方法]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>URLConnection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo：NexT主题优化之路]]></title>
    <url>%2Fposts%2Fdc01d1e2%2F</url>
    <content type="text"><![CDATA[选择了Hexo + Next完成个人博客建站之后，仍然会有很多不足之处。此时，万能的搜索引擎和git社区为我们提供了琳琅满目的解决方案。本文将陆续记录本站采用过的优化措施，以供大家参考。 缩小首页文章列表间距并增加阴影效果在5.1.3版本中，可以直接修改next/source/css/_custom/custom.styl文件，如下： // 主页文章添加阴影效果.posts-expand &#123; .post &#123; margin-top: 60px; margin-bottom: 20px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5); &#125;&#125; 增加标签步骤一你需要在hexo根目录的source文件夹下新建一个tags文件夹，然后在tags文件夹里面新建一个index.md文件。快捷命令为： hexo new page "tags" 步骤二编辑source/tags/index.md文件，内容如下： ---title: &quot;tags&quot;type: tagslayout: &quot;tags&quot;comments: false--- title标题不重要，自定义。comments为false，可以关闭本页的评论功能。 步骤三编辑主题配置文件 nav: home: / about: /about tags: /tags 步骤四文章中多个标签的添加方式如下： tags: - tag1 - tag2 或者 tags: [tag1, tag2] 增加分类方法同上，区别是: tags换成categories; 分类只能有一个。 文章中增加categories: xxx。 添加站内搜索安装插件支持站内搜索需要hexo-generator-search和hexo-generator-searchdb两个插件，在站点的根目录下执行以下命令： npm install hexo-generator-search --savenpm install hexo-generator-searchdb --save 启用搜索第一步：在hexo的_config.yml配置文件增加如下内容： search: path: search.xml field: post format: html limit: 10000 第二步：在NexT的_config.yml配置文件修改如下内容： local_search: enable: true 修改Pisces主题内容区宽度默认的宽度觉得有点窄，想改宽一点，可以在source/css/_schemes/Picses/_layout.styl文件末尾添加如下代码: /*扩展宽度*/header&#123; width: 80% !important; &#125;header.post-header &#123; width: auto !important;&#125;.container .main-inner &#123; width: 80%; &#125;.content-wrap &#123; width: calc(100% - 260px); &#125;.header &#123; +tablet() &#123; width: auto !important; &#125; +mobile() &#123; width: auto !important; &#125;&#125;.container .main-inner &#123; +tablet() &#123; width: auto !important; &#125; +mobile() &#123; width: auto !important; &#125;&#125;.content-wrap &#123; +tablet() &#123; width: 100% !important; &#125; +mobile() &#123; width: 100% !important; &#125;&#125; 去掉图片默认的边框将Next主题/themes/next/source/css/_common/components/post/post-expand.styl文件中的img的border的值修改为none //将border的值修改为none即可去掉边框，默认值为 1px solid $gray-lighter img &#123; box-sizing: border-box; margin: auto; padding: 3px; border: none; &#125; 持久化链接优化写的文章复制到微信中链接被分开了，无法直接点击链接访问。看了其他人的博客，大多数是转换为英文的，也没说实现方法。看到一个abbrlink的方法，使用解决了这一问题。 安装abbr-link插件npm install hexo-abbrlink --save 配置博客站点文件permalink: posts/:abbrlink/# abbrlink configabbrlink: alg: crc32 #support crc16(default) and crc32 rep: hex #support dec(default) and hex 部署执行hexo clean和hexo s，使得配置生效]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
        <tag>tags</tag>
        <tag>文章阴影</tag>
        <tag>文章列表间距</tag>
        <tag>搜索，Pisces</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[足迹：龙门古镇]]></title>
    <url>%2Fposts%2F7fc1a8e1%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[足迹：六和塔]]></title>
    <url>%2Fposts%2F55828a88%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[足迹：九溪十八涧]]></title>
    <url>%2Fposts%2Fcaeb5da5%2F</url>
    <content type="text"><![CDATA[2017-04-03清明假期第二天，天气晴好，阳光明媚。 老婆刚刚确认怀孕，岳母也是大病初愈。一家人也算是一扫16年的阴霾，心情大好地出门去近郊踏青。 从九溪公交车站往里走，人是越来越多，但是风景更是越来越好。初入景区，左边是湍流的溪水，右边是漫山的茶园。耳边响起的是溪涧奔流的叮咚声，鼻子嗅到的是明前龙井的清新，更有游人的欢声笑语和采茶女穿梭山间茶园倩影。眼前的风景，让人不禁赞叹春光无限好。 到达九溪烟树的石碑，是一路美丽风光的顶峰。图一的照片正是九溪风景的名片。我认为秋天才是九溪烟树最美的季节，不同的植被在这个季节会披上不同的颜色，有红的似火的枫叶，有金黄的梧桐，有万年长青的香樟，连溪水的颜色都会不同。恰似倒翻了的颜料盘，在大自然打开了五彩斑斓的画卷。想不到的是春天的景观也不逊色，虽不是暖色调为主，但是嫩绿、翠绿、深绿，层次分明，错落有致的绿色，让我们感受到沁人心脾的清新自然，心旷神怡。 图二是我和丈母娘看到有人在那里拍婚纱照，料定必有美景，便一同前往。碧玉般的湖水和青山，在红绿相间的枝叶半遮半掩之下，绘制出一番犹抱琵琶半遮面的羞涩意境，更惹人喜爱。连累得在九曲桥上休息的老婆和丈人，看了我手机拍下的照片，也想重新启程，亲览美景。 图三则是在返程的路上，路过一步长的小桥拍下的。九溪的美正如这张照片，不经意之间的一瞥，邂逅的可能就是百看不厌的传世画卷。]]></content>
      <categories>
        <category>足迹</category>
      </categories>
      <tags>
        <tag>九溪十八涧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[足迹：湘湖]]></title>
    <url>%2Fposts%2F2500110d%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[足迹：白马湖]]></title>
    <url>%2Fposts%2F58ecbb5a%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[足迹：千岛湖]]></title>
    <url>%2Fposts%2F20a3881c%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[足迹：乌镇]]></title>
    <url>%2Fposts%2F5f961822%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[足迹：迪士尼]]></title>
    <url>%2Fposts%2Fb2af91bf%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
</search>
