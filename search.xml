<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Nginx-平滑升级]]></title>
    <url>%2Fposts%2F6ea553c6%2F</url>
    <content type="text"><![CDATA[概述当面临新的需求，需要安装新的模块；或者遇到安全检查，需要安装安全补丁；甚至为了更新到最新版本的Nginx，我们如何能保证现有业务不中断，平滑地升级Nginx成了很有必要的课题。 平滑升级原理多进程模式下的请求分配方式Nginx默认工作在多进程模式下，即主进程（master process）启动后完成配置加载和端口绑定等动作，fork出指定数量的工作进程（worker process），这些子进程会持有监听端口的文件描述符（fd），并通过在该描述符上添加监听事件来接受连接（accept）。 信号的接收和处理Nginx主进程在启动完成后会进入等待状态，负责响应各类系统消息，如SIGCHLD、SIGHUP、SIGUSR2等。 Nginx信号简介主进程支持的信号 TERM, INT: 立刻退出 QUIT: 等待工作进程结束后再退出 KILL: 强制终止进程 HUP: 重新加载配置文件，使用新的配置启动工作进程，并逐步关闭旧进程。 USR1: 重新打开日志文件 USR2: 启动新的主进程，实现热升级 WINCH: 逐步关闭工作进程 工作进程支持的信号 TERM, INT: 立刻退出 QUIT: 等待请求处理结束后再退出 USR1: 重新打开日志文件 平滑升级实战备份原Nginx二进制文件将Nginx的安装目录整体备份 [root@zzz ~]# cp /usr/local/nginx/ /usr/local/nginx_$(date +%F) 编译新的nginx源码包编译新Nginx源码，安装路径需与旧版一致 [root@zzz nginx-1.15.7]# ./configure --prefix=/usr/local/nginx[root@zzz nginx-1.15.7]# make&amp;make install 发送USR2信号向主进程发送USR2信号，Nginx会启动一个新版本的master进程和工作进程，和旧版一起处理请求 [root@zzz ~]# ps -ef|grep nginx##打印内容root 3669 1 0 12月19 ? 00:00:00 nginx: master process ./sbin/nginx -c ./conf/nginx.confroot 3670 3669 0 12月19 ? 00:00:01 nginx: worker processroot 3671 3669 0 12月19 ? 00:00:00 nginx: worker processroot 3672 3669 0 12月19 ? 00:00:01 nginx: worker processroot 3673 3669 0 12月19 ? 00:00:02 nginx: worker process[root@zzz ~]# kill -USR2 3669 发送WITCH信号向原Nginx主进程发送WINCH信号，它会逐步关闭旗下的工作进程（主进程不退出），这时所有请求都会由新版Nginx处理 [root@zzz ~]# kill -WITCH 3669 但是，我尝试关闭原来的Nginx进程却无法关闭，于是，用了QUIT 命令 [root@zzz ~]# kill -QUIT 3669 发送HUP信号如果这时需要回退，可向原Nginx主进程发送HUP信号，它会重新启动工作进程， 仍使用旧版配置文件 。然后可以将新版Nginx进程杀死（使用QUIT、TERM、或者KILL） [root@zzz ~]# kill -HUP 3669 注：此步骤只需在回滚的时候执行即可 升级完毕如果不需要回滚，可以将原Nginx主进程杀死（使用QUIT、TERM、或者KILL），至此完成热升级。]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>平滑升级</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring-Jasypt加密配置文件]]></title>
    <url>%2Fposts%2Fd39f004c%2F</url>
    <content type="text"><![CDATA[在开发WEB项目的时候，会使用到很多中间件，比如数据库、redis、消息队列等等，或者涉及敏感信息，如邮箱等账号信息。如果采用明文方式保存在配置文件或者代码中，会产生很大风险。因此，如何加密这些信息将是一个很有用的话题。 本文采用Jasypt对基于Spring Boot的项目进行加密。Jasypt默认使用DES对文本信息进行加密，通过适当的配置，可以重载配置文件的载入过程，实现自动解密的功能。 引入 Maven 依赖&lt;dependency&gt; &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt; &lt;artifactId&gt;jasypt-spring-boot&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; 定义加密盐在application.properties配置文件中增加如下内容（加解密时使用） jasypt.encryptor.password=secret!@#$ 生成密钥可以在main函数或者测试类中，使用StringEncryptor生成密钥。 @RunWith(SpringRunner.class)@SpringBootTest@WebAppConfigurationpublic class EncryptorTest &#123; @Autowired StringEncryptor encryptor; @Test public void getPass() &#123; System.out.print("Password\n"); String p = encryptor.encrypt("Password"); System.out.print(p+"\n"); &#125;&#125; 替换原来的文本用上面生成的加密后的字符，替换配置文件中对应的密码，替换后如下： #spring.datasource.password=Passwordspring.datasource.password=ENC(UBtTQGk1xbdmhff+UUoT6g==) 只有符合格式才能自动处理，注意格式为：ENC(密钥) FQ如果在调用StringEncryptor类的时候，警告不存在该类的话，可以在入口函数增加@EnableEncryptableProperties注释 @SpringBootApplication@EnableEncryptablePropertiespublic class MyWebApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MyWebApplication.class, args); &#125;&#125; 参考Jasypt项目的 GitHub 地址]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Jasypt</tag>
        <tag>DES</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring-Application.properties用法]]></title>
    <url>%2Fposts%2F3a9e5616%2F</url>
    <content type="text"><![CDATA[参数间引用在application.properties中的各个参数之间也可以直接引用来使用，就像下面的设置： com.name=&quot;张三&quot;com.id=&quot;8&quot;com.psrInfo=$&#123;com.name&#125;编号为$&#123;com.id&#125; 这样我们就可以只是用psrInfo这个属性就好]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Appium-环境部署]]></title>
    <url>%2Fposts%2F42fc8a9%2F</url>
    <content type="text"><![CDATA[安装Java jdk1.8搭建环境：Ubuntu 16.04 x64JDK :jdk-8u171-linux-x64.tar.gz 下载linux对应的安装包下载地址：http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html 解压安装包jdk-8u171-linux-x64.tar.gztar -zxvf jdk-8u171-linux-x64.tar.gz 转移目录到 /usr/lib 目录下cd /usr/libsudo mkdir jdksudo mv ~/jdk1.8.0_171/ usr/lib/jdk 配置java环境变量sudo vi /etc/bash.bashrc 在末尾加以下几行文字： #set java envexport JAVA_HOME=/usr/lib/jdk/jdk1.8.0_171export JRE_HOME=$&#123;JAVA_HOME&#125;/jre export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH 执行命令使修改立即生效 source /etc/profile 测试安装是否成功在终端输入，出现版本号则表示安装成功 java -version 安装 Android SDK依赖安装Android SDK中的adb程序是32位的，Ubuntu x64系统需要安装32位库文件，用于兼容32位的程序。如果不安装，adb会出错：java.io.IOException: error=2输入下面命令，安装库文件（国内需先换源） sudo apt-get install -y libc6-i386 lib32stdc++6 lib32gcc1 lib32ncurses5 lib32z1 下载 SDK Tools地址：http://www.androiddevtools.cn/在AndroidDevTools中下载SDK Tools，在Downloads文件夹下找到下载的文件，并将android-linux-sdk移动到/opt/目录下： sudo mv /Download/android-sdk-linux /opt/ 配置Android SDK 环境变量sudo vi /etc/bash.bashrc 在末尾增加如下内容： export ANDROID_SDK_HOME=/opt/android-sdk-linuxexport PATH=$PATH:$&#123;ANDROID_SDK_HOME&#125;/toolsexport PATH=$PATH:$&#123;ANDROID_SDK_HOME&#125;/platform-tools 踩坑 Appium执行过程中，执行adb shell 命令，导致appium测试中断：原因：linux使用yum和直接拷贝Android SDK的方式，在使用adb的时候会导致appium和系统adb分别使用两个不同文件的情况，导致端口占用。删掉一个可以解决。]]></content>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ:配置SSL安全访问]]></title>
    <url>%2Fposts%2F348c654f%2F</url>
    <content type="text"><![CDATA[一、生成 SSL 证书SSL(Secure Sockets Layer 安全套接层)，及其继任者传输层安全（Transport Layer Security，TLS）是为网络通信提供安全及数据完整性的一种安全协议。TLS与SSL在传输层对网络连接进行加密，一般可分为单向认证和双向认证。RabbitMQ 采用的是双向认证方式。 1.创建目录# mkdir testca# cd testca# mkdir certs private# chmod 700 private# echo 01 &gt; serial# touch index.txt 2.在该目录下，生成openssl.cnf文件，内容如下：[ ca ]default_ca = testca[ testca ]dir = .certificate = $dir/cacert.pemdatabase = $dir/index.txtnew_certs_dir = $dir/certsprivate_key = $dir/private/cakey.pemserial = $dir/serialdefault_crl_days = 7default_days = 365default_md = sha256policy = testca_policyx509_extensions = certificate_extensions[ testca_policy ]commonName = suppliedstateOrProvinceName = optionalcountryName = optionalemailAddress = optionalorganizationName = optionalorganizationalUnitName = optionaldomainComponent = optional[ certificate_extensions ]basicConstraints = CA:false[ req ]default_bits = 2048default_keyfile = ./private/cakey.pemdefault_md = sha256prompt = yesdistinguished_name = root_ca_distinguished_namex509_extensions = root_ca_extensions[ root_ca_distinguished_name ]commonName = hostname[ root_ca_extensions ]basicConstraints = CA:truekeyUsage = keyCertSign, cRLSign[ client_ca_extensions ]basicConstraints = CA:falsekeyUsage = digitalSignatureextendedKeyUsage = 1.3.6.1.5.5.7.3.2[ server_ca_extensions ]basicConstraints = CA:falsekeyUsage = keyEnciphermentextendedKeyUsage = 1.3.6.1.5.5.7.3.1 3.颁发自己的 CA 证书# openssl req -x509 -config openssl.cnf -newkey rsa:2048 -days 365 -out cacert.pem -outform PEM -subj /CN=MyTestCA/ -nodes# openssl x509 -in cacert.pem -out cacert.cer -outform DER 4.生成服务器证书# cd ..# lstestca# mkdir server# cd server# openssl genrsa -out key.pem 2048# openssl req -new -key key.pem -out req.pem -outform PEM -subj /CN=$(hostname)/O=server/ -nodes# cd ../testca# openssl ca -config openssl.cnf -in ../server/req.pem -out ../server/cert.pem -notext -batch -extensions server_ca_extensions# cd ../server# openssl pkcs12 -export -out keycert.p12 -in cert.pem -inkey key.pem -passout pass:MySecretPassword 5.生成客户端证书# cd ..# lsserver testca# mkdir client# cd client# openssl genrsa -out key.pem 2048# openssl req -new -key key.pem -out req.pem -outform PEM -subj /CN=$(hostname)/O=client/ -nodes# cd ../testca# openssl ca -config openssl.cnf -in ../client/req.pem -out ../client/cert.pem -notext -batch -extensions client_ca_extensions# cd ../client# openssl pkcs12 -export -out keycert.p12 -in cert.pem -inkey key.pem -passout pass:MySecretPassword 后续需要要使用的文件分别是：testca/cacert.pem、server/cert.pem、server/key.pem、client/cert.pem、client/key.pem、client/keycert.p12 6.番外此外，生成证书的过程也有git上的大神写好的shell脚本可以使用，项目地址为：https://github.com/Berico-Technologies/CMF-AMQP-Configuration 可直接通过git命令进行clone到本地（最好新建个文件夹AMQPSSL）： git clone https://github.com/Berico-Technologies/CMF-AMQP-Configuration.git 在clone后的项目目录中，doc文件夹下有详细的说明shell脚本如何使用。 确保已经安装好了openssl，具体安装方法请自行google； 切换到 CMF-AMQP-Configuration/ssl 文件夹，运行 sh setup_ca.sh MyRabbitMQCA 名称定义为”MyRabbitMQCA”，这个名字可以自行指定，用于在证书中显示证书颁发机构名。 生成服务器证书 sh make_server_cert.sh rabbitmq-server rabbit 一个参数是服务器名，第二个参数是密码。 生成客户端证书 sh create_client_cert.sh rabbit-client rabbit 第一个参数是客户端名称，第二个参数是密码。 执行完以上步骤之后，会在ssl目录下生成：ca、server、client三个文件夹。 二、配置 RabbitMQ 服务器1.配置RabbitMQ环境Mac上RabbitMQ的配置文件通常位于/usr/local/etc/rabbitmq，在该目录下创建rabbitmq.conf和advanced.config两个文件，并修改rabbitmq-env.conf内容如下： CONFIG_FILE=/usr/local/etc/rabbitmq/rabbitmqRABBITMQ_ADVANCED_CONFIG_FILE=//usr/local/etc/rabbitmq/advanced#NODE_IP_ADDRESS=127.0.0.1NODENAME=rabbit@localhost 2.基本配置 rabbitmq.conf 修改listeners.ssl.default=5671 ssl_options.cacertfile=/usr/local/etc/rabbitmq/ca/cacert.pemssl_options.certfile=/usr/local/etc/rabbitmq/ca/cert.pemssl_options.keyfile=/usr/local/etc/rabbitmq/ca/key.pemssl_options.verify=verify_peerssl_options.fail_if_no_peer_cert=false 3.高级配置 advanced.config 修改%% list allowed ciphers[ &#123;ssl, [&#123;versions, [&apos;tlsv1.2&apos;, &apos;tlsv1.1&apos;]&#125;]&#125;, &#123;rabbit, [ &#123;ssl_listeners, [5671]&#125;, &#123;ssl_options, [&#123;cacertfile,&quot;/usr/local/etc/rabbitmq/ca/cacert.pem&quot;&#125;, &#123;certfile, &quot;/usr/local/etc/rabbitmq/ca/cert.pem&quot;&#125;, &#123;keyfile, &quot;/usr/local/etc/rabbitmq/ca/key.pem&quot;&#125;, &#123;versions, [&apos;tlsv1.2&apos;, &apos;tlsv1.1&apos;]&#125;, %% This list is just an example! %% Not all cipher suites are available on all machines. %% Cipher suite order is important: preferred suites %% should be listed first. %% Different suites have different security and CPU load characteristics. &#123;ciphers, [ &#123;ecdhe_ecdsa,aes_256_gcm,null,sha384&#125;, &#123;ecdhe_rsa,aes_256_gcm,null,sha384&#125;, &#123;ecdhe_ecdsa,aes_256_cbc,sha384,sha384&#125;, &#123;ecdhe_rsa,aes_256_cbc,sha384,sha384&#125;, &#123;ecdh_ecdsa,aes_256_gcm,null,sha384&#125;, &#123;ecdh_rsa,aes_256_gcm,null,sha384&#125;, &#123;ecdh_ecdsa,aes_256_cbc,sha384,sha384&#125;, &#123;ecdh_rsa,aes_256_cbc,sha384,sha384&#125;, &#123;dhe_rsa,aes_256_gcm,null,sha384&#125;, &#123;dhe_dss,aes_256_gcm,null,sha384&#125;, &#123;dhe_rsa,aes_256_cbc,sha256&#125;, &#123;dhe_dss,aes_256_cbc,sha256&#125;, &#123;rsa,aes_256_gcm,null,sha384&#125;, &#123;rsa,aes_256_cbc,sha256&#125;, &#123;ecdhe_ecdsa,aes_128_gcm,null,sha256&#125;, &#123;ecdhe_rsa,aes_128_gcm,null,sha256&#125;, &#123;ecdhe_ecdsa,aes_128_cbc,sha256,sha256&#125;, &#123;ecdhe_rsa,aes_128_cbc,sha256,sha256&#125;, &#123;ecdh_ecdsa,aes_128_gcm,null,sha256&#125;, &#123;ecdh_rsa,aes_128_gcm,null,sha256&#125;, &#123;ecdh_ecdsa,aes_128_cbc,sha256,sha256&#125;, &#123;ecdh_rsa,aes_128_cbc,sha256,sha256&#125;, &#123;dhe_rsa,aes_128_gcm,null,sha256&#125;, &#123;dhe_dss,aes_128_gcm,null,sha256&#125;, &#123;dhe_rsa,aes_128_cbc,sha256&#125;, &#123;ecdh_rsa,aes_128_gcm,null,sha256&#125; ]&#125;, &#123;fail_if_no_peer_cert,true&#125; ]&#125; ]&#125;]. 三、配置 Java 客户端使用JDK自带的keytool工具，可以导入秘钥，进行证书管理。在Java的代码中，通过实例化 Trust Manager实现客户端的认证。 keytool -import -alias server1 -file /path/to/server/certificate.pem -keystore /path/to/rabbitstore 上面的命令将导入server/certificate.pem到rabbitstore，并且与server1关联。keytool在确认证书是否被信任的过程会要求设置密码保护。 下面展示了Java如何使用Key Manager和Trust Manager进行客户端认证。 import java.io.FileInputStream;import java.security.KeyStore;import javax.net.ssl.KeyManagerFactory;import javax.net.ssl.SSLContext;import javax.net.ssl.TrustManagerFactory;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.GetResponse;public class Example2 &#123; public static void main(String[] args) throws Exception &#123; char[] keyPassphrase = &quot;MySecretPassword&quot;.toCharArray(); KeyStore ks = KeyStore.getInstance(&quot;PKCS12&quot;); ks.load(new FileInputStream(Class.class.getResource(&quot;/&quot;).getPath() + &quot;keycert.p12&quot;), keyPassphrase); KeyManagerFactory kmf = KeyManagerFactory.getInstance(&quot;SunX509&quot;); kmf.init(ks, keyPassphrase); char[] trustPassphrase = &quot;rabbitstore&quot;.toCharArray(); KeyStore tks = KeyStore.getInstance(&quot;JKS&quot;); tks.load(new FileInputStream(Class.class.getResource(&quot;/&quot;).getPath() + &quot;rabbitstore&quot;), trustPassphrase); TrustManagerFactory tmf = TrustManagerFactory.getInstance(&quot;SunX509&quot;); tmf.init(tks); SSLContext c = SSLContext.getInstance(&quot;TLSv1.1&quot;); c.init(kmf.getKeyManagers(), tmf.getTrustManagers(), null); ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;&quot;); factory.setPort(5671); factory.setUsername(&quot;&quot;); factory.setPassword(&quot;&quot;); factory.useSslProtocol(c); Connection conn = factory.newConnection(); Channel channel = conn.createChannel(); channel.queueDeclare(&quot;rabbitmq-java-test&quot;, false, true, true, null); channel.basicPublish(&quot;&quot;, &quot;rabbitmq-java-test&quot;, null, &quot;Hello, World&quot;.getBytes()); GetResponse chResponse = channel.basicGet(&quot;rabbitmq-java-test&quot;, false); if(chResponse == null) &#123; System.out.println(&quot;No message retrieved&quot;); &#125; else &#123; byte[] body = chResponse.getBody(); System.out.println(&quot;Recieved: &quot; + new String(body)); &#125; channel.close(); conn.close(); &#125;&#125; 四、配置有效性检查1.证书有效性校验打开一个终端，输入以下命令启动服务端： openssl s_server -accept 8443 -cert server/cert.pem -key server/key.pem -CAfile testca/cacert.pem 在另外一个终端，输入以下命令启动客户端： openssl s_client -connect localhost:8443 -cert client/cert.pem -key client/key.pem -CAfile testca/cacert.pem 如果生产的证书是有效的，将会在客户端返回连接成功的消息，结尾如下所示： Verify return code: 0 (ok) 2.验证RabbitMQ配置有效性查看日志 在RabbitMQ启动的控制台，可以看到日志的位置如下： Logs: /usr/local/var/log/rabbitmq/rabbit@localhost.log /usr/local/var/log/rabbitmq/rabbit@localhost_upgrade.log 查看日志的内容，可以看到如下内容，说明TLS配置已经生效： started SSL Listener on [::]:5671 手动建立openssl连接 openssl s_client -connect localhost:5671 -cert client/cert.pem -key client/key.pem -CAfile testca/cacert.pem 如果连接成功，会看到和前面8443端口连接相同的结束信息，并且会在RabbitMQ的日志中查看到如下消息： accepting AMQP connection &lt;0.223.0&gt; (127.0.0.1:58954 -&gt; 127.0.0.1:5671) 五、异常处理1.客户端证书密码错误如果在Java客户端中，导入keycert.p12证书的密码设置错误，控制台会返回如下异常。 java.io.IOException: failed to decrypt safe contents entry: javax.crypto.BadPaddingException: Given final block not properly padded 2.客户端和服务器的加密套协商失败使用openssl或者Java客户端进行远程连接时，会使用openssl或者JDK的加密套，但是，RabbitMQ的服务端中，默认的加密套（cipher suite）不一定会有与之一致的加密算法，这将在握手阶段就发生协商加密套失败，客户端的错误返回如下： javax.net.ssl.SSLHandshakeException: Received fatal alert: insufficient_security 查看RabbitMQ的日志，可以看到详细的错误如下： TLS server: In state hello at tls_handshake.erl:197 generated SERVER ALERT: Fatal - Insufficient Security - no_suitable_ciphers 可以知道是握手阶段的加密套协商失败，因此，可以通过wireshark抓包，查看客户端发出请求所包含的加密套。我的Java客户端加密套如下所示： 从图中，可以看到OpenSSL定义的加密套名称，我选择其中的一个，在github上找到对应的Erlang名称，添加到RabbitMQ的advance.config中，重启服务之后，就能够完成握手了。 参考映射表：https://github.com/rabbitmq/rabbitmq-website/issues/453加密套概念：https://blog.helong.info/blog/2015/01/23/ssl_tls_ciphersuite_intro/加密协议：https://www.iana.org/assignments/tls-parameters/tls-parameters.xhtml#tls-parameters-4openssl配置说明：http://www.jinbuguo.com/linux/openssl_install.html]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
        <tag>AMQP</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ:SSL加密套映射表]]></title>
    <url>%2Fposts%2Fbcc0ef8%2F</url>
    <content type="text"><![CDATA[关于加密套中，OpenSSL、IANA和Erlang的映射关系 OpenSSL IANA Erlang TLS_PSK_WITH_NULL_SHA PSK-NULL-SHA {psk, null, sha, default_prf} TLS_DHE_PSK_WITH_NULL_SHA DHE-PSK-NULL-SHA {dhe_psk, null, sha, default_prf} TLS_RSA_PSK_WITH_NULL_SHA RSA-PSK-NULL-SHA {rsa_psk, null, sha, default_prf} TLS_RSA_WITH_AES_128_CBC_SHA AES128-SHA {rsa, aes_128_cbc, sha, default_prf} TLS_DHE_DSS_WITH_AES_128_CBC_SHA DHE-DSS-AES128-SHA {dhe_dss, aes_128_cbc, sha, default_prf} TLS_DHE_RSA_WITH_AES_128_CBC_SHA DHE-RSA-AES128-SHA {dhe_rsa, aes_128_cbc, sha, default_prf} TLS_DH_anon_WITH_AES_128_CBC_SHA ADH-AES128-SHA {dh_anon, aes_128_cbc, sha, default_prf} TLS_RSA_WITH_AES_256_CBC_SHA AES256-SHA {rsa, aes_256_cbc, sha, default_prf} TLS_DHE_DSS_WITH_AES_256_CBC_SHA DHE-DSS-AES256-SHA {dhe_dss, aes_256_cbc, sha, default_prf} TLS_DHE_RSA_WITH_AES_256_CBC_SHA DHE-RSA-AES256-SHA {dhe_rsa, aes_256_cbc, sha, default_prf} TLS_DH_anon_WITH_AES_256_CBC_SHA ADH-AES256-SHA {dh_anon, aes_256_cbc, sha, default_prf} TLS_RSA_WITH_AES_128_CBC_SHA256 AES128-SHA256 {rsa, aes_128_cbc, sha256, default_prf} TLS_RSA_WITH_AES_256_CBC_SHA256 AES256-SHA256 {rsa, aes_256_cbc, sha256, default_prf} TLS_DHE_DSS_WITH_AES_128_CBC_SHA256 DHE-DSS-AES128-SHA256 {dhe_dss, aes_128_cbc, sha256, default_prf} TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 DHE-RSA-AES128-SHA256 {dhe_rsa, aes_128_cbc, sha256, default_prf} TLS_DHE_DSS_WITH_AES_256_CBC_SHA256 DHE-DSS-AES256-SHA256 {dhe_dss, aes_256_cbc, sha256, default_prf} TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 DHE-RSA-AES256-SHA256 {dhe_rsa, aes_256_cbc, sha256, default_prf} TLS_DH_anon_WITH_AES_128_CBC_SHA256 ADH-AES128-SHA256 {dh_anon, aes_128_cbc, sha256, default_prf} TLS_DH_anon_WITH_AES_256_CBC_SHA256 ADH-AES256-SHA256 {dh_anon, aes_256_cbc, sha256, default_prf} TLS_PSK_WITH_RC4_128_SHA PSK-RC4-SHA {psk, rc4_128, sha, default_prf} TLS_PSK_WITH_3DES_EDE_CBC_SHA PSK-3DES-EDE-CBC-SHA {psk, ‘3des_ede_cbc’, sha, default_prf} TLS_PSK_WITH_AES_128_CBC_SHA PSK-AES128-CBC-SHA {psk, aes_128_cbc, sha, default_prf} TLS_PSK_WITH_AES_256_CBC_SHA PSK-AES256-CBC-SHA {psk, aes_256_cbc, sha, default_prf} TLS_DHE_PSK_WITH_RC4_128_SHA DHE-PSK-RC4-SHA {dhe_psk, rc4_128, sha, default_prf} TLS_DHE_PSK_WITH_3DES_EDE_CBC_SHA DHE-PSK-3DES-EDE-CBC-SHA {dhe_psk, ‘3des_ede_cbc’, sha, default_prf} TLS_DHE_PSK_WITH_AES_128_CBC_SHA DHE-PSK-AES128-CBC-SHA {dhe_psk, aes_128_cbc, sha, default_prf} TLS_DHE_PSK_WITH_AES_256_CBC_SHA DHE-PSK-AES256-CBC-SHA {dhe_psk, aes_256_cbc, sha, default_prf} TLS_RSA_PSK_WITH_RC4_128_SHA RSA-PSK-RC4-SHA {rsa_psk, rc4_128, sha, default_prf} TLS_RSA_PSK_WITH_3DES_EDE_CBC_SHA RSA-PSK-3DES-EDE-CBC-SHA {rsa_psk, ‘3des_ede_cbc’, sha, default_prf} TLS_RSA_PSK_WITH_AES_128_CBC_SHA RSA-PSK-AES128-CBC-SHA {rsa_psk, aes_128_cbc, sha, default_prf} TLS_RSA_PSK_WITH_AES_256_CBC_SHA RSA-PSK-AES256-CBC-SHA {rsa_psk, aes_256_cbc, sha, default_prf} TLS_RSA_WITH_AES_128_GCM_SHA256 AES128-GCM-SHA256 {rsa, aes_128_gcm, null, sha256} TLS_RSA_WITH_AES_256_GCM_SHA384 AES256-GCM-SHA384 {rsa, aes_256_gcm, null, sha384} TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 DHE-RSA-AES128-GCM-SHA256 {dhe_rsa, aes_128_gcm, null, sha256} TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 DHE-RSA-AES256-GCM-SHA384 {dhe_rsa, aes_256_gcm, null, sha384} TLS_DH_RSA_WITH_AES_128_GCM_SHA256 DH-RSA-AES128-GCM-SHA256 {dh_rsa, aes_128_gcm, null, sha256} TLS_DH_RSA_WITH_AES_256_GCM_SHA384 DH-RSA-AES256-GCM-SHA384 {dh_rsa, aes_256_gcm, null, sha384} TLS_DHE_DSS_WITH_AES_128_GCM_SHA256 DHE-DSS-AES128-GCM-SHA256 {dhe_dss, aes_128_gcm, null, sha256} TLS_DHE_DSS_WITH_AES_256_GCM_SHA384 DHE-DSS-AES256-GCM-SHA384 {dhe_dss, aes_256_gcm, null, sha384} TLS_DH_DSS_WITH_AES_128_GCM_SHA256 DH-DSS-AES128-GCM-SHA256 {dh_dss, aes_128_gcm, null, sha256} TLS_DH_DSS_WITH_AES_256_GCM_SHA384 DH-DSS-AES256-GCM-SHA384 {dh_dss, aes_256_gcm, null, sha384} TLS_DH_anon_WITH_AES_128_GCM_SHA256 ADH-AES128-GCM-SHA256 {dh_anon, aes_128_gcm, null, sha256} TLS_DH_anon_WITH_AES_256_GCM_SHA384 ADH-AES256-GCM-SHA384 {dh_anon, aes_256_gcm, null, sha384} TLS_PSK_WITH_AES_128_GCM_SHA256 PSK-AES128-GCM-SHA256 {psk, aes_128_gcm, null, sha256} TLS_PSK_WITH_AES_256_GCM_SHA384 PSK-AES256-GCM-SHA384 {psk, aes_256_gcm, null, sha384} TLS_DHE_PSK_WITH_AES_128_GCM_SHA256 DHE-PSK-AES128-GCM-SHA256 {dhe_psk, aes_128_gcm, null, sha256} TLS_DHE_PSK_WITH_AES_256_GCM_SHA384 DHE-PSK-AES256-GCM-SHA384 {dhe_psk, aes_256_gcm, null, sha384} TLS_RSA_PSK_WITH_AES_128_GCM_SHA256 RSA-PSK-AES128-GCM-SHA256 {rsa_psk, aes_128_gcm, null, sha256} TLS_RSA_PSK_WITH_AES_256_GCM_SHA384 RSA-PSK-AES256-GCM-SHA384 {rsa_psk, aes_256_gcm, null, sha384} TLS_PSK_WITH_AES_128_CBC_SHA256 PSK-AES128-CBC-SHA256 {psk, aes_128_cbc, sha256, default_prf} TLS_PSK_WITH_AES_256_CBC_SHA384 PSK-AES256-CBC-SHA384 {psk, aes_256_cbc, sha384, default_prf} TLS_PSK_WITH_NULL_SHA256 PSK-NULL-SHA256 {psk, null, sha256, default_prf} TLS_PSK_WITH_NULL_SHA384 PSK-NULL-SHA384 {psk, null, sha384, default_prf} TLS_DHE_PSK_WITH_AES_128_CBC_SHA256 DHE-PSK-AES128-CBC-SHA256 {dhe_psk, aes_128_cbc, sha256, default_prf} TLS_DHE_PSK_WITH_AES_256_CBC_SHA384 DHE-PSK-AES256-CBC-SHA384 {dhe_psk, aes_256_cbc, sha384, default_prf} TLS_DHE_PSK_WITH_NULL_SHA256 DHE-PSK-NULL-SHA256 {dhe_psk, null, sha256, default_prf} TLS_DHE_PSK_WITH_NULL_SHA384 DHE-PSK-NULL-SHA384 {dhe_psk, null, sha384, default_prf} TLS_RSA_PSK_WITH_AES_128_CBC_SHA256 RSA-PSK-AES128-CBC-SHA256 {rsa_psk, aes_128_cbc, sha256, default_prf} TLS_RSA_PSK_WITH_AES_256_CBC_SHA384 RSA-PSK-AES256-CBC-SHA384 {rsa_psk, aes_256_cbc, sha384, default_prf} TLS_RSA_PSK_WITH_NULL_SHA256 RSA-PSK-NULL-SHA256 {rsa_psk, null, sha256, default_prf} TLS_RSA_PSK_WITH_NULL_SHA384 RSA-PSK-NULL-SHA384 {rsa_psk, null, sha384, default_prf} TLS_ECDH_ECDSA_WITH_NULL_SHA ECDH-ECDSA-NULL-SHA {ecdh_ecdsa, null, sha, default_prf} TLS_ECDH_ECDSA_WITH_RC4_128_SHA ECDH-ECDSA-RC4-SHA {ecdh_ecdsa, rc4_128, sha, default_prf} TLS_ECDH_ECDSA_WITH_3DES_EDE_CBC_SHA ECDH-ECDSA-DES-CBC3-SHA {ecdh_ecdsa, ‘3des_ede_cbc’, sha, default_prf} TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA ECDH-ECDSA-AES128-SHA {ecdh_ecdsa, aes_128_cbc, sha, default_prf} TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA ECDH-ECDSA-AES256-SHA {ecdh_ecdsa, aes_256_cbc, sha, default_prf} TLS_ECDHE_ECDSA_WITH_NULL_SHA ECDHE-ECDSA-NULL-SHA {ecdhe_ecdsa, null, sha, default_prf} TLS_ECDHE_ECDSA_WITH_RC4_128_SHA ECDHE-ECDSA-RC4-SHA {ecdhe_ecdsa, rc4_128, sha, default_prf} TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA ECDHE-ECDSA-DES-CBC3-SHA {ecdhe_ecdsa, ‘3des_ede_cbc’, sha, default_prf} TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA ECDHE-ECDSA-AES128-SHA {ecdhe_ecdsa, aes_128_cbc, sha, default_prf} TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA ECDHE-ECDSA-AES256-SHA {ecdhe_ecdsa, aes_256_cbc, sha, default_prf} TLS_ECDH_RSA_WITH_NULL_SHA ECDH-RSA-NULL-SHA {ecdh_rsa, null, sha, default_prf} TLS_ECDH_RSA_WITH_RC4_128_SHA ECDH-RSA-RC4-SHA {ecdh_rsa, rc4_128, sha, default_prf} TLS_ECDH_RSA_WITH_3DES_EDE_CBC_SHA ECDH-RSA-DES-CBC3-SHA {ecdh_rsa, ‘3des_ede_cbc’, sha, default_prf} TLS_ECDH_RSA_WITH_AES_128_CBC_SHA ECDH-RSA-AES128-SHA {ecdh_rsa, aes_128_cbc, sha, default_prf} TLS_ECDH_RSA_WITH_AES_256_CBC_SHA ECDH-RSA-AES256-SHA {ecdh_rsa, aes_256_cbc, sha, default_prf} TLS_ECDHE_RSA_WITH_NULL_SHA ECDHE-RSA-NULL-SHA {ecdhe_rsa, null, sha, default_prf} TLS_ECDHE_RSA_WITH_RC4_128_SHA ECDHE-RSA-RC4-SHA {ecdhe_rsa, rc4_128, sha, default_prf} TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA ECDHE-RSA-DES-CBC3-SHA {ecdhe_rsa, ‘3des_ede_cbc’, sha, default_prf} TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA ECDHE-RSA-AES128-SHA {ecdhe_rsa, aes_128_cbc, sha, default_prf} TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA ECDHE-RSA-AES256-SHA {ecdhe_rsa, aes_256_cbc, sha, default_prf} TLS_ECDH_anon_WITH_NULL_SHA AECDH-NULL-SHA {ecdh_anon, null, sha, default_prf} TLS_ECDH_anon_WITH_RC4_128_SHA AECDH-RC4-SHA {ecdh_anon, rc4_128, sha, default_prf} TLS_ECDH_anon_WITH_3DES_EDE_CBC_SHA AECDH-DES-CBC3-SHA {ecdh_anon, ‘3des_ede_cbc’, sha, default_prf} TLS_ECDH_anon_WITH_AES_128_CBC_SHA AECDH-AES128-SHA {ecdh_anon, aes_128_cbc, sha, default_prf} TLS_ECDH_anon_WITH_AES_256_CBC_SHA AECDH-AES256-SHA {ecdh_anon, aes_256_cbc, sha, default_prf} TLS_SRP_SHA_WITH_3DES_EDE_CBC_SHA SRP-3DES-EDE-CBC-SHA {srp_anon, ‘3des_ede_cbc’, sha, default_prf} TLS_SRP_SHA_RSA_WITH_3DES_EDE_CBC_SHA SRP-RSA-3DES-EDE-CBC-SHA {srp_rsa, ‘3des_ede_cbc’, sha, default_prf} TLS_SRP_SHA_DSS_WITH_3DES_EDE_CBC_SHA SRP-DSS-3DES-EDE-CBC-SHA {srp_dss, ‘3des_ede_cbc’, sha, default_prf} TLS_SRP_SHA_WITH_AES_128_CBC_SHA SRP-AES-128-CBC-SHA {srp_anon, aes_128_cbc, sha, default_prf} TLS_SRP_SHA_RSA_WITH_AES_128_CBC_SHA SRP-RSA-AES-128-CBC-SHA {srp_rsa, aes_128_cbc, sha, default_prf} TLS_SRP_SHA_DSS_WITH_AES_128_CBC_SHA SRP-DSS-AES-128-CBC-SHA {srp_dss, aes_128_cbc, sha, default_prf} TLS_SRP_SHA_WITH_AES_256_CBC_SHA SRP-AES-256-CBC-SHA {srp_anon, aes_256_cbc, sha, default_prf} TLS_SRP_SHA_RSA_WITH_AES_256_CBC_SHA SRP-RSA-AES-256-CBC-SHA {srp_rsa, aes_256_cbc, sha, default_prf} TLS_SRP_SHA_DSS_WITH_AES_256_CBC_SHA SRP-DSS-AES-256-CBC-SHA {srp_dss, aes_256_cbc, sha, default_prf} TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 ECDHE-ECDSA-AES128-SHA256 {ecdhe_ecdsa, aes_128_cbc, sha256, sha256} TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384 ECDHE-ECDSA-AES256-SHA384 {ecdhe_ecdsa, aes_256_cbc, sha384, sha384} TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA256 ECDH-ECDSA-AES128-SHA256 {ecdh_ecdsa, aes_128_cbc, sha256, sha256} TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA384 ECDH-ECDSA-AES256-SHA384 {ecdh_ecdsa, aes_256_cbc, sha384, sha384} TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 ECDHE-RSA-AES128-SHA256 {ecdhe_rsa, aes_128_cbc, sha256, sha256} TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 ECDHE-RSA-AES256-SHA384 {ecdhe_rsa, aes_256_cbc, sha384, sha384} TLS_ECDH_RSA_WITH_AES_128_CBC_SHA256 ECDH-RSA-AES128-SHA256 {ecdh_rsa, aes_128_cbc, sha256, sha256} TLS_ECDH_RSA_WITH_AES_256_CBC_SHA384 ECDH-RSA-AES256-SHA384 {ecdh_rsa, aes_256_cbc, sha384, sha384} TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 ECDHE-ECDSA-AES128-GCM-SHA256 {ecdhe_ecdsa, aes_128_gcm, null, sha256} TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 ECDHE-ECDSA-AES256-GCM-SHA384 {ecdhe_ecdsa, aes_256_gcm, null, sha384} TLS_ECDH_ECDSA_WITH_AES_128_GCM_SHA256 ECDH-ECDSA-AES128-GCM-SHA256 {ecdh_ecdsa, aes_128_gcm, null, sha256} TLS_ECDH_ECDSA_WITH_AES_256_GCM_SHA384 ECDH-ECDSA-AES256-GCM-SHA384 {ecdh_ecdsa, aes_256_gcm, null, sha384} TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 ECDHE-RSA-AES128-GCM-SHA256 {ecdhe_rsa, aes_128_gcm, null, sha256} TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 ECDHE-RSA-AES256-GCM-SHA384 {ecdhe_rsa, aes_256_gcm, null, sha384} TLS_ECDH_RSA_WITH_AES_128_GCM_SHA256 ECDH-RSA-AES128-GCM-SHA256 {ecdh_rsa, aes_128_gcm, null, sha256} TLS_ECDH_RSA_WITH_AES_256_GCM_SHA384 ECDH-RSA-AES256-GCM-SHA384 {ecdh_rsa, aes_256_gcm, null, sha384} TLS_ECDHE_PSK_WITH_RC4_128_SHA ECDHE-PSK-RC4-SHA {ecdhe_psk, rc4_128, sha, default_prf} TLS_ECDHE_PSK_WITH_3DES_EDE_CBC_SHA ECDHE-PSK-3DES-EDE-CBC-SHA {ecdhe_psk, ‘3des_ede_cbc’, sha, default_prf} TLS_ECDHE_PSK_WITH_AES_128_CBC_SHA ECDHE-PSK-AES128-CBC-SHA {ecdhe_psk, aes_128_cbc, sha, default_prf} TLS_ECDHE_PSK_WITH_AES_256_CBC_SHA ECDHE-PSK-AES256-CBC-SHA {ecdhe_psk, aes_256_cbc, sha, default_prf} TLS_ECDHE_PSK_WITH_AES_128_CBC_SHA256 ECDHE-PSK-AES128-CBC-SHA256 {ecdhe_psk, aes_128_cbc, sha256, default_prf} TLS_ECDHE_PSK_WITH_AES_256_CBC_SHA384 ECDHE-PSK-AES256-CBC-SHA384 {ecdhe_psk, aes_256_cbc, sha384, default_prf} TLS_ECDHE_PSK_WITH_NULL_SHA256 ECDHE-PSK-NULL-SHA256 {ecdhe_psk, null, sha256, default_prf} TLS_ECDHE_PSK_WITH_NULL_SHA384 ECDHE-PSK-NULL-SHA384 {ecdhe_psk, null, sha384, default_prf} TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 ECDHE-RSA-CHACHA20-POLY1305 {ecdhe_rsa, chacha20_poly1305, null, sha256} TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 ECDHE-ECDSA-CHACHA20-POLY1305 {ecdhe_ecdsa, chacha20_poly1305, null, sha256} TLS_DHE_RSA_WITH_CHACHA20_POLY1305_SHA256 DHE-RSA-CHACHA20-POLY1305 {dhe_rsa, chacha20_poly1305, null, sha256} 映射表：https://github.com/rabbitmq/rabbitmq-website/issues/453加密套概念：https://blog.helong.info/blog/2015/01/23/ssl_tls_ciphersuite_intro/加密协议：https://www.iana.org/assignments/tls-parameters/tls-parameters.xhtml#tls-parameters-4openssl配置说明：http://www.jinbuguo.com/linux/openssl_install.html]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
        <tag>AMQP</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java:正则表达式用法]]></title>
    <url>%2Fposts%2F5ddc6624%2F</url>
    <content type="text"><![CDATA[java的regex库java里预留了一个regex库，方便于我们在java里操作正则表达式，或者用它来匹配字符串。 其中比较常用的就是 Pattern 和 Matcher ,pattern是一个编译好的正则表达式，而Matcher是一个正则表达式适配器，Matcher的功能很强大，所以我们一般用pattern 来获取一个Matcher对象，然后用Matcher来操作正则表达式。先看一下这两个类的用法吧. Pattern创建pattern的对象是很简单的，但是由于pattern的构造方法是用private声明的，所以我们仅能通过工厂模式的compile方法来返回一个Pattern的对象。 Pattern pattern = Pattern.compile("[abc]"); compile可以接收一个正则表达式作为参数。 接下来我们创建一个Matcher对象。Matcher的构造方法也是一个private方法，但是我们可以通过Pattern的Matcher方法来返回一个Matcher对象。 Matcher matcher = pattern.matcher("hello abc"); 这里matcher可以接收一个字符串作为参数，准确的说这里所接收的参数类型是CharSequences接口类型的参数，但是String、StringBuffer、StringBuilder，还有CharBuffer都实现了CharSequence接口，因此我们向里面传入这四种任何我们需要的参数。 与此同时Pattern还提供了一个matches静态方法，它允许我们传入一个String类型的正则表达式和一个String类型的需要匹配的字符串，并返回一个boolean类型的值，这个方法的好处在于我们可以不用创建pattern对象和matcher对象就可以知道所传入的正则表达式能不能匹配所传入的字符串。 boolean bool = Pattern.matches("\\w+","hello abc"); Matcher说到Matcher，这个东西就很强大了，我们比较常用的方法有: find(); group(); （1）先来说一下find()和group()这两个方法。 find有点像一个迭代器，它能通过正则表达式向前迭代。下来看一个例子 public class Main &#123; public static void main(String[] args)&#123; Pattern pattern = Pattern.compile("\\w+"); Matcher matcher = pattern.matcher("hello abc bbc cbc ccc"); //find向前迭代 while(matcher.find())&#123; System.out.println(matcher.group()); &#125; &#125;&#125; 我们先来看看 jdk 给出的 api 怎么定义find的: boolean find(); 可以知道find返回的是一个boolean值，当前方没有内容的时候，find会返回false，所以我们这里可以直接用while来写，这句代码打印出的内容是 helloabcbbccbcccc 可以看到其实我们的正则表达式”\w+”只匹配到了第一个单词hello ，但是因为find迭代的关系，把后面的单词全部都打印出来了，参照的正是我们给出的正则表达式。 （2）group: 说到find就不得不说group。下面看个式子 (a(b)(c(d))) 这里的话我们把整个式子称为第0组, 第一组是 a(b)(c(d)) 第二组是 子式 b 和 子式c(d) 第三组是 d 看一下几个group方法 int groupCount() 返回此匹配器模式中的捕获组数，这个方法也就是返回所匹配的字符串的组数。 public class Main &#123; public static void main(String[] args)&#123; Pattern pattern = Pattern.compile("(\\w+)\\d+"); Matcher matcher = pattern.matcher("hello123 abc bbc cbc ccc"); matcher.find(); System.out.println(matcher.groupCount()); &#125;&#125; 这里匹配到的是hello123， 当然不加()也能得到，这里只是为了方便演示。打印出来的数值是1，这是因为我们只有一个组 那group()呢? String group() 返回由以前匹配操作所匹配的输入子序列。 也就是说group是返回所匹配到的第0组的值，返回值是一个String。这也能解释我们刚刚用find进行迭代的那个例子了。 public class Main &#123; public static void main(String[] args)&#123; Pattern pattern = Pattern.compile("\\w+"); Matcher matcher = pattern.matcher("hello abc bbc cbc ccc"); //find向前迭代 while(matcher.find())&#123; System.out.println(matcher.group()); &#125; &#125;&#125; 这里没有分组所以直接将匹配到的String打印出来，其实也就是第0组。 另外，group还有个重载的方法，可以接收一个int类型的参数 String group(int group) 返回在以前匹配操作期间由给定组捕获的输入子序列。传入的参数正是组数. public class Main &#123; public static void main(String[] args)&#123; Pattern pattern = Pattern.compile("(\\w+)\\s\\d+"); Matcher matcher = pattern.matcher("hello 123 abc bbc cbc ccc"); matcher.find(); System.out.println(matcher.group(1)); &#125;&#125; 打印出来的结果正在我们的意料之中是hello。 除此之外还有两个可以返回匹配当前字符串的索引的方法。 int start();int end(); 其中start是返回匹配成功的子串的第一个字母的索引，而end是返回子串最后一个索引的位置+1。 String input = "hello abc BBc Cbc ccc";Matcher matcher = Pattern.compile("[A-Z][A-Z]\\w").matcher(input);matcher.find();System.out.println(input.charAt(matcher.start())); 这里打印出来的值是B。但是如果我们换成end就不一样了。 System.out.println(input.charAt(matcher.end())); 这里打印出来的值却是&quot; &quot;是一个空字符,也就是c的索引加了1，所以我们这里只需稍作修改便可以打印出c了。 System.out.println(input.charAt(matcher.end()-1));]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>regex</tag>
        <tag>pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ:配置远程访问]]></title>
    <url>%2Fposts%2Fe4d74468%2F</url>
    <content type="text"><![CDATA[开启WEB管理如果只从命令行操作RabbitMQ，多少有点不方便。幸好RabbitMQ自带了web管理界面，只需要启动插件便可以使用。控制台输入以下命令： sudo rabbitmq-plugins enable rabbitmq_management 响应如下： The following plugins have been configured: rabbitmq_management rabbitmq_management_agent rabbitmq_web_dispatchApplying plugin configuration to rabbit@vhost05...The following plugins have been enabled: rabbitmq_management rabbitmq_management_agent rabbitmq_web_dispatchstarted 3 plugins. 然后通过浏览器访问 url: http://ip:15672 添加用户并授权默认的guest/guest用户，rabbitmqctl add_user csh cshrabbitmqctl set_user_tags csh administratorrabbitmqctl set_permissions -p / csh &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 查看用户列表rabbitmqctl list_users Mac特殊情况使用HomeBrew安装rabbitmq，会在/usr/local/etc/的环境变量文件rabbitmq-env.conf中有如下配置,使得rabbitmq只能监听127.0.01进来的连接。 NODE_IP_ADDRESS=127.0.0.1 注释掉这部分内容后，就可以从其他机器访问连接。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Spring：基本知识]]></title>
    <url>%2Fposts%2Fc157b8b0%2F</url>
    <content type="text"><![CDATA[SpringSpring 是 2003 年兴起的一个轻量级的 Java 开发框架，由 Rod Johnson 创建。它解决了业务逻辑层和其他各层的松耦合问题，并将面向接口的编程思想贯穿整个系统应用。 简单来说，Spring 是一个分层的 JavaSE/EE Full-Stack（一站式） 轻量级开源框架。为什么说 spring 是分层、一站式、轻量级的框架呢？ 首先看分层。JavaEE 经典的 MVC 三层结构为表现层、业务层、持久层，Web表现层负责页面数据显示、页面跳转调度，例如 JSP/Servlet、SpringMVC； Service 业务层负责业务处理、功能逻辑和事务控制，例如 Service、JavaBean、EJB；而持久层Dao则负责数据存取和封装，及与数据库打交道，例如 JDBC、Hibernate、Mybatis。 而一站式，则指 Spring 为 JavaEE 的每一层都提供了解决方案，比如： 表现层：Struts1、Struts2、Spring MVC； 业务层：IoC 控制反转、AOP 面向切面编程、事务控制； 持久层：JdbcTemplate、HibernateTemplate、ORM 框架（对象关系映射）的整合。 至于轻量，则是指从大小与开销两方面而言，Spring都是轻量的。完整的 Spring 框架可以在一个大小只有 1MB 多的 Jar 文件里发布。并且 Spring 所需的处理开销也是微不足道的。 Spring 的出现解决了 EJB 臃肿、低效、繁琐复杂、脱离现实的情况。而且使用 Spring 编程是非侵入式的。Spring 应用中的对象不依赖于 Spring 的特定类。 Spring 的体系结构Spring 框架是一个分层架构，它包含一系列的功能要素，被分为大约20个模块。这些模块分为 Core Container、Data Access/Integration、Web、AOP、Aspects、Instrumentation 和 Test，如下图所示： 核心容器（Core Container）包括 Core、Beans、Context、EL 模块。 Core 和 Beans 模块提供了 Spring 最基础的功能，Core 模块是核心，为其他模块提供支持，包括 Spring 的核心工具类。Beans 是 Spring 管理实体类 Bean 的主要模块，提供 IoC 控制反转和依赖注入 DI。 控制反转即将控制权由原来的程序员自己管理交给 Spring 来管理，依赖注入就是注入对象实例，有四种方式，即接口注入、setter 方法注入、构造器注入和注解注入。 Context 上下文模块，主要基于 Core 和 Beans 模块，Context 模块的 Context 包继承了 Beans 包的功能，还增加了国际化（I18N）、事件传播等，Context 上下文模块，还包括企业服务，例如 JNDI、EJB、电子邮件、国际化、校验和调度功能。 Expression Language，表达式语言模块，又称 SpEL，提供了在运行期间查询和操作对象图的强大能力。包含五个主要特性：（1）使用 Bean 的 ID 引用 Bean；（2）调用方法和访问对象的属性；（3）对值进行算术，关系和逻辑运算；（4）正则表达式匹配；（5）集合操作。 Spring 的三大核心这三大核心分别为 IOC（Inverse of Control 控制反转）、DI（Dependency Injection，依赖注入）和AOP（Aspect Oriented Programming 面向切面编程）。 1. IOC（Inverse of Control 控制反转）IOC，即将对象创建权利交给 Spring 工厂进行管理。比如说 Content content = new Content(); 现在，可以这样写: Content content = ContentFactory.getContent(); 2. DI（Dependency Injection，依赖注入）DI 是指在 Spring 框架创建 Bean 对象时，动态地将依赖对象注入到 Bean 组件。简单的说，就是将另外一个 Bean 对象动态地注入到另一个 Bean 中。 DI 的做法是：由 Spring 容器创建 Service、Dao 对象，并且通过注解或配置将 Dao 传入 Servcie，那么 Service 对象就包含了 Dao 对象的引用。比如： @Servicepublic class UserServiceImpl implements UserService &#123; @Autowire //通过注解注入对象 private UserMapper userMapper;&#125; 3. AOP（Aspect Oriented Programming 面向切面编程）AOP 采取横向抽取机制，取代了传统纵向继承体系重复性代码的编写方式（例如性能监视、事务管理、安全检查、缓存、日志记录等）。 AOP 基于代理思想，对原来目标对象，创建代理对象，在不修改原对象代码情况下，通过代理对象，调用增强功能的代码，从而对原有业务方法进行增强。例如可以在插入 User 对象之前进行打印日志，请看下面的代码示例。 UserService.java public interface UserService &#123; void add(User user);&#125; 前置增强类 PrintLogBefore.java //前置增强代码public class PrintLogBefore implements MehtodBeforeAdvice &#123; private static final Logger log = Logger.getLogger(PrintLogBefore.class); @Override public void before(Method method, Object[] arguments, Object target) throws Throwable &#123; log.info("在插入User之前执行的方法"); &#125;&#125; 最后配置切入点： &lt;bean id="printBefore" class="com.example.PrintLogBefore"&gt;&lt;/bean&gt; &lt;aop:config&gt; &lt;aop:pointcut expression="execution(public void add(com.example.entity.User))" id="pointcut /&gt; &lt;aop:advisor advice-ref="printBefore" pointcut-ref="pointcut"/&gt; &lt;/aop:config&gt; 这样在调用 add(User user) 方法之前就会打印如下内容： “在插入User之前执行的方法”]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java:并发编程lock]]></title>
    <url>%2Fposts%2F9b7d34c3%2F</url>
    <content type="text"><![CDATA[从Java 5之后，在java.util.concurrent.locks包下提供了另外一种方式来实现同步访问，那就是Lock。 但是，既然都可以通过synchronized来实现同步访问了，那么为什么还需要提供Lock？这个问题将在下面进行阐述。本文先从synchronized的缺陷讲起，然后再讲述java.util.concurrent.locks包下常用的有哪些类和接口，最后讨论以下一些关于锁的概念方面的东西 原文链接：http://www.cnblogs.com/dolphin0520/p/3923167.html 一.synchronized的缺陷synchronized是java中的一个关键字，也就是说是Java语言内置的特性。那么为什么会出现Lock呢？ 在上面一篇文章中，我们了解到如果一个代码块被synchronized修饰了，当一个线程获取了对应的锁，并执行该代码块时，其他线程便只能一直等待，等待获取锁的线程释放锁，而这里获取锁的线程释放锁只会有两种情况： 1）获取锁的线程执行完了该代码块，然后线程释放对锁的占有； 2）线程执行发生异常，此时JVM会让线程自动释放锁。 那么如果这个获取锁的线程由于要等待IO或者其他原因（比如调用sleep方法）被阻塞了，但是又没有释放锁，其他线程便只能干巴巴地等待，试想一下，这多么影响程序执行效率。 因此就需要有一种机制可以不让等待的线程一直无期限地等待下去（比如只等待一定的时间或者能够响应中断），通过Lock就可以办到。 再举个例子：当有多个线程读写文件时，读操作和写操作会发生冲突现象，写操作和写操作会发生冲突现象，但是读操作和读操作不会发生冲突现象。 但是采用synchronized关键字来实现同步的话，就会导致一个问题： 如果多个线程都只是进行读操作，所以当一个线程在进行读操作时，其他线程只能等待无法进行读操作。 因此就需要一种机制来使得多个线程都只是进行读操作时，线程之间不会发生冲突，通过Lock就可以办到。 另外，通过Lock可以知道线程有没有成功获取到锁。这个是synchronized无法办到的。 总结一下，也就是说Lock提供了比synchronized更多的功能。但是要注意以下几点： 1）Lock不是Java语言内置的，synchronized是Java语言的关键字，因此是内置特性。Lock是一个类，通过这个类可以实现同步访问； 2）Lock和synchronized有一点非常大的不同，采用synchronized不需要用户去手动释放锁，当synchronized方法或者synchronized代码块执行完之后，系统会自动让线程释放对锁的占用；而Lock则必须要用户去手动释放锁，如果没有主动释放锁，就有可能导致出现死锁现象。 java.util.concurrent.locks包下常用的类下面我们就来探讨一下java.util.concurrent.locks包中常用的类和接口。 1.Lock 首先要说明的就是Lock，通过查看Lock的源码可知，Lock是一个接口： public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; 下面来逐个讲述Lock接口中每个方法的使用，lock()、tryLock()、tryLock(long time, TimeUnit unit)和lockInterruptibly()是用来获取锁的。unLock()方法是用来释放锁的。newCondition()这个方法暂且不在此讲述，会在后面的线程协作一文中讲述。 在Lock中声明了四个方法来获取锁，那么这四个方法有何区别呢？ 首先lock()方法是平常使用得最多的一个方法，就是用来获取锁。如果锁已被其他线程获取，则进行等待。 由于在前面讲到如果采用Lock，必须主动去释放锁，并且在发生异常时，不会自动释放锁。因此一般来说，使用Lock必须在try{}catch{}块中进行，并且将释放锁的操作放在finally块中进行，以保证锁一定被被释放，防止死锁的发生。通常使用Lock来进行同步的话，是以下面这种形式去使用的： Lock lock = ...;lock.lock();try&#123; //处理任务&#125;catch(Exception ex)&#123; &#125;finally&#123; lock.unlock(); //释放锁&#125; tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。 tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。 所以，一般情况下通过tryLock来获取锁时是这样使用的： Lock lock = ...;if(lock.tryLock()) &#123; try&#123; //处理任务 &#125;catch(Exception ex)&#123; &#125;finally&#123; lock.unlock(); //释放锁 &#125; &#125;else &#123; //如果不能获取锁，则直接做其他事情&#125; lockInterruptibly()方法比较特殊，当通过这个方法去获取锁时，如果线程正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态。也就使说，当两个线程同时通过lock.lockInterruptibly()想获取某个锁时，假若此时线程A获取到了锁，而线程B只有在等待，那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。 由于lockInterruptibly()的声明中抛出了异常，所以lock.lockInterruptibly()必须放在try块中或者在调用lockInterruptibly()的方法外声明抛出InterruptedException。 因此lockInterruptibly()一般的使用形式如下： public void method() throws InterruptedException &#123; lock.lockInterruptibly(); try &#123; //..... &#125; finally &#123; lock.unlock(); &#125; &#125; 注意，当一个线程获取了锁之后，是不会被interrupt()方法中断的。因为本身在前面的文章中讲过单独调用interrupt()方法不能中断正在运行过程中的线程，只能中断阻塞过程中的线程。 因此当通过lockInterruptibly()方法获取某个锁时，如果不能获取到，只有进行等待的情况下，是可以响应中断的。 而用synchronized修饰的话，当一个线程处于等待某个锁的状态，是无法被中断的，只有一直等待下去。 2.ReentrantLockReentrantLock，意思是“可重入锁”，关于可重入锁的概念在下一节讲述。ReentrantLock是唯一实现了Lock接口的类，并且ReentrantLock提供了更多的方法。下面通过一些实例看具体看一下如何使用ReentrantLock。 例子1，lock()的正确使用方法 public class Test &#123; private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void insert(Thread thread) &#123; Lock lock = new ReentrantLock(); //注意这个地方 lock.lock(); try &#123; System.out.println(thread.getName()+"得到了锁"); for(int i=0;i&lt;5;i++) &#123; arrayList.add(i); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125;finally &#123; System.out.println(thread.getName()+"释放了锁"); lock.unlock(); &#125; &#125;&#125; 各位朋友先想一下这段代码的输出结果是什么？ Thread-0得到了锁Thread-1得到了锁Thread-0释放了锁Thread-1释放了锁 也许有朋友会问，怎么会输出这个结果？第二个线程怎么会在第一个线程释放锁之前得到了锁？原因在于，在insert方法中的lock变量是局部变量，每个线程执行该方法时都会保存一个副本，那么理所当然每个线程执行到lock.lock()处获取的是不同的锁，所以就不会发生冲突。 知道了原因改起来就比较容易了，只需要将lock声明为类的属性即可。 public class Test &#123; private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); private Lock lock = new ReentrantLock(); //注意这个地方 public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void insert(Thread thread) &#123; lock.lock(); try &#123; System.out.println(thread.getName()+"得到了锁"); for(int i=0;i&lt;5;i++) &#123; arrayList.add(i); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125;finally &#123; System.out.println(thread.getName()+"释放了锁"); lock.unlock(); &#125; &#125;&#125; 这样就是正确地使用Lock的方法了。 例子2，tryLock()的使用方法 public class Test &#123; private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); private Lock lock = new ReentrantLock(); //注意这个地方 public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void insert(Thread thread) &#123; if(lock.tryLock()) &#123; try &#123; System.out.println(thread.getName()+"得到了锁"); for(int i=0;i&lt;5;i++) &#123; arrayList.add(i); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125;finally &#123; System.out.println(thread.getName()+"释放了锁"); lock.unlock(); &#125; &#125; else &#123; System.out.println(thread.getName()+"获取锁失败"); &#125; &#125;&#125; 输出结果： Thread-0得到了锁Thread-1获取锁失败Thread-0释放了锁 例子3，lockInterruptibly()响应中断的使用方法： public class Test &#123; private Lock lock = new ReentrantLock(); public static void main(String[] args) &#123; Test test = new Test(); MyThread thread1 = new MyThread(test); MyThread thread2 = new MyThread(test); thread1.start(); thread2.start(); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread2.interrupt(); &#125; public void insert(Thread thread) throws InterruptedException&#123; lock.lockInterruptibly(); //注意，如果需要正确中断等待锁的线程，必须将获取锁放在外面，然后将InterruptedException抛出 try &#123; System.out.println(thread.getName()+"得到了锁"); long startTime = System.currentTimeMillis(); for( ; ;) &#123; if(System.currentTimeMillis() - startTime &gt;= Integer.MAX_VALUE) break; //插入数据 &#125; &#125; finally &#123; System.out.println(Thread.currentThread().getName()+"执行finally"); lock.unlock(); System.out.println(thread.getName()+"释放了锁"); &#125; &#125;&#125; class MyThread extends Thread &#123; private Test test = null; public MyThread(Test test) &#123; this.test = test; &#125; @Override public void run() &#123; try &#123; test.insert(Thread.currentThread()); &#125; catch (InterruptedException e) &#123; System.out.println(Thread.currentThread().getName()+"被中断"); &#125; &#125;&#125; 运行之后，发现thread2能够被正确中断。 3.ReadWriteLockReadWriteLock也是一个接口，在它里面只定义了两个方法： public interface ReadWriteLock &#123; /** * Returns the lock used for reading. * * @return the lock used for reading. */ Lock readLock(); /** * Returns the lock used for writing. * * @return the lock used for writing. */ Lock writeLock();&#125; 一个用来获取读锁，一个用来获取写锁。也就是说将文件的读写操作分开，分成2个锁来分配给线程，从而使得多个线程可以同时进行读操作。下面的ReentrantReadWriteLock实现了ReadWriteLock接口。 4.ReentrantReadWriteLockReentrantReadWriteLock里面提供了很多丰富的方法，不过最主要的有两个方法：readLock()和writeLock()用来获取读锁和写锁。 下面通过几个例子来看一下ReentrantReadWriteLock具体用法。 假如有多个线程要同时进行读操作的话，先看一下synchronized达到的效果： public class Test &#123; private ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); &#125; public synchronized void get(Thread thread) &#123; long start = System.currentTimeMillis(); while(System.currentTimeMillis() - start &lt;= 1) &#123; System.out.println(thread.getName()+"正在进行读操作"); &#125; System.out.println(thread.getName()+"读操作完毕"); &#125;&#125; 这段程序的输出结果会是，直到thread1执行完读操作之后，才会打印thread2执行读操作的信息。 Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0读操作完毕Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作 而改成用读写锁的话： public class Test &#123; private ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void get(Thread thread) &#123; rwl.readLock().lock(); try &#123; long start = System.currentTimeMillis(); while(System.currentTimeMillis() - start &lt;= 1) &#123; System.out.println(thread.getName()+"正在进行读操作"); &#125; System.out.println(thread.getName()+"读操作完毕"); &#125; finally &#123; rwl.readLock().unlock(); &#125; &#125;&#125; 此时打印的结果为： Thread-0正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作 说明thread1和thread2在同时进行读操作。 这样就大大提升了读操作的效率。 不过要注意的是，如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写锁的线程会一直等待释放读锁。 如果有一个线程已经占用了写锁，则此时其他线程如果申请写锁或者读锁，则申请的线程会一直等待释放写锁。 关于ReentrantReadWriteLock类中的其他方法感兴趣的朋友可以自行查阅API文档。 5.Lock和synchronized的选择 总结来说，Lock和synchronized有以下几点不同： 1）Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现； 2）synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁； 3）Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断； 4）通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。 5）Lock可以提高多个线程进行读操作的效率。 在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized。所以说，在具体使用时要根据适当情况选择。 三.锁的相关概念介绍在前面介绍了Lock的基本使用，这一节来介绍一下与锁相关的几个概念。 1.可重入锁 如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2。 看下面这段代码就明白了： class MyClass &#123; public synchronized void method1() &#123; method2(); &#125; public synchronized void method2() &#123; &#125;&#125; 上述代码中的两个方法method1和method2都用synchronized修饰了，假如某一时刻，线程A执行到了method1，此时线程A获取了这个对象的锁，而由于method2也是synchronized方法，假如synchronized不具备可重入性，此时线程A需要重新申请锁。但是这就会造成一个问题，因为线程A已经持有了该对象的锁，而又在申请获取该对象的锁，这样就会线程A一直等待永远不会获取到的锁。 而由于synchronized和Lock都具备可重入性，所以不会发生上述现象。 2.可中断锁可中断锁：顾名思义，就是可以相应中断的锁。 在Java中，synchronized就不是可中断锁，而Lock是可中断锁。 如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。 在前面演示lockInterruptibly()的用法时已经体现了Lock的可中断性。 3.公平锁公平锁即尽量以请求锁的顺序来获取锁。比如同是有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该所，这种就是公平锁。 非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。 在Java中，synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。 而对于ReentrantLock和ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁。 看一下这2个类的源代码就清楚了： 201808011448-java-lock 在ReentrantLock中定义了2个静态内部类，一个是NotFairSync，一个是FairSync，分别用来实现非公平锁和公平锁。 我们可以在创建ReentrantLock对象时，通过以下方式来设置锁的公平性： ReentrantLock lock = new ReentrantLock(true); 如果参数为true表示为公平锁，为fasle为非公平锁。默认情况下，如果使用无参构造器，则是非公平锁。 另外在ReentrantLock类中定义了很多方法，比如： isFair() //判断锁是否是公平锁 isLocked() //判断锁是否被任何线程获取了 isHeldByCurrentThread() //判断锁是否被当前线程获取了 hasQueuedThreads() //判断是否有线程在等待该锁 在ReentrantReadWriteLock中也有类似的方法，同样也可以设置为公平锁和非公平锁。不过要记住，ReentrantReadWriteLock并未实现Lock接口，它实现的是ReadWriteLock接口。 4.读写锁读写锁将对一个资源（比如文件）的访问分成了2个锁，一个读锁和一个写锁。 正因为有了读写锁，才使得多个线程之间的读操作不会发生冲突。 ReadWriteLock就是读写锁，它是一个接口，ReentrantReadWriteLock实现了这个接口。 可以通过readLock()获取读锁，通过writeLock()获取写锁。 上面已经演示过了读写锁的使用方法，在此不再赘述。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
        <tag>lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx:安装和常用命令]]></title>
    <url>%2Fposts%2F8747ea0e%2F</url>
    <content type="text"><![CDATA[下载安装包从官网下载nginx压缩包，官网地址：https://nginx.org/en/download.html。最好选择稳定版本。 安装假设下载的安装包位于/root/用户根目录下。 1、解压文件tar -zxvf nginx-1.15.2.tar.gz 2、自定义nginx安装位置 #创建文件夹cd /usr/localmkdir nginx-1.15.2#回到解压文件夹cd /root/nginx-1.15.2指定安装路径./configure --prefix=/usr/local/nginx-1.15.2编译安装makemake install 常用命令先进入到nginx的安装路径，可以看到目录结构如下： drwx------ 2 root root 6 7月 30 19:05 client_body_tempdrwxr-xr-x 2 root root 4096 7月 30 19:16 confdrwx------ 2 root root 6 7月 30 19:05 fastcgi_tempdrwxr-xr-x 5 root root 141 7月 30 19:15 htmldrwxr-xr-x 2 root root 58 7月 30 19:12 logsdrwx------ 2 root root 6 7月 30 19:05 proxy_tempdrwxr-xr-x 2 root root 19 7月 30 19:04 sbindrwx------ 2 root root 6 7月 30 19:05 scgi_tempdrwx------ 2 root root 6 7月 30 19:05 uwsgi_temp 其中，conf是配置文件，html是静态文件目录，logs是错误日志目录，sbin是执行文件目录 1、启动 ./sbin/nginx 2、停止 ./sbin/nginx -s stop 3、重载配置文件 ./sbin/nignx -s reload 4、指定配置文件启动 ./sbin/nginx -c /conf/nginx.conf 配置策略1. 负载均衡同源策略当同时使用负载均衡和CAS单点登录的时候，upstream的多个后端会分别于CAS Server建立会话，导致登录流程异常。该问题可以通过配置同源策略，根据访客ip固定被调用服务器。 http &#123; upstream gateway &#123; ip_hash; server 172.28.20.114:8080 ; server 172.28.20.140:8080 ; server 172.28.20.122:8080 ; &#125;&#125; 常见问题1. 缺少C compiler库./configure: error: C compiler cc is not found 安装 yum -y install gcc gcc-c++ 2. 缺少PCRE库./configure: error: the HTTP rewrite module requires the PCRE library. 使用yum安装 yum -y install pcre-devel 3. 缺少OpenSSL库安装--with-http_ssl_module模块，缺少依赖 ./configure: error: SSL modules require the OpenSSL library. Linux环境下安装yum -y install openssl openssl-devel Mac环境下由于不能安装openssl，因此，需要到官网下载openssl 压缩包。 地址： https://www.openssl.org/source/ 安装命令修改为： /configure --prefix=/usr/local/nginx --with-http_ssl_module --with-openssl=&lt;path&gt; 是openssl文件解压位置。 但是，在make编译过程中，可能存在如下问题： ld: symbol(s) not found for architecture x86_64clang: error: linker command failed with exit code 1 (use -v to see invocation) 解决方法 #在源码目录下vi objs/Makefile#找到类似下面这行&amp;&amp; ./config --prefix=/Users/wid/Downloads/nginx-1.8.0/../openssl-1.0.2d/.openssl no-shared 将config修改为Configure darwin64-x86_64-cc, --prefix之后的不用修改, 修改后的如: &amp;&amp; ./Configure darwin64-x86_64-cc --prefix=/Users/wid/Downloads/nginx-1.8.0/../openssl-1.0.2d/.openssl no-shared 保存后，继续make即可]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Appium:分布式测试环境搭建]]></title>
    <url>%2Fposts%2F4e971816%2F</url>
    <content type="text"><![CDATA[需求同时向大量的跨平台机器推送脚本，执行测试。 环境搭建1.Selenium Standalone Server1、下载jar包，地址为：https://www.seleniumhq.org/download/ 2、启动服务 java -jar selenium-server-standalone-&lt;version&gt;.jar -role hub 服务启动后，访问：localhost：4444验证。 3、编辑节点配置文件 &#123; &quot;capabilities&quot;: [ &#123; &quot;browserName&quot;: &quot;&lt;e.g._iPhone5_or_iPad4&gt;&quot;, &quot;version&quot;:&quot;&lt;version_of_iOS_e.g._7.1&gt;&quot;, &quot;maxInstances&quot;: 1, &quot;platform&quot;:&quot;&lt;platform_e.g._MAC_or_ANDROID&gt;&quot; &#125; ], &quot;configuration&quot;: &#123; &quot;cleanUpCycle&quot;:2000, &quot;timeout&quot;:30000, &quot;proxy&quot;: &quot;org.openqa.grid.selenium.proxy.DefaultRemoteProxy&quot;, &quot;url&quot;:&quot;http://&lt;host_name_appium_server_or_ip-address_appium_server&gt;:&lt;appium_port&gt;/wd/hub&quot;, &quot;host&quot;: &lt;host_name_appium_server_or_ip-address_appium_server&gt;, &quot;port&quot;: &lt;appium_port&gt;, &quot;maxSession&quot;: 1, &quot;register&quot;: true, &quot;registerCycle&quot;: 5000, &quot;hubPort&quot;: &lt;grid_port&gt;, &quot;hubHost&quot;: &quot;&lt;Grid_host_name_or_grid_ip-address&gt;&quot; &#125;&#125; 如果没有给出 url、host 和 port，配置会自动指向 localhost:whatever-port-Appium-started-on。 如果你的 Appium Server 和 Selenium Grid 没有运行在同一台机器上，为确保 Selenium Grid 连接正常，请在你的 host &amp; url 上使用外部域名或 IP 地址，而不是 localhost 和 127.0.0.1 4、指定配置文件启动Appuium节点appium -p 4724 -bp 4714 --nodeconfig &quot;json文件路径&quot; 其中，-p与配置文件中的port一致，即指定appium启动的端口号，-bp是手机客户端bootStrap监听的端口号 启动后，控制台输出如下： [Appium] Appium support for versions of node &lt; 8 has been deprecated and will be removed in a future version. Please upgrade![Appium] Welcome to Appium v1.8.1[Appium] Non-default server args:[Appium] port: 4724[Appium] bootstrapPort: 4714[Appium] nodeconfig: SM-G9550[debug] [Appium] Starting auto register thread for grid. Will try to register every 5000 ms.[Appium] Appium REST http interface listener started on 0.0.0.0:4724[debug] [Appium] Appium successfully registered with the grid on http://localhost:4444 问题Selenium Grid会发生阻塞，如果上一个测试任务因为异常无法继续执行会发生阻塞，后面的测试任务无法继续执行 Selenium Grid 架构 什么时 Hub呢？ 它是你加载所有测试的机器。 一个Grid里只有一个Hub。 hub是测试运行的地方，但是你看到的测试是在node上的浏览器上执行的。 什么是Nodes？ 这台机器将执行您在hub上加载的测试 他可以是一个或者多个nodes在一个grid里，Grid中有不同浏览器和操作系统。 做成多线程方式Selenium Grid只是提供多系统、多浏览器的执行环境，而不是说任务一个test case丢给它就能并行运行。并行的运行我这里就交给testng了]]></content>
      <categories>
        <category>Appium</category>
      </categories>
      <tags>
        <tag>Appium</tag>
        <tag>Grid</tag>
        <tag>Selenium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Quartz：Listener注入Spring对象]]></title>
    <url>%2Fposts%2F1b401ae4%2F</url>
    <content type="text"><![CDATA[我们知道，由于listener启动会先于spring容器。况且quratz 中的bean是独立于spring外运行的，也就是说spring把创建bean的生命周期权限托管给了quratz所以要想在job 或者job的listener中注入spring的bean肯定是不行的 但是我们可以使用别的方法。下面我写一个自己认为最简单的方法： 先创建一个spring的SpringUtil的工具类，该工具类主要是利用实现了ApplicationContextAware接口，利用set方法先实例化一个ApplicationContext，然后就可以获取对应的bean源码如下: import org.springframework.beans.BeansException;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.stereotype.Component;@Componentpublic class SpringUtil implements ApplicationContextAware&#123; private static ApplicationContext applicationContext; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; if(SpringUtil.applicationContext == null) &#123; SpringUtil.applicationContext = applicationContext; &#125; &#125; //获取applicationContext public static ApplicationContext getApplicationContext() &#123; return applicationContext; &#125; //通过name获取 Bean. public static Object getBean(String name)&#123; return getApplicationContext().getBean(name); &#125; //通过class获取Bean. public static &lt;T&gt; T getBean(Class&lt;T&gt; clazz)&#123; return getApplicationContext().getBean(clazz); &#125; //通过name,以及Clazz返回指定的Bean public static &lt;T&gt; T getBean(String name,Class&lt;T&gt; clazz)&#123; return getApplicationContext().getBean(name, clazz); &#125;&#125; 使用方法 @Componentpublic class MySchedulerListener implements SchedulerListener&#123; ... @Override public void jobScheduled(Trigger trigger) &#123; MyBatisMapper myBatisMapper = (MyBatisMapper)SpringUtil.getBean(MyBatisMapper.class); myBatisMapper.updateByPrimaryKey(0); System.out.println("任务被部署时被执行"); &#125; ...&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库：MySQL常用语句]]></title>
    <url>%2Fposts%2Fa81bce10%2F</url>
    <content type="text"><![CDATA[查询字段为null或者不为null在mysql中，查询某字段为空时，切记不可用= null，而是 is null，不为空则是is not null，示例如下： select * from table where column is null;select * from table where column is not null; group by 异常MySQL5.7 后将sql_mode的ONLY_FULL_GROUP_BY模式默认设置为打开状态，这样一来，很多之前的sql语句可能会出现错误，错误信息如下： Error Code: 1055. Expression #3 of SELECT list is not in GROUP BY clause and contains nonaggregated column &apos;×××&apos; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by 解决方法： 1、查看sql_mode select @@sql_mode 查询出来的值为： ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION 2、去掉ONLY_FULL_GROUP_BY，重新设置值 set @@sql_mode =&apos;STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION&apos;; 3、上面是改变了全局sql_mode，对于新建的数据库有效。对于已存在的数据库，则需要在对应的数据下执行 set sql_mode =&apos;STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION&apos;; 4、以上的改表方式只能临时生效，在MySQL重启之后就失效了，想要一劳永逸的办法，就是修改配置文件。RPM的安装方式，配置文件位于/etc/my.cnf，增加如下配置： sql_mode=STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION 忽略表名大小写在配置文件my.cnf在增加如下配置： #默认是0，区分大小写；1忽略大小写lower_case_table_names=1 如果原有的数据库表中有大写的表名，在配置生效后，会出现该表查找不到的异常。在配置之前，将含有大写的表导出，在配置生效之后，重新导入，可以消除异常。 计算两个日期的时间差函数：TIMESTAMPDIFF(interval,datetime_expr1,datetime_expr2) 说明:返回日期或日期时间表达式datetime_expr1和datetime_expr2之间的整数差。其结果的单位由interval参数给出。interval的法定值同TIMESTAMPADD()函数说明中所列出的相同。可选项如下： 名称 参数 秒 SECOND 分钟 MINUTE 小时 HOUR 天 DAY 月 MONTH 年 YEAR 字符串拼接使用CONCAT这个关键字，如下： SELECT CONCAT(&apos;学号: &apos;,XNumber) FROM user 输出：学号: 20 添加表字段alter table table1 add transactor varchar(10) not Null;alter table table1 add id int unsigned not Null auto_increment primary key]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务：Zuul转发后文件名乱码]]></title>
    <url>%2Fposts%2Fe7f3dec2%2F</url>
    <content type="text"><![CDATA[最近在使用 SpringCloud 搭建微服务的过程中，发现上传文件经过 Zuul 网关转发的时候，因为上传文件名中文乱码，导致文件的写操作失败。但是不经过 Zuul 转发的时候，文件上传正常，因此猜测是 Zuul 对上传的请求的编码进行了处理。 原文件名：file中文.txt上传后：file__.txt 解决方法如下：一、增加请求前缀在上传文件的请求路径之前添加字符串zuul声明。网关将所有带/zuul请求的请求都走zuulServlet，不带zuul的请求都走spring mvc的dispatchServlet，避免多余的编码处理。 原请求路径：http://localhost:8080/uploadFile修改后：http://localhost:8080/zuul/uploadFile 二、增加 application.property 属性在方案一的基础上，主要修改前端代码，也可以在application.property声明属性来处理。 zuul.servlet-path=/ 但是，如果前端文件部署在网关上，会由于所有的请求都跳过spring mvc处理，而无法正常渲染前端页面。因此，请根据实际需求选择解决方案。]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>zuul</tag>
        <tag>文件上传</tag>
        <tag>乱码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[版本管理：Git代码冲突常见解决方法]]></title>
    <url>%2Fposts%2Ffbabd5d1%2F</url>
    <content type="text"><![CDATA[如果系统中有一些配置文件在服务器上做了配置修改,然后后续开发又新添加一些配置项的时候，在发布这个配置文件的时候,会发生代码冲突: error: Your local changes to the following files would be overwritten by merge: protected/config/main.phpPlease, commit your changes or stash them before you can merge. 如果希望保留生产服务器上所做的改动,仅仅并入新配置项, 处理方法如下: git stashgit pullgit stash pop 然后可以使用git diff -w +文件名来确认代码自动合并的情况. 反过来,如果希望用代码库中的文件完全覆盖本地工作版本. 方法如下: git reset --hardgit pull 其中git reset是针对版本,如果想针对文件回退本地修改,使用 git checkout HEAD file/to/restore]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JAVA：流]]></title>
    <url>%2Fposts%2F9c74640c%2F</url>
    <content type="text"><![CDATA[*Java核心技术卷二-读书笔记 流输入流：可以从其中读入字节序列的对象；输出流：可以向其中写入字节序列的对象； 抽象类InputStream和OutputStream构成输入/输出(I/O)类层次结构基础。 Unicode中每个字符都使用多个字节表示，以上面向字节的流不便处理，因此，从抽象类Reader和Writer中继承出专用于处理Unicode字符的类层次结构，且读写操作都基于两字节的Unicode码元。 读写字节adstract int read() InputStream类的抽象方法，作用是：读入一个字节，并返回读入的字节，或者在遇到输入源结尾时返回-1。具体的输入流类必须覆盖此方法以提供适用的功能。 abstract void write(int b) OutputStream的抽象方法，用于向某个输出位置写出一个字节。 read和write方法在执行时都将阻塞，直至字节确实被读入或写出。 available方法用于检查当前可读入的字节数量。以下的代码写法就不可能被阻塞，因为字节数组的长度被确定。 int bytesAvailable = in.available();if (bytesAvailable &gt; 0) &#123; byte[] data = new byte[bytesAvailable]; in.read(data);&#125; 完成对流的读写后，应调用close方法关闭它，释放系统资源。关闭输出流的同时，还会冲刷用于该输出流的缓冲区（buffer）：字节输出时，先被置于临时缓冲区中，再以更大的包（block）的形式写出，当关闭输出流时，会将缓冲区内容输出。如果不关闭，那么写出字节的最后一个包可能永远也无法输出。当然，也可以用flush方法强制输出。 组合流过滤器FileInputStream和FileOutputStream可以通过文件路径读取磁盘文件上的输入/输出流，并且只能从fin对象中读入字节和字节数组。 FileInputStream fin = new FileInputStream("employee.dat")byte b = (byte)fin.read(); 提示：java.io的相对路径以用户工作目录开始，调用System.getProperty(&quot;user.dir&quot;)来获取。 DataInputStream只能读入数值类型，而不能从文件获取数据。 DataInputStream din = ...;double s = din.readDouble(); 如果希望从文件或者其他外部位置获取字节，再将其组装到更有用的数据类型中（如数字类型），则必须对二者进行组合。 FileInputStream fin = new FileInputStream(&quot;employee.dat&quot;);DataInputStream din = new DataInputStream(fin);double s = din.readDouble(); 再例如，默认情况下流的读取时不被缓冲区缓存的，每调用一次read会请求操作系统再分发一个字节。要想使用缓冲机制，并从文件获取数据，就需要如下的构造器序列。 DataInputStream din = new DataInputStream( new BufferInputStream( new FileInputStream(&quot;employee.dat&quot;))); 文本输入与输出保存数据时，可以选择二进制格式或者文本格式。尽管二进制格式的I/O高效且高速，但是难以阅读。 在存储文本字符串时，需要考虑字符编码（character encoding）方式，如UTF-16、ISO 8859-1等。 OutputStreamWriter类使用选定的字符编码方式，把Unicode字符流转换为字节流。而InputStreamReader类将字节输入流转为可以产生Unicode码元的读入器。 例如，从控制台读入键盘敲击信息，并转为Unicode： InputStreamReader in = new InputStreamReader(System.in); 这个InputStreamReader使用系统默认字符编码方式，如需指定不同的编码方式，则可用以下方式： InputStreamReader in = new InputStreamReader( new FileInputStream("kremlin.dat"), "ISO8859_5"); 如何写出文本输出PrintWriter类拥有以文本格式打印字符串和数字的方法，再使用与System.out相同的print、println和printf方法打印数字、字符、布尔值、字符串和对象到文件中。例如： PrintWriter out = new PrintWriter("employee.txt");String name = "Harry Hacker";double salary = 75000;out.print(name);out.print(' ');out.println(salary); 输出以下内容到 employee.txt 中： Harry Hacker 75000.0 如何读入文本输入在 Java SE 5.0 之前，通过BufferedReader类的readLine方法读入一行文本。readLine在没有输入时返回 null。以下示例集成缓冲功能： BufferedReader in = new BufferedReader( new InputStreamReader(new FileInputStream("employee.txt"), "UTF-8")); String line;while ((line - in.readLine()) != null) &#123; do something with line&#125; 然而，BufferedReader不能读入数字，建议使用Scanner来处理。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>InputStream</tag>
        <tag>OutputStream</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA：[转]深入理解abstract class和interface]]></title>
    <url>%2Fposts%2Fa494d8f4%2F</url>
    <content type="text"><![CDATA[理解抽象类abstract class和interface在Java语言中都是用来进行抽象类（本文中的抽象类并非从abstract class翻译而来，它表示的是一个抽象体，而abstract class为Java语言中用于定义抽象类的一种方法，请读者注意区分）定义的，那么什么是抽象类，使用抽象类能为我们带来什么好处呢？ 在面向对象的概念中，我们知道所有的对象都是通过类来描绘的，但是反过来却不是这样。并不是所有的类都是用来描绘对象的，如果一个类中没有包含足够的信息来描绘一个具体的对象，这样的类就是抽象类。抽象类往往用来表征我们在对问题领域进行分析、设计中得出的抽象概念，是对一系列看上去不同，但是本质上相同的具体概念的抽象。比如：如果我们进行一个图形编辑软件的开发，就会发现问题领域存在着圆、三角形这样一些具体概念，它们是不同的，但是它们又都属于形状这样一个概念，形状这个概念在问题领域是不存在的，它就是一个抽象概念。正是因为抽象的概念在问题领域没有对应的具体概念，所以用以表征抽象概念的抽象类是不能够实例化的。 在面向对象领域，抽象类主要用来进行类型隐藏。我们可以构造出一个固定的一组行为的抽象描述，但是这组行为却能够有任意个可能的具体实现方式。这个抽象描述就是抽象类，而这一组任意个可能的具体实现则表现为所有可能的派生类。模块可以操作一个抽象体。由于模块依赖于一个固定的抽象体，因此它可以是不允许修改的；同时，通过从这个抽象体派生，也可扩展此模块的行为功能。熟悉OCP的读者一定知道，为了能够实现面向对象设计的一个最核心的原则OCP( Open-Closed Principle)，抽象类是其中的关键所在。 从语法定义层面看abstract class和interface在语法层面，Java语言对于abstract class和interface给出了不同的定义方式，下面以定义一个名为Demo的抽象类为例来说明这种不同。 使用abstract class的方式定义Demo抽象类的方式如下： abstract class Demo ｛ abstract void method1(); abstract void method2(); …｝ 使用interface的方式定义Demo抽象类的方式如下： interface Demo &#123; void method1(); void method2(); …&#125; 在abstract class方式中，Demo可以有自己的数据成员，也可以有非abstarct的成员方法，而在interface方式的实现中，Demo只能够有静态的不能被修改的数据成员（也就是必须是static final的，不过在interface中一般不定义数据成员），所有的成员方法都是abstract的。从某种意义上说，interface是一种特殊形式的abstract class。 对于abstract class和interface在语法定义层面更多的细节问题，不是本文的重点，不再赘述，读者可以参阅参考文献〔1〕获得更多的相关内容。 从编程层面看abstract class和interface从编程的角度来看，abstract class和interface都可以用来实现”design by contract”的思想。但是在具体的使用上面还是有一些区别的。 首先，abstract class在Java语言中表示的是一种继承关系，一个类只能使用一次继承关系。但是，一个类却可以实现多个interface。也许，这是Java语言的设计者在考虑Java对于多重继承的支持方面的一种折中考虑吧。 其次，在abstract class的定义中，我们可以赋予方法的默认行为。但是在interface的定义中，方法却不能拥有默认行为，为了绕过这个限制，必须使用委托，但是这会 增加一些复杂性，有时会造成很大的麻烦。 在抽象类中不能定义默认行为还存在另一个比较严重的问题，那就是可能会造成维护上的麻烦。因为如果后来想修改类的界面（一般通过abstract class或者interface来表示）以适应新的情况（比如，添加新的方法或者给已用的方法中添加新的参数）时，就会非常的麻烦，可能要花费很多的时间（对于派生类很多的情况，尤为如此）。但是如果界面是通过abstract class来实现的，那么可能就只需要修改定义在abstract class中的默认行为就可以了。 同样，如果不能在抽象类中定义默认行为，就会导致同样的方法实现出现在该抽象类的每一个派生类中，违反了”one rule，one place”原则，造成代码重复，同样不利于以后的维护。因此，在abstract class和interface间进行选择时要非常的小心。 从设计理念层面看abstract class和interface上面主要从语法定义和编程的角度论述了abstract class和interface的区别，这些层面的区别是比较低层次的、非本质的。本小节将从另一个层面：abstract class和interface所反映出的设计理念，来分析一下二者的区别。作者认为，从这个层面进行分析才能理解二者概念的本质所在。 前面已经提到过，abstarct class在Java语言中体现了一种继承关系，要想使得继承关系合理，父类和派生类之间必须存在”is a”关系，即父类和派生类在概念本质上应该是相同的（参考文献〔3〕中有关于”is a”关系的大篇幅深入的论述，有兴趣的读者可以参考）。对于interface 来说则不然，并不要求interface的实现者和interface定义在概念本质上是一致的，仅仅是实现了interface定义的契约而已。为了使论述便于理解，下面将通过一个简单的实例进行说明。 考虑这样一个例子，假设在我们的问题领域中有一个关于Door的抽象概念，该Door具有执行两个动作open和close，此时我们可以通过abstract class或者interface来定义一个表示该抽象概念的类型，定义方式分别如下所示： 使用abstract class方式定义Door： abstract class Door &#123; abstract void open(); abstract void close()；&#125; 使用interface方式定义Door： interface Door &#123; void open(); void close();&#125; 其他具体的Door类型可以extends使用abstract class方式定义的Door或者implements使用interface方式定义的Door。看起来好像使用abstract class和interface没有大的区别。 如果现在要求Door还要具有报警的功能。我们该如何设计针对该例子的类结构呢（在本例中，主要是为了展示abstract class和interface反映在设计理念上的区别，其他方面无关的问题都做了简化或者忽略）？下面将罗列出可能的解决方案，并从设计理念层面对这些不同的方案进行分析。 解决方案一：简单的在Door的定义中增加一个alarm方法，如下： abstract class Door &#123; abstract void open(); abstract void close()； abstract void alarm();&#125; 或者 interface Door &#123; void open(); void close(); void alarm();&#125; 那么具有报警功能的AlarmDoor的定义方式如下： class AlarmDoor extends Door &#123; void open() &#123; … &#125; void close() &#123; … &#125; void alarm() &#123; … &#125;&#125; 或者 class AlarmDoor implements Door ｛ void open() &#123; … &#125; void close() &#123; … &#125; void alarm() &#123; … &#125;｝ 这种方法违反了面向对象设计中的一个核心原则ISP（Interface Segregation Priciple），在Door的定义中把Door概念本身固有的行为方法和另外一个概念”报警器”的行为方法混在了一起。这样引起的一个问题是那些仅仅依赖于Door这个概念的模块会因为”报警器”这个概念的改变（比如：修改alarm方法的参数）而改变，反之依然。 解决方案二：既然open、close和alarm属于两个不同的概念，根据ISP原则应该把它们分别定义在代表这两个概念的抽象类中。定义方式有：这两个概念都使用abstract class方式定义；两个概念都使用interface方式定义；一个概念使用abstract class方式定义，另一个概念使用interface方式定义。 显然，由于Java语言不支持多重继承，所以两个概念都使用abstract class方式定义是不可行的。后面两种方式都是可行的，但是对于它们的选择却反映出对于问题领域中的概念本质的理解、对于设计意图的反映是否正确、合理。我们一一来分析、说明。 如果两个概念都使用interface方式来定义，那么就反映出两个问题：1、我们可能没有理解清楚问题领域，AlarmDoor在概念本质上到底是Door还是报警器？2、如果我们对于问题领域的理解没有问题，比如：我们通过对于问题领域的分析发现AlarmDoor在概念本质上和Door是一致的，那么我们在实现时就没有能够正确的揭示我们的设计意图，因为在这两个概念的定义上（均使用interface方式定义）反映不出上述含义。 如果我们对于问题领域的理解是：AlarmDoor在概念本质上是Door，同时它有具有报警的功能。我们该如何来设计、实现来明确的反映出我们的意思呢？前面已经说过，abstract class在Java语言中表示一种继承关系，而继承关系在本质上是”is a”关系。所以对于Door这个概念，我们应该使用abstarct class方式来定义。另外，AlarmDoor又具有报警功能，说明它又能够完成报警概念中定义的行为，所以报警概念可以通过interface方式定义。如下所示： abstract class Door &#123; abstract void open(); abstract void close()； &#125;interface Alarm &#123; void alarm();&#125;class AlarmDoor extends Door implements Alarm &#123; void open() &#123; … &#125; void close() &#123; … &#125; void alarm() &#123; … &#125;&#125; 这种实现方式基本上能够明确的反映出我们对于问题领域的理解，正确的揭示我们的设计意图。其实abstract class表示的是”is a”关系，interface表示的是”like a”关系，大家在选择时可以作为一个依据，当然这是建立在对问题领域的理解上的，比如：如果我们认为AlarmDoor在概念本质上是报警器，同时又具有Door的功能，那么上述的定义方式就要反过来了。 结论abstract class和interface是Java语言中的两种定义抽象类的方式，它们之间有很大的相似性。但是对于它们的选择却又往往反映出对于问题领域中的概念本质的理解、对于设计意图的反映是否正确、合理，因为它们表现了概念间的不同的关系（虽然都能够实现需求的功能）。这其实也是语言的一种的惯用法，希望读者朋友能够细细体会。]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Quartz:常见异常]]></title>
    <url>%2Fposts%2F6ed02c97%2F</url>
    <content type="text"><![CDATA[持久化模式常见异常无数据源完成持久化的配置之后，仍然无法连接到数据库，报错的内容是：C3P0的connectionProvider初始化失败。查了很多资料，再结合错误信息，花了半天时间，才发现：原来quartz默认使用了C3P0的数据源，然而quartz的依赖包中并没有C3P0的依赖，因此无法初始化连接器。解决方法：只要在maven管理的POM.xml中把C3P0的依赖加上就可以了。 连接超时MySQL服务器默认的“wait_timeout”是28800秒即8小时，意味着如果一个连接的空闲时间超过8个小时，MySQL将自动断开该连接，而连接池却认为该连接还是有效的(因为并未校验连接的有效性)，当应用申请使用该连接时，就会导致异常发生。 在本文，由于我们的C3P0连接池没有配置连接有效性检查，导致quartz使用的连接线程可能超时无效。错误如下：JobStoreTX - MisfireHandler: Error handling misfires: Database error recovering from misfires.Another error has occurred [ com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: No operations allowed after connection closed. ] which will not be reported to listeners! 解决这个问题的办法有三种，但是推荐第二种——减少连接池内连接的生命周期。 1. 增加 MySQL 的 wait_timeout 属性的值修改mysql安装目录下的配置文件 my.ini文件（如果没有此文件， 复制“my-default.ini”文件，生成“复件 my-default.ini”文件。 将“复件 my-default.ini”文件重命名成“my.ini” ），在文件中设置： wait_timeout=31536000 interactive_timeout=31536000 2. 减少连接池内连接的生存周期减少连接池内连接的生存周期， 使之小于 上一项中所设置的 wait_timeout 的值。此处修改Quartz的c3p0配置信息，内容如下： org.quartz.dataSource.NAME.validationQuery增加用于验证连接有效性的数据库查询语句，如select count(*) from QRTZ_CALENDARS org.quartz.dataSource.NAME.validateOnCheckout只有配置了validationQuery之后，才能设置为true org.quartz.dataSource.NAME.idleConnectionValidationSeconds只有配置了validationQuery之后，才能配置有效性查询的时间间隔，默认50s org.quartz.dataSource.NAME.discardIdleConnectionsSeconds废弃空闲连接的时间，默认是0s 参考：Quartz官方文档 3. 定期使用连接池内的连接定期使用连接池内的连接，使得它们不会因为闲置超时而被 MySQL 断开。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven:管理本地jar包]]></title>
    <url>%2Fposts%2F46b8b7d2%2F</url>
    <content type="text"><![CDATA[Maven依赖管理，可以很方便的帮助我们添加所需的jar包。但是，大部分情况，这些jar包都是Maven项目。如果我们需要引入自定义的jar包，又该如何处理呢？ 起初，我在项目中新建lib文件夹，并把自定义的jar包放进去，然后，在pom.xml中进行如下配置：&lt;dependency&gt; &lt;groupId&gt;dd-plist&lt;/groupId&gt; &lt;artifactId&gt;dd-plist&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;project.basedir&#125;/lib/dd-plist.jar&lt;/systemPath&gt;&lt;/dependency&gt; 结果，本地使用IDE运行调试时没有问题，但是打成jar包上传到服务器却找不到该jar包中的类文件。 为了解决这个问题，我找到了如下的方案。 1 在项目的目录下创建lib文件夹2 使用Maven安装自定义jar包在命令行执行以下命令，可以安装自定义jar包到我们指定的lib文件夹。注意配置好自定义jar包的路径。 mvn install:install-file -Dfile=path_to_mylib.jar -DgroupId=com.mylib -DartifactId=jar_name -Dversion=1.0 -Dpackaging=jar -DlocalRepositoryPath=path_to_my_project/lib 执行成功后，终端显示内容如下： [INFO] Scanning for projects...[INFO] [INFO] ------------------------------------------------------------------------[INFO] Building Maven Stub Project (No POM) 1[INFO] ------------------------------------------------------------------------[INFO] [INFO] --- maven-install-plugin:2.4:install-file (default-cli) @ standalone-pom ---[INFO] Installing path_to_mylib.jar to path_to_my_project/lib/com/mylib/jar_name/1.0/dd-plist-1.0.jar[INFO] Installing /var/folders/r5/86whqmls4y36p5qgnhwstr6w0000gn/T/mvninstall2596441059296695813.pom to path_to_my_project/lib/com/mylib/jar_name/1.0/dd-plist-1.0.pom[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 0.413 s[INFO] Finished at: 2018-06-01T10:13:20+08:00[INFO] Final Memory: 9M/309M[INFO] ------------------------------------------------------------------------ 3 配置POM文件按如下文件配置POM.xml，配置完成之后，重新执行Maven Reimport，即可生效。&lt;repositories&gt; &lt;repository&gt; &lt;!-- DO NOT set id to &quot;local&quot; because it is reserved by Maven --&gt; &lt;id&gt;lib&lt;/id&gt; &lt;url&gt;file://$&#123;project.basedir&#125;/lib&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.mylib&lt;/groupId&gt; &lt;artifactId&gt;mylib&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 结语通过以上方式配置的自定义jar包，在工程打包部署后仍然可以生效。具体的原理，可以留言给我。我很乐意多学习一些Maven的知识。]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[足迹：富春桃源]]></title>
    <url>%2Fposts%2Fec6986a1%2F</url>
    <content type="text"><![CDATA[2018年5月19日和S一起来到富春桃园，参加她们公司的TB。当天淫雨霏霏，初晴乍雨，空气清新潮湿。 大巴先到了图中的码头，放眼望去，确实有一种古时吴越之地那种“沉舟侧畔千帆过，病树前头万木春“的意境。一日的行程，终止于此。期间历经登山、穿越溶洞、轨道滑行、农家乐、竹筏漂流。登岸时，仰望天际，有种”激流勇进，放浪天涯“的冲动。]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo：常用命令]]></title>
    <url>%2Fposts%2Fc8dcc28b%2F</url>
    <content type="text"><![CDATA[草稿草稿相当于很多博客都有的“私密文章”功能。 hexo new draft &quot;new draft&quot; 会在source/_drafts目录下生成一个new-draft.md文件。但是这个文件不被显示在页面上，链接也访问不到。也就是说如果你想把某一篇文章移除显示，又不舍得删除，可以把它移动到_drafts目录之中。 如果你希望强行预览草稿，更改配置文件： render_drafts: true 或者，如下方式启动server： hexo server --drafts 下面这条命令可以把草稿变成文章，或者页面： hexo publish [layout] &lt;filename&gt;]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>草稿</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务[Exception]：Zuul无法访问负载均衡服务]]></title>
    <url>%2Fposts%2F8e887edc%2F</url>
    <content type="text"><![CDATA[问题描述使用zuul的负载均衡功能时，无法访问负载均衡服务 先决条件 使用Eureka作为服务注册 zuul配置路由匹配规则为服务化的路由规则 异常如下15:50:18.013 Gateway [http-nio-9090-exec-6] WARN o.s.c.n.z.f.post.SendErrorFilter - Error during filteringcom.netflix.zuul.exception.ZuulException: Forwarding error at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.handleException(RibbonRoutingFilter.java:189) at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:164) at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.run(RibbonRoutingFilter.java:111) at com.netflix.zuul.ZuulFilter.runFilter(ZuulFilter.java:112) at com.netflix.zuul.FilterProcessor.processZuulFilter(FilterProcessor.java:193) at com.netflix.zuul.FilterProcessor.runFilters(FilterProcessor.java:157) at com.netflix.zuul.FilterProcessor.route(FilterProcessor.java:118) at com.netflix.zuul.ZuulRunner.route(ZuulRunner.java:96) at com.netflix.zuul.http.ZuulServlet.route(ZuulServlet.java:116) at com.netflix.zuul.http.ZuulServlet.service(ZuulServlet.java:81) at org.springframework.web.servlet.mvc.ServletWrappingController.handleRequestInternal(ServletWrappingController.java:157) at org.springframework.cloud.netflix.zuul.web.ZuulController.handleRequest(ZuulController.java:44) at org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter.handle(SimpleControllerHandlerAdapter.java:50) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) at javax.servlet.http.HttpServlet.service(HttpServlet.java:635) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127) at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:170) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at com.cmcc.cmct.gateway.auth.AuthenticationTokenProcessingFilter.doFilter(AuthenticationTokenProcessingFilter.java:47) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:116) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:105) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:56) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331) at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214) at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:478) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803) at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459) at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748)Caused by: com.netflix.client.ClientException: null at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:118) at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:152) at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:49) at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:302) at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:298) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:46) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:51) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:51) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeMap.call(OnSubscribeMap.java:48) at rx.internal.operators.OnSubscribeMap.call(OnSubscribeMap.java:33) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:41) at rx.internal.operators.OnSubscribeDoOnEach.call(OnSubscribeDoOnEach.java:30) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:51) at rx.internal.operators.OnSubscribeDefer.call(OnSubscribeDefer.java:35) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.subscribe(Observable.java:10247) at rx.Observable.subscribe(Observable.java:10214) at rx.internal.operators.BlockingOperatorToFuture.toFuture(BlockingOperatorToFuture.java:51) at rx.observables.BlockingObservable.toFuture(BlockingObservable.java:411) at com.netflix.hystrix.HystrixCommand.queue(HystrixCommand.java:378) at com.netflix.hystrix.HystrixCommand.execute(HystrixCommand.java:344) at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:158) ... 105 common frames omittedCaused by: java.lang.RuntimeException: java.net.UnknownHostException: xntest02.gzhl.quality: 未知的名称或服务 at rx.exceptions.Exceptions.propagate(Exceptions.java:58) at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:464) at rx.observables.BlockingObservable.single(BlockingObservable.java:341) at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:112) ... 167 common frames omittedCaused by: java.net.UnknownHostException: xntest02.gzhl.quality: 未知的名称或服务 at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method) at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928) at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1323) at java.net.InetAddress.getAllByName0(InetAddress.java:1276) at java.net.InetAddress.getAllByName(InetAddress.java:1192) at java.net.InetAddress.getAllByName(InetAddress.java:1126) at org.apache.http.impl.conn.SystemDefaultDnsResolver.resolve(SystemDefaultDnsResolver.java:45) at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:112) at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:359) at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381) at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237) at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185) at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89) at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111) at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83) at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108) at org.springframework.cloud.netflix.ribbon.apache.RibbonLoadBalancingHttpClient.execute(RibbonLoadBalancingHttpClient.java:82) at org.springframework.cloud.netflix.ribbon.apache.RibbonLoadBalancingHttpClient.execute(RibbonLoadBalancingHttpClient.java:42) at com.netflix.client.AbstractLoadBalancerAwareClient$1.call(AbstractLoadBalancerAwareClient.java:104) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:303) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:287) at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:231) at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:228) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.drain(OnSubscribeConcatMap.java:286) at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.onNext(OnSubscribeConcatMap.java:144) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:185) at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:180) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:94) at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:42) at rx.Observable.unsafeSubscribe(Observable.java:10151) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber$1.call(OperatorRetryWithPredicate.java:127) at rx.internal.schedulers.TrampolineScheduler$InnerCurrentThreadScheduler.enqueue(TrampolineScheduler.java:73) at rx.internal.schedulers.TrampolineScheduler$InnerCurrentThreadScheduler.schedule(TrampolineScheduler.java:52) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber.onNext(OperatorRetryWithPredicate.java:79) at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber.onNext(OperatorRetryWithPredicate.java:45) at rx.internal.util.ScalarSynchronousObservable$WeakSingleProducer.request(ScalarSynchronousObservable.java:276) at rx.Subscriber.setProducer(Subscriber.java:209) at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:138) at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:129) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48) at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30) at rx.Observable.subscribe(Observable.java:10247) at rx.Observable.subscribe(Observable.java:10214) at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:444) ... 169 common frames omitted 分析根据如下两部分的异常内容，通常会认为是Ribbon和Hystrix的超时问题。 异常一： com.netflix.zuul.exception.ZuulException: Forwarding error at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.handleException(RibbonRoutingFilter.java:189) at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.forward(RibbonRoutingFilter.java:164) at org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter.run(RibbonRoutingFilter.java:111) ...... 异常二： Caused by: com.netflix.client.ClientException: null at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:118) at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:152) at org.springframework.cloud.netflix.zuul.filters.route.support.AbstractRibbonCommand.run(AbstractRibbonCommand.java:49) at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:302) at com.netflix.hystrix.HystrixCommand$2.call(HystrixCommand.java:298) 相应的解决方案： ribbon.ConnectTimeout=60000ribbon.ReadTimeout=60000hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=120000 然而 不幸的是，我加了这两个超时配置之后，并没有改变zuul负载均衡转发异常。唯一改变的是：在每次异常发生时，请求的等待时间被大大延长。抓狂~~~~ 通过多次的本地实验，我才开始对异常三产生了重视，内容如下：异常三： Caused by: java.net.UnknownHostException: xntest02.gzhl.quality: 未知的名称或服务 at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method) at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928) at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1323) 是的，重点在这里。尽管负载均衡器在启动的时候就发现了可以用于分担压力的三个节点，然而，这些节点信息都是Eureka提供的。我们的当地主机虽然获得了这些节点的hostname，却根本不知道如何去访问它们。 zuul启动时获取的服务注册信息 16:07:42.327 Gateway [main] INFO c.n.l.DynamicServerListLoadBalancer - DynamicServerListLoadBalancer for client CloudAPI initialized: DynamicServerListLoadBalancer:&#123;NFLoadBalancer:name=CloudAPI,current list of Servers=[xntest02.gzhl.quality:9000, xntest03.gzhl.quality:9000, xntest01.gzhl.quality:9000],Load balancer stats=Zone stats: &#123;defaultzone=[Zone:defaultzone; Instance count:3; Active connections count: 0; Circuit breaker tripped count: 0; Active connections per server: 0.0;]&#125;,Server stats: [[Server:xntest03.gzhl.quality:9000; Zone:defaultZone; Total Requests:0; Successive connection failure:0; Total blackout seconds:0; Last connection made:Thu Jan 01 08:00:00 CST 1970; First connection made: Thu Jan 01 08:00:00 CST 1970; Active Connections:0; total failure count in last (1000) msecs:0; average resp time:0.0; 90 percentile resp time:0.0; 95 percentile resp time:0.0; min resp time:0.0; max resp time:0.0; stddev resp time:0.0], [Server:xntest01.gzhl.quality:9000; Zone:defaultZone; Total Requests:0; Successive connection failure:0; Total blackout seconds:0; Last connection made:Thu Jan 01 08:00:00 CST 1970; First connection made: Thu Jan 01 08:00:00 CST 1970; Active Connections:0; total failure count in last (1000) msecs:0; average resp time:0.0; 90 percentile resp time:0.0; 95 percentile resp time:0.0; min resp time:0.0; max resp time:0.0; stddev resp time:0.0], [Server:xntest02.gzhl.quality:9000; Zone:defaultZone; Total Requests:0; Successive connection failure:0; Total blackout seconds:0; Last connection made:Thu Jan 01 08:00:00 CST 1970; First connection made: Thu Jan 01 08:00:00 CST 1970; Active Connections:0; total failure count in last (1000) msecs:0; average resp time:0.0; 90 percentile resp time:0.0; 95 percentile resp time:0.0; min resp time:0.0; max resp time:0.0; stddev resp time:0.0]]&#125; 看到这儿，解决方案也就出来了。那就是，确保每一个服务所在的服务器节点都能通过hostname和zuul网关互通。从操作角度来说，就是要在每一台服务节点上配置其他所有服务节点的hostname，使得这些服务集群互通。 Liunx解决方案：第一步 打开配置文件 vi /etc/hosts 第二步 增加服务所在主机ip对应的hostname 172.23.25.1 xntest01172.23.25.2 xntest02172.23.25.3 xntest03 大功告成~~~]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>zuul</tag>
        <tag>micro service</tag>
        <tag>spring cloud</tag>
        <tag>eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务：Zuul代理转发]]></title>
    <url>%2Fposts%2Fb778229b%2F</url>
    <content type="text"><![CDATA[Zuul代理转发zuul代理转发的方式有两种： URL映射：优点是不用对被代理的服务做任务修改，适合旧系统迁移到微服务架构时采用。过渡状态中，通常会保留旧代码继续使用，同时逐步将功能一点点迁移到新平台。旧功能的访问便可以采用这种方法，使得项目可以在用户毫无感知的情况下迁移到微服务架构。缺点是每增加一个服务就需要配置一条内容，不支持动态提供后端的服务。服务化映射：在实现微服务架构时，服务名与服务实例地址的关系在eureka server中已经存在了，所以只需要将Zuul注册到eureka server上去发现其他服务，就可以实现对serviceId的映射。 URL映射客户端存在context-path客户端application.property配置 spring.application.name=service-cloudappserver.context-path=/SPLD 说明: 直接访问路径为——http://ip:port/SPLD/api zuulapplication.property配置 #注册Eureka服务发现eureka.client.serviceUrl.defaultZone: http://localhost:8060/eureka/#转发zuul.routes.app.path=/SPLD/**zuul.routes.app.serviceId=service-cloudapp 那么访问路径是：http://ip:port/SPLD/SPLD/api 如何去掉重复的前缀呢？可以在zuul中，路由后面增加配置如下： zuul.routes.app.stripPrefix=false 原理 当stripPrefix=true的时候，代理前缀默认会从请求路径中移除。访问http://zuul-ip:port/SPLD/api重定向到http://spld-ip:port/api 当stripPrefix=false的时候，会保留代理前缀。访问http://zuul-ip:port/SPLD/api会重定向到http://spld-ip:port/SPLD/api。 参考文章：springcloud(十)：服务网关zuul]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>zuul</tag>
        <tag>micro service</tag>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Liunx：常用命令]]></title>
    <url>%2Fposts%2Fcbdebe31%2F</url>
    <content type="text"><![CDATA[SCP-文件传输从服务器下载文件scp username@servername:/remote_path/filename ~/local_destination 从服务器下载整个目录scp -r username@servername:/remote_path/remote_dir/ ~/local_destination 上传本地文件到服务器scp ~/local_path/local_filename username@servername:/remote_path 上传目录到服务器scp -r ~/local_dir username@servername:/remote_path/remote_dir 查看内存free命令 total used free shared buff/cache availableMem: 8010180 1027572 454540 74152 6528068 6504456Swap: 0 0 0 total:总计物理内存的大小。used:已使用多大。free:可用有多少。Shared:多个进程共享的内存总额。Buffers/cached:磁盘缓存的大小。 Mem的used/free是从OS的角度来看，因为对于OS，buffers/cached都是属于被使用的 修改密码 登录账户后，输入passwd 输入一遍旧密码，输入两遍新密码，密码不能太简单 软连接通常数据文件会和应用部署所在系统盘分开。此时，为了既能保持整体一致性，又不会占用系统盘资源，通常会在应用部署的文件夹下建立一个指向数据盘的软连接。 命令：ln -s abc(源文件) efg(目标快捷方式) ln -s /data/upload/ ./upload 效果：当前目录产生如下文件目录 lrwxrwxrwx 1 root root 13 6月 20 15:35 upload -&gt; /data/upload/ 注意：必须使用绝对路径，否则会出现符号连接的层数过多的错误。 查看进程的完整路径在使用ps -ef查看当前进程时，看到的路径通常是不完整的，比如： #查看命令ps -aux |grep nginx#显示内容root 12996 1 0 19:44 ? 00:00:00 nginx: master process ../sbin/nginx 其中，最后的../sbin/nginx就是启动进程的命令。那么如何才能查看到完整路径呢？ linux为每一个启动的进程都建立了一个文件夹，目录位于/proc/，以上面的进程为例： #输入命令cd /proc/12996ll#查看结果lrwxrwxrwx 1 root root 0 7月 30 20:04 cwd -&gt; /usr/local/nginx-1.15.2/conflrwxrwxrwx 1 root root 0 7月 30 20:04 exe -&gt; /usr/local/nginx-1.15.2/sbin/nginx 由此可见，exe表示完整路径为：/usr/local/nginx-1.15.2/sbin/nginx，cwd符号链接的是进程运行时的目录。 解压缩中文乱码当上传zip文件到服务器时，可能在解压缩的时候出现中文乱码的情况，可以在 unzip 后面增加编码格式来避免这种情况，具体命令如下： unzip -O GBK file.zip]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>scp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库：MyBatis常用语法]]></title>
    <url>%2Fposts%2F5a838215%2F</url>
    <content type="text"><![CDATA[Else判断分支使用MyBatis写动态SQL查询相比Hiberntate是非常方便的。select不仅能够根据mapper接口中的返回值自动匹配 查询selectOne还是selectList，而且在查询中还可以灵活的定制查询的方式，添加if 或者 choose等标签进行查询。mybaits中没有else要用“chose when otherwise”代替 &lt;!--批量插入用户--&gt;&lt;select id="getItems" parameterType="com.ipro.shopping.to.IntegerEntity" resultType="itemsType"&gt; select * from itemsType &lt;where&gt; &lt;!--方式一使用choose的方式查询--&gt; &lt;!-- &lt;choose&gt; &lt;when test="parentId !=0 "&gt;parentTypeId=#&#123;parentId&#125;&lt;/when&gt; &lt;when test="parentId==0"&gt;parentTypeId is null&lt;/when&gt; &lt;/choose&gt; --&gt; &lt;!--方式二使用if的方式查询--&gt; &lt;if test="parentId!=0"&gt; parentTypeId=#&#123;parentId&#125; &lt;/if&gt; &lt;if test="parentId==0"&gt; parentTypeId is null &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; 导出表结构和数据使用mysqldump命令，具体用法如下： mysqldump -u用戶名 -p密码 -d 数据库名 表名 &gt; 脚本名; 导出整个数据库结构和数据 mysqldump -h localhost -uroot -p123456 database &gt; dump.sql 导出单个数据表结构和数据 mysqldump -h localhost -uroot -p123456 database table &gt; dump.sql 导出整个数据库结构（不包含数据） mysqldump -h localhost -uroot -p123456 -d database &gt; dump.sql 导出单个数据表结构（不包含数据） mysqldump -h localhost -uroot -p123456 -d database table &gt; dump.sql 可能异常可能在执行导出命令时，会遇到如下异常： mysqldump: Error: &apos;Got error 28 from storage engine&apos; when trying to dump tablespacesmysqldump: Couldn&apos;t execute &apos;show fields from `consumption`&apos;: Got error 28 from storage engine (1030) 原因 是系统空间不足，可以清理一下缓存。 数据库外键关联外键关联有四种模式，分别如下： CASCADE: 从父表中删除或更新对应的行，同时自动的删除或更新子表中匹配的行。ON DELETE CANSCADE和ON UPDATE CANSCADE都被InnoDB所支持。 SET NULL: 从父表中删除或更新对应的行，同时将子表中的外键列设为空。注意，这些在外键列没有被设为NOT NULL时才有效。ON DELETE SET NULL和ON UPDATE SET SET NULL都被InnoDB所支持。 NO ACTION: InnoDB拒绝删除或者更新父表。 RESTRICT: 拒绝删除或者更新父表。指定RESTRICT（或者NO ACTION）和忽略ON DELETE或者ON UPDATE选项的效果是一样的 按天分组查询 username create_time 张三 2018-03-13 09:48:34 李四 2018-03-14 09:24:32 查询某天： SELECT DATE_FORMAT( create_time, &quot;%Y-%m-%d) as date, COUNT( * ) as countFROM testGROUP BY DATE_FORMAT( create_time, &quot;%Y-%m-%d) 结果： date count 2018-03-13 1 2018-03-14 1 如果想要查询某时的统计信息，可以修改DATE_FORMAT内容： create_time, &quot;%Y-%m-%d %H&quot; 依次类推，其实就是对create_time进行处理，然后再对处理后的数据分组。 模糊匹配like CONCAT(&apos;%&apos;, #&#123;port&#125;, &apos;%&apos;) 插入数据后返回id&lt;insert id=&quot;insertSelective&quot; parameterType=&quot;com.cmcc.Bean&quot;&gt;标签最后加入useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;。新标签如下所示： &lt;insert id=&quot;insertSelective&quot; parameterType=&quot;com.cmcc.Bean&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot; &gt;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>scp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Quartz：Cron表达式详解]]></title>
    <url>%2Fposts%2Ff507bee4%2F</url>
    <content type="text"><![CDATA[CronExpression：用于配置cronTrigger的实例，由七个子表达式组成。这些表达式之间用空格分隔。 Seconds（秒） Minutes（分） Hours（小时） Day-of-Month（天） Month（月） Day-of-Week（周） Year（年） 例：”0 0 12 ? * WED” 意思是：每个星期三的中午12点执行。 个别子表达式可以包含范围或者列表。例如：上面例子中的WED可以换成”MON-FRI”，”MON,WED,FRI”，甚至”MON-WED,SAT”。 子表达式范围 Seconds (0~59) Minutes (0~59) Hours (0~23) Day-of-Month (1~31,但是要注意有些月份没有31天) Month (0~11，或者”JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV,DEC”) Day-of-Week (1~7,1=SUN 或者”SUN, MON, TUE, WED, THU, FRI, SAT”) Year (1970~2099) 字段名 允许的值 允许的特殊字符 秒 0-59 , - * / 分 0-59 , - * / 小时 0-23 , - * / 日 1-31 , - * ? / L W C 月 1-12 or JAN-DEC , - * / 周几 1-7 or SUN-SAT , - * ? / L C # 年(可选字段) empty 1970-2099 , - * / 字符含义* ：代表所有可能的值。因此，“*”在Month中表示每个月，在Day-of-Month中表示每天，在Hours表示每小时 - ：表示指定范围。 , ：表示列出枚举值。例如：在Minutes子表达式中，“5,20”表示在5分钟和20分钟触发。 / ：被用于指定增量。例如：在Minutes子表达式中，“0/15”表示从0分钟开始，每15分钟执行一次。”3/20”表示从第三分钟开始，每20分钟执行一次。和”3,23,43”（表示第3，23，43分钟触发）的含义一样。 ? ：用在Day-of-Month和Day-of-Week中，指“没有具体的值”。当两个子表达式其中一个被指定了值以后，为了避免冲突，需要将另外一个的值设为“?”。例如：想在每月20日触发调度，不管20号是星期几，只能用如下写法：0 0 0 20 ?，其中最后以为只能用“?”，而不能用“”。 L ：用在day-of-month和day-of-week字串中。它是单词“last”的缩写。它在两个子表达式中的含义是不同的。在day-of-month中，“L”表示一个月的最后一天，一月31号，3月30号。在day-of-week中，“L”表示一个星期的最后一天，也就是“7”或者“SAT”如果“L”前有具体内容，它就有其他的含义了。例如：“6L”表示这个月的倒数第六天。“FRIL”表示这个月的最后一个星期五。注意：在使用“L”参数时，不要指定列表或者范围，这样会出现问题。 W ：“Weekday”的缩写。只能用在day-of-month字段。用来描叙最接近指定天的工作日（周一到周五）。例如：在day-of-month字段用“15W”指“最接近这个月第15天的工作日”，即如果这个月第15天是周六，那么触发器将会在这个月第14天即周五触发；如果这个月第15天是周日，那么触发器将会在这个月第 16天即周一触发；如果这个月第15天是周二，那么就在触发器这天触发。注意一点：这个用法只会在当前月计算值，不会越过当前月。“W”字符仅能在 day-of-month指明一天，不能是一个范围或列表。也可以用“LW”来指定这个月的最后一个工作日，即最后一个星期五。 # ：只能用在day-of-week字段。用来指定这个月的第几个周几。例：在day-of-week字段用”6#3” or “FRI#3”指这个月第3个周五（6指周五，3指第3个）。如果指定的日期不存在，触发器就不会触发。 表达式例子 表达式 含义 0 ? 每1分钟触发一次 0 0 * ? 每天每1小时触发一次 0 0 10 ? 每天10点触发一次 0 14 * ? 在每天下午2点到下午2:59期间的每1分钟触发 0 30 9 1 * ? 每月1号上午9点半 0 15 10 15 * ? 每月15日上午10:15触发 /5 * ? 每隔5秒执行一次 0 /1 ? 每隔1分钟执行一次 0 0 5-15 ? 每天5-15点整点触发 0 0/3 * ? 每三分钟触发一次 0 0-5 14 ? 在每天下午2点到下午2:05期间的每1分钟触发 0 0/5 14 ? 在每天下午2点到下午2:55期间的每5分钟触发 0 0/5 14,18 ? 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发 0 0/30 9-17 ? 朝九晚五工作时间内每半小时 0 0 10,14,16 ? 每天上午10点，下午2点，4点 0 0 12 ? * WED 表示每个星期三中午12点 0 0 17 ? * TUES,THUR,SAT 每周二、四、六下午五点 0 10,44 14 ? 3 WED 每年三月的星期三的下午2:10和2:44触发 0 15 10 ? * MON-FRI 周一至周五的上午10:15触发 0 0 23 L * ? 每月最后一天23点执行一次 0 15 10 L * ? 每月最后一日的上午10:15触发 0 15 10 ? * 6L 每月的最后一个星期五上午10:15触发 0 15 10 ? 2005 2005年的每天上午10:15触发 0 15 10 ? * 6L 2002-2005 2002年至2005年的每月的最后一个星期五上午10:15触发 0 15 10 ? * 6#3 每月的第三个星期五上午10:15触发]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>Quartz</tag>
        <tag>持久化</tag>
        <tag>对象注入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo：Nginx独立部署方法]]></title>
    <url>%2Fposts%2F3a8571de%2F</url>
    <content type="text"><![CDATA[前言在自己的生产环境中部署hexo静态博客，通常有两种方法：nohup命令：通过nohup执行hexo s实现。由于hexo s是框架提供的调试方法，不是部署方式，因此在生产环境会存在性能问题，不建议使用；Nginx服务器：通过nginx部署静态资源，将本地调试好的hexo工程打包生成的public目录部署到nginx上。nginx性能好，访问速度快。 Hexo配置处理二级目录：当生产环境中，静态博客部署在二级目录下（如：“http://域名(ip)/blog”这种情况），需要修改hexo工程下的_config.yml配置文件，否则打包生成的css、js文件目录会缺失（默认在根目录），导致无法加载样式。一般修改root和url,增加二级目录 # URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' ## and root as '/child/'url: http://yoursite.com/blogroot: /blogpermalink: :year/:month/:day/:title/permalink_defaults: 部署在根目录无需处理 打包：通常在调试环境无需打包，修改后使用hexo s，即可生效，可以直接在本地查看效果。但是，以静态资源的方式部署需要打包生成静态资源，命令为：hexo generate。 Nginx配置静态资源路由示例：hexo打包完成之后，以静态资源的方式部署到nginx，增加一个location模块。路由的细节有两种：root和alias，主要区别就是怎么解析location后面的uri。以下代码以root为例： location /blog &#123; root html; index index.html;&#125; root规则: 以上的示例，说明访问的实际路由为：html/blog/index.html alias规则: 同样的路径，alias需要按下面这么写，location后面的blog不会接到alias后面，而且alias指定的目录名后面一定要加上”/“。（^~表示uri以某个常规字符串开头，用于匹配url路径（而且不对url做编码处理，例如请求/static/20%/aa，可以被规则^~ /static/ /aa 匹配到（注意是空格））。下面是alias示例： location ^~ /blog/ &#123; alias html/blog/; index index.html;&#125; Nginx常用命令 启动：nginx 停止：nginx -s stop 重启：nginx -s restart 指定配置文件启动：nginx -c 路径 参考： nginx之location（root/alias）]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo：Github部署站点的SEO优化教程]]></title>
    <url>%2Fposts%2Fundefined%2F</url>
    <content type="text"><![CDATA[个人博客搭建完成，就算在互联网的世界里安了一个家。从阿里云的万网申请到了域名，我们的家也就有了门牌号。然而，要在茫茫人海中被人发现，仅仅靠口口相传是不够的。我们需要在黄页上登记自己的住址和成员，这样，有缘人才能登门拜访。 百度1.生成sitemap针对百度和谷歌，分别有两种hexo插件，hexo-generator-sitemap是传统的sitemap，可供谷歌使用；hexo-generator-baidu-sitemap则是针对百度。 npm install hexo-generator-sitemap --save-devnpm install hexo-generator-baidu-sitemap --save-dev 安装完成后，重启hexo，执行hexo g后，在public目录下生成对应的xml文件。本地可以通过http://127.0.0.4000/sitemap.xml和 http://127.0.0.4000/baidusitemap.xml访问到sitemap文件。 2.注册百度站长平台有百度账号即可 3.添加个人站点进入站点管理，添加网站，主要障碍在第二步的验证，方式有三：文件、html标签和cname。由于hexo会在生成编译文件的过程中，修改html文件内容，导致百度验证失败，因此，不建议再踩一遍这个坑。 由于域名是我在万网上注册的，所以选择cname的方式。过程如下： 进入万网云解析管理平台； 添加解析&gt;记录类型（CNAME），填写表单，两项必填： 主机：就是他给你的带有自身网站后缀的域名 记录值：ziyuan.baidu.com 4.提交sitemap回到链接提交处，选择自己的站点网址。找到自动提交，选择sitemap，按照提示的格式添加自己的sitemap文件 5.新增蜘蛛协议新建robots.txt文件，添加以下文件内容，把robots.txt放在hexo站点的source文件下。 # hexo robots.txtUser-agent: * Allow: /Allow: /archives/Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: http://dadroid.cn/sitemap.xmlSitemap: http://dadroid.cn/baidusitemap.xml 然后去百度站长平台检测robots文件是否生效。 However挂了好几天，发现百度依然收录不了我的站点，登录平台查看抓取诊断-&gt;抓取一次，错误信息如下： HTTP/1.1 403 ForbiddenCache-Control: no-cacheContent-Type: text/htmlTransfer-Encoding: chunkedAccept-Ranges: bytesDate: Thu, 03 May 2018 05:57:37 GMTVia: 1.1 varnishConnection: closeX-Served-By: cache-hnd18744-HNDX-Cache: MISSX-Cache-Hits: 0X-Timer: S1525327058.780403,VS0,VE113Vary: Accept-EncodingX-Fastly-Request-ID: 7333aaaa3853b41672517dffa1a85e843dcbcdb4 可以看出该错误是拒绝访问，根据百度提供的信息可知 【访问遭拒绝】一般情况下，百度会通过跟踪网页间的链接来查找内容。百度spider必须能够访问某个网页才能抓取该网页。如果您意外地看到了“访问遭拒”错误，可能是由于以下几种原因导致的：（1）百度spider无法访问您网站上的网址，因为您网站上的所有或部分内容要求用户登录后才能查看。（2）您的服务器要求用户使用代理进行身份验证，或者您的托管服务提供商阻止百度spider访问您的网站。 说明我们托管在github pages上的博客禁止百度爬虫的访问。那么我们有什么办法能让百度收录我们的页面呢？ 托管在国内平台，如coding 采用主动/手动提交链接 由于coding绑定自定义域名免费模式会被拦截，显示coding的广告，既影响爬虫抓取站点内容，也影响美观，因此尝试过后便放弃了。下面介绍使用hexo自动提交链接的插件。 前提注册百度站长工具，然后在工具-&gt;网页抓取-&gt;链接提交里找到你的密匙。 hexo-baidu-url-submit首先，在Hexo根目录下，安装本插件：npm install hexo-baidu-url-submit --save 然后，同样在根目录下，把以下内容配置到_config.yml文件中: baidu_url_submit: count: 1 ## 提交最新的一个链接 host: www.hui-wang.info ## 在百度站长平台中注册的域名 token: your_token ## 请注意这是您的秘钥，所以请不要把博客源代码发布在公众仓库里! path: baidu_urls.txt ## 文本文档的地址， 新链接会保存在此文本文档里 其次，记得查看_config.ym文件中url的值， 必须包含是百度站长平台注册的域名（一般有www）， 比如: # URLurl: http://www.dadroid.cnroot: /permalink: 最后，加入新的deployer: deploy:- type: git ## 这是我原来的deployer- type: baidu_url_submitter ## 这是新加的 实现原理 新链接的产生，hexo generate会产生一个文本文件，里面包含最新的链接 新链接的提交，hexo deploy会从上述文件中读取链接，提交至百度搜索引擎 谷歌步骤1——5与百度大同小异，以下介绍一些不同点： 1.注册Google Search Console链接：https://www.google.com/webmasters/ 2.抓取方式完成robost检测后，点击左侧的Google抓取方式。 在这里我们填上我们需要抓取的url，不填这表示抓取首页，抓取方式可以选择桌面，智能手机，自行根据需要选择。填好url之后，点击抓取。然后可能会出现几种情况，如:完成、部分完成、重定向等，自由这三种情况是可以提交的。 提交完成后，提交至索引，根据提示操作就可以了 hexo优化修改文章链接Hexo默认的文章链接形式是一个四级url——domain/year/month/day/postname，可能造成url过长，对搜索引擎是十分不友好。我们可以改成domain/postname的形式，编辑站点_config.yml文件，修改permalink字段改为permalink: :title.html即可。 keywords 和 description在hexo工程根目录下的\scaffolds\post.md中添加如下代码，用于生成的文章中添加关键字和描述。 keywords:description: 给出站链接添加 “nofollow” 标签网络爬虫可能在搜索当前页面的所有链接时，跳到别的网站回不来了。因此，需要nofollow标签发挥作用。 nofollow标签是由谷歌领头创新的一个“反垃圾链接”的标签，并被百度、yahoo等各大搜索引擎广泛支持，引用nofollow标签的目的是：用于指示搜索引擎不要追踪（即抓取）网页上带有nofollow属性的任何出站链接，以减少垃圾链接的分散网站权重。 Hexo的Next主题需要改以下几个地方： 找到footer.swig，路径在your-hexo-site\themes\next\layout\_partials，将下面代码中的a标签加上rel=&quot;external nofollow&quot;属性； &#123;&#123; __(&apos;footer.powered&apos;, &apos;&lt;a class=&quot;theme-link&quot; href=&quot;http://hexo.io&quot;&gt;Hexo&lt;/a&gt;&apos;) &#125;&#125; &lt;a class=&quot;theme-link&quot; href=&quot;https://github.com/iissnan/hexo-theme-next&quot;&gt; 修改sidebar.swig文件，路径在your-hexo-site\themes\next\layout_macro，将下面代码中的a标签加上rel=&quot;external nofollow&quot;属性； &lt;a href=&quot;&#123;&#123; link &#125;&#125;&quot; target=&quot;_blank&quot;&gt;&#123;&#123; name &#125;&#125;&lt;/a&gt; &lt;a href=&quot;http://creativecommons.org/licenses/&#123;&#123; theme.creative_commons &#125;&#125;/4.0&quot; class=&quot;cc-opacity&quot; target=&quot;_blank&quot;&gt; 首页title的优化更改index.swig文件，文件路径是your-hexo-site\themes\next\layout，将下面代码：&#123;% block title %&#125; &#123;&#123; config.title &#125;&#125; &#123;% endblock %&#125; 改为：&#123;% block title %&#125; &#123;&#123; config.title &#125;&#125; - &#123;&#123; theme.description &#125;&#125; &#123;% endblock %&#125;]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>SEO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Quartz：基本用法总结]]></title>
    <url>%2Fposts%2Ff6df2318%2F</url>
    <content type="text"><![CDATA[OpenSymphony所提供的Quartz是任务调度领域享誉盛名的开源框架。Spring提供了集成Quartz的功能，可以让开发人员以更面向Spring的方式创建基于Quartz的任务调度应用。任务调度本身设计多线程并发、运行时间规则制定及解析、运行现场保持与恢复、线程池维护等诸多方面的工作。如果以自定义线程池的原始方法开发，难点很大。 1.普通JAVA任务启动基本的Quartz任务包含一下流程： 创建任务类：实现Job接口的void execute(JobExecutionContext context)方法，定义被执行任务的执行逻辑； 生成JobDetail对象：通过加载任务类（不是实例）来绑定任务逻辑与任务信息； 生成Trigger对象：定时器的触发时间有两种方式可以定义，分别是CronSchedule和simpleSchedule()。前者使用正则表达式，后者则是简单封装后的定时器。 获取Scheduler对象：通过StdSchedulerFactory工厂方法初始化scheduler对象，把任务和定时器绑定在一起，并启动任务。 完整实例代码import org.quartz.*;import org.quartz.impl.StdSchedulerFactory;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.Date;public class RAMQuartz &#123; private static Logger logger = LoggerFactory.getLogger(RAMQuartz.class); public static void main(String[] args) throws SchedulerException &#123; //创建scheduler SchedulerFactory sf = new StdSchedulerFactory(); Scheduler scheduler = sf.getScheduler(); //定义一个JobDetail //定义Job类为RAMJob类，这是真正的执行逻辑所在 JobDetail jb = JobBuilder.newJob(RAMJob1.class) .withDescription("this is a ram job") .withIdentity("ramJob", "ramGroup")//定义name/group .build(); //通过JobDataMap传递参数 jb.getJobDataMap().put("Test", "This is test parameter value"); long time = System.currentTimeMillis() + 3*1000L; Date startTime = new Date(time); //定义一个Trigger Trigger trigger = TriggerBuilder.newTrigger() .withDescription("") .withIdentity("ramTrigger", "ramTriggerGroup")//定义name/group .startAt(startTime)//加入scheduler后，在指定时间启动 //使用CronTrigger .withSchedule(CronScheduleBuilder.cronSchedule("0/2 * * * * ?")) .build(); //绑定任务和定时器到调度器 scheduler.scheduleJob(jb,trigger); //启动 scheduler.start(); logger.info("启动时间 ： " + new Date()); &#125;&#125; import org.quartz.Job;import org.quartz.JobDataMap;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import java.util.Date;public class RAMJob1 implements Job&#123; private static Logger logger = LoggerFactory.getLogger(RAMJob.class); @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; try &#123; JobDataMap dataMap = jobExecutionContext.getJobDetail().getJobDataMap(); String str = dataMap.getString("Test"); logger.info("Quartz dataMap : " + new Date() + "\n" + str); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.对象注入在Spring的WEB应用中使用定时器，通常都会用到spring的特性——对象注入。前面的代码虽然能够很好地执行简单的定时器任务，但是遇到复杂的执行逻辑（如数据库读写等），就不能应付了。 下面代码可以看出，任务2需要执行myBatis的数据库插入语句： public class RAMJob2 implements Job&#123; @Autowired private TestQuartzMapper testQuartzMapper; private static Logger logger = LoggerFactory.getLogger(RAMJob.class); @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; try &#123; testQuartzMapper.insertSelective(testQuartz); logger.info("Insert MyBatis Success!"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 执行这个业务逻辑，就不得不注入对象。如果仍然延用上面的方法，我们会发现执行的时候，testQuartzMapper的对象为null，结果自然毫无悬念地不断报错。 如何为我们的定时器注入Spring的对象，下面介绍一下思路： 自定义JobFactory工厂方法，扩展AdaptableJobFactory，重写其createJobInstance方法； 声明SchedulerFactoryBean，传入自定义的JobFactory工厂方法； 通过新的SchedulerFactoryBean获取scheduler实例，用注入的方式在需要的地方使用。 完整示例import org.quartz.spi.TriggerFiredBundle;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.config.AutowireCapableBeanFactory;import org.springframework.scheduling.quartz.AdaptableJobFactory;import org.springframework.stereotype.Component;@Componentpublic class MyJobFactory extends AdaptableJobFactory &#123; @Autowired private AutowireCapableBeanFactory capableBeanFactory; @Override protected Object createJobInstance(TriggerFiredBundle bundle) throws Exception &#123; // 调用父类的方法 Object jobInstance = super.createJobInstance(bundle); // 进行注入 capableBeanFactory.autowireBean(jobInstance); return jobInstance; &#125;&#125; @Configurationpublic class QuartzConfig &#123; @Autowired private MyJobFactory myJobFactory; @Bean public SchedulerFactoryBean schedulerFactoryBean() throws IOException &#123; SchedulerFactoryBean factory = new SchedulerFactoryBean(); // 加载quartz数据源配置 factory.setQuartzProperties(quartzProperties()); // 自定义Job Factory，用于Spring注入 factory.setJobFactory(myJobFactory); return factory; &#125; @Bean public Scheduler scheduler() throws IOException, SchedulerException &#123; Scheduler scheduler = schedulerFactoryBean().getScheduler(); scheduler.start(); return scheduler; &#125;&#125; 3.Spring简单任务Spring对Quartz进行了封装，方便开发者调用。下面以Spring Boot为例，介绍一下简单任务在Spring的执行方式。 任务类定义仔细观察可以发现，与普通Java任务的区别在于使用了@Component和@EnableScheduling的注释，相应的，就不用声明implements Job，以及重写execute方法。这是Spring提供的一种便利。 @Component@EnableSchedulingpublic class SpringJob &#123; @Autowired WriteService writeService; private Logger logger = LoggerFactory.getLogger(this.getClass()); public void myJobBusinessMethod() &#123; this.logger.info("MyFirstExerciseJob哇被触发了哈哈哈哈哈"); writeService.writeMSG("张三"); &#125;&#125; 配置JobDetail和Trigger的BeanMethodInvokingJobDetailFactoryBean是Spring提供的JobDetail工厂方法，使用它可以快速地定义JobDetail。然而，缺点是生成的任务无法持久化保存，也就是说，无法管理任务的启动、暂停、恢复、停止等操作。CronTriggerFactoryBean为表达式型触发器。 @Configurationpublic class QuartzJobConfig &#123; /** * 方法调用任务明细工厂Bean */ @Bean(name = "SpringJobBean") public MethodInvokingJobDetailFactoryBean myFirstExerciseJobBean(SpringJob springJob) &#123; MethodInvokingJobDetailFactoryBean jobDetail = new MethodInvokingJobDetailFactoryBean(); jobDetail.setConcurrent(false); // 是否并发 jobDetail.setName("general-springJob"); // 任务的名字 jobDetail.setGroup("general"); // 任务的分组 jobDetail.setTargetObject(springJob); // 被执行的对象 jobDetail.setTargetMethod("myJobBusinessMethod"); // 被执行的方法 return jobDetail; &#125; /** * 表达式触发器工厂Bean */ @Bean(name = "SpringJobTrigger") public CronTriggerFactoryBean myFirstExerciseJobTrigger(@Qualifier("SpringJobBean") MethodInvokingJobDetailFactoryBean springJobBean) &#123; CronTriggerFactoryBean tigger = new CronTriggerFactoryBean(); tigger.setJobDetail(springJobBean.getObject()); tigger.setCronExpression("0/10 * * * * ?"); // 什么是否触发，Spring Scheduler Cron表达式 tigger.setName("general-springJobTrigger"); return tigger; &#125;&#125; 调度器下面将任务和触发器注册到调度器 @Configurationpublic class QuartzConfig &#123; /** * 调度器工厂Bean */ @Bean(name = "schedulerFactory") public SchedulerFactoryBean schedulerFactory(@Qualifier("SpringJobTrigger") Trigger springJobTrigger) &#123; SchedulerFactoryBean bean = new SchedulerFactoryBean(); // 覆盖已存在的任务 bean.setOverwriteExistingJobs(true); // 延时启动定时任务，避免系统未完全启动却开始执行定时任务的情况 bean.setStartupDelay(15); // 注册触发器 bean.setTriggers(SpringJobTrigger); return bean; &#125;&#125; 完成上述配置后，启动spring boot就可以出发定时器任务了。而且，仔细观察上面的代码，在执行过程中有WriteService的spring对象注入，而无需我们自己去自定义JobFactory的Spring对象。 4.持久化任务持久化需要用到数据库，而初始化数据库的SQL可以从下载的发布版的文件中找到，比如，我在官网的Download页下载了当前版本的Full Distribution：Quartz 2.2.3 .tar.gz，解压后在quartz-2.2.3\docs\dbTables能找到初始化脚本，因我用的是MySQL的Innodb引擎，所以我用此脚本tables_mysql_innodb.sql。 配置默认情况下，调度器的详情信息会被存储在内存，模式为：RAMJobStore，而且也不需要填写quartz.properties的配置。然而，如果是持久化的模式，那么quartz.properties就必须填写，因为文件中制定了信息存储模式和数据源信息。 # 线程调度器实例名org.quartz.scheduler.instanceName = quartzScheduler# 线程池的线程数，即最多3个任务同时跑org.quartz.threadPool.threadCount = 3# 如何存储任务和触发器等信息org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX# 驱动代理org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate# 表前缀org.quartz.jobStore.tablePrefix = qrtz_ # 数据源org.quartz.jobStore.dataSource = quartzDataSource# 是否集群org.quartz.jobStore.isClustered = false# 数据源# 驱动org.quartz.dataSource.quartzDataSource.driver = com.mysql.cj.jdbc.Driver# 连接URLorg.quartz.dataSource.quartzDataSource.URL = jdbc:mysql://localhost:3306/quartz?characterEncoding=utf-8&amp;useSSL=true&amp;&amp;serverTimezone=Asia/Shanghai# 用户名org.quartz.dataSource.quartzDataSource.user = root# 密码org.quartz.dataSource.quartzDataSource.password = 123456# 最大连接数org.quartz.dataSource.quartzDataSource.maxConnections = 5 其他内容和RAMJobStore模式相同。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>Quartz</tag>
        <tag>持久化</tag>
        <tag>对象注入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo：NexT主题优化之路]]></title>
    <url>%2Fposts%2Fdc01d1e2%2F</url>
    <content type="text"><![CDATA[选择了Hexo + Next完成个人博客建站之后，仍然会有很多不足之处。此时，万能的搜索引擎和git社区为我们提供了琳琅满目的解决方案。本文将陆续记录本站采用过的优化措施，以供大家参考。 缩小首页文章列表间距并增加阴影效果在5.1.3版本中，可以直接修改next/source/css/_custom/custom.styl文件，如下： // 主页文章添加阴影效果.posts-expand &#123; .post &#123; margin-top: 60px; margin-bottom: 20px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5); &#125;&#125; 增加标签步骤一你需要在hexo根目录的source文件夹下新建一个tags文件夹，然后在tags文件夹里面新建一个index.md文件。快捷命令为： hexo new page "tags" 步骤二编辑source/tags/index.md文件，内容如下： ---title: &quot;tags&quot;type: tagslayout: &quot;tags&quot;comments: false--- title标题不重要，自定义。comments为false，可以关闭本页的评论功能。 步骤三编辑主题配置文件 nav: home: / about: /about tags: /tags 步骤四文章中多个标签的添加方式如下： tags: - tag1 - tag2 或者 tags: [tag1, tag2] 增加分类方法同上，区别是: tags换成categories; 分类只能有一个。 文章中增加categories: xxx。 添加站内搜索安装插件支持站内搜索需要hexo-generator-search和hexo-generator-searchdb两个插件，在站点的根目录下执行以下命令： npm install hexo-generator-search --savenpm install hexo-generator-searchdb --save 启用搜索第一步：在hexo的_config.yml配置文件增加如下内容： search: path: search.xml field: post format: html limit: 10000 第二步：在NexT的_config.yml配置文件修改如下内容： local_search: enable: true 修改Pisces主题内容区宽度默认的宽度觉得有点窄，想改宽一点，可以在source/css/_schemes/Picses/_layout.styl文件末尾添加如下代码: /*扩展宽度*/header&#123; width: 80% !important; &#125;header.post-header &#123; width: auto !important;&#125;.container .main-inner &#123; width: 80%; &#125;.content-wrap &#123; width: calc(100% - 260px); &#125;.header &#123; +tablet() &#123; width: auto !important; &#125; +mobile() &#123; width: auto !important; &#125;&#125;.container .main-inner &#123; +tablet() &#123; width: auto !important; &#125; +mobile() &#123; width: auto !important; &#125;&#125;.content-wrap &#123; +tablet() &#123; width: 100% !important; &#125; +mobile() &#123; width: 100% !important; &#125;&#125; 去掉图片默认的边框将Next主题/themes/next/source/css/_common/components/post/post-expand.styl文件中的img的border的值修改为none //将border的值修改为none即可去掉边框，默认值为 1px solid $gray-lighter img &#123; box-sizing: border-box; margin: auto; padding: 3px; border: none; &#125; 持久化链接优化写的文章复制到微信中链接被分开了，无法直接点击链接访问。看了其他人的博客，大多数是转换为英文的，也没说实现方法。看到一个abbrlink的方法，使用解决了这一问题。 安装abbr-link插件npm install hexo-abbrlink --save 配置博客站点文件permalink: posts/:abbrlink/# abbrlink configabbrlink: alg: crc32 #support crc16(default) and crc32 rep: hex #support dec(default) and hex 部署执行hexo clean和hexo s，使得配置生效]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
        <tag>tags</tag>
        <tag>文章阴影</tag>
        <tag>文章列表间距</tag>
        <tag>搜索，Pisces</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA：文件下载]]></title>
    <url>%2Fposts%2Fc0372a48%2F</url>
    <content type="text"><![CDATA[如何通过Java（模拟浏览器）发送HTTP请求，下载文件是WEB应用经常处理的场景。Java有原生的API可用于发送HTTP请求，即：java.net.URL、java.net.URLConnection。这些API本身已经足够好用，但不够简便。所以，也流行有许多Java HTTP请求的framework，如Apache的HttpClient等。 目前项目主要用到Java原生的方式，所以，这里主要介绍此方式。 1.Get请求和Post请求HTTP请求简单分为GET请求和POST请求（详见：Hypertext Transfer Protocol – HTTP/1.1 - Method Definitions）。 使用Java发送这两种请求的代码大同小异，只是一些参数设置的不同。步骤如下： 通过统一资源定位器（java.net.URL）获取连接器（java.net.URLConnection） 设置请求的参数 发送请求 以输入流的形式获取返回内容 关闭输入流 HttpURLConnection继承自URLConnection，常用它下面几个方法： -setRequestMethod：设置URL请求的方法， 如GET、POST、HEAD、OPTIONS、PUT、DELETE、TRACE。其中，GET方法是默认的，可以不写； -setRequestProperty：设置一般请求属性，如”Accept-Charset”、”Content-Type”、”User-Agent”等； -getResponseCode：从HTTP响应消息获取状态码； -getResponseMessage：获取与来自服务器的响应代码一起返回的HTTP响应消息（如果有）。 2.下载文件文件下载请求，本质上也是一个POST请求，因此，流程大体相同。下面的示例正是按照流程顺序进行了处理。如果项目中有多处地方使用HTTP请求，我们可以适当对其进行封装。 封装文件下载器/** * 从网络Url中下载文件 * @param urlStr * @param fileName * @param savePath * @throws IOException */public static void downLoadFromUrl(String urlStr,String fileName,String savePath) throws IOException&#123; URL url = new URL(urlStr); HttpURLConnection conn = (HttpURLConnection)url.openConnection(); //设置超时间为3秒 conn.setConnectTimeout(3*1000); //防止屏蔽程序抓取而返回403错误 conn.setRequestProperty("User-Agent", "Mozilla/4.0 (compatible; MSIE 5.0; Windows NT; DigExt)"); //得到输入流 InputStream inputStream = conn.getInputStream(); //转储文件 saveToLocal(inputStream, savePath, fileName); System.out.println("info:"+url+" download success");&#125; 执行文件转储/** * 文件转储 * @param in * @param fileName * @param savePath * @throws IOException */public static void saveToLocal(InputStream in, String fileName, String savePath) throws IOException &#123; //获取字节流 byte[] getData = readInputStream(in); //父文件夹位置 File saveDir = new File(savePath); if(!saveDir.exists())&#123; saveDir.mkdir(); &#125; File file = new File(saveDir+File.separator+fileName); FileOutputStream fos = new FileOutputStream(file); fos.write(getData); //关闭输入输出流 if(fos!=null)&#123; fos.close(); &#125; if(in!=null)&#123; in.close(); &#125;&#125; 输入流转字节流/** * 从输入流中获取字节数组 * @param inputStream * @return * @throws IOException */public static byte[] readInputStream(InputStream inputStream) throws IOException &#123; byte[] buffer = new byte[1024]; int len = 0; ByteArrayOutputStream bos = new ByteArrayOutputStream(); while((len = inputStream.read(buffer)) != -1) &#123; bos.write(buffer, 0, len); &#125; bos.close(); return bos.toByteArray();&#125; 参考：如果想学习如何用URLConnection发送Get请求和Post请求，可参考这篇好文：通过java.net.URLConnection发送HTTP请求的方法]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>URLConnection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[足迹：龙门古镇]]></title>
    <url>%2Fposts%2F7fc1a8e1%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[足迹：六和塔]]></title>
    <url>%2Fposts%2F55828a88%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[足迹：九溪十八涧]]></title>
    <url>%2Fposts%2Fcaeb5da5%2F</url>
    <content type="text"><![CDATA[2017-04-03清明假期第二天，天气晴好，阳光明媚。 老婆刚刚确认怀孕，岳母也是大病初愈。一家人也算是一扫16年的阴霾，心情大好地出门去近郊踏青。 从九溪公交车站往里走，人是越来越多，但是风景更是越来越好。初入景区，左边是湍流的溪水，右边是漫山的茶园。耳边响起的是溪涧奔流的叮咚声，鼻子嗅到的是明前龙井的清新，更有游人的欢声笑语和采茶女穿梭山间茶园倩影。眼前的风景，让人不禁赞叹春光无限好。 到达九溪烟树的石碑，是一路美丽风光的顶峰。图一的照片正是九溪风景的名片。我认为秋天才是九溪烟树最美的季节，不同的植被在这个季节会披上不同的颜色，有红的似火的枫叶，有金黄的梧桐，有万年长青的香樟，连溪水的颜色都会不同。恰似倒翻了的颜料盘，在大自然打开了五彩斑斓的画卷。想不到的是春天的景观也不逊色，虽不是暖色调为主，但是嫩绿、翠绿、深绿，层次分明，错落有致的绿色，让我们感受到沁人心脾的清新自然，心旷神怡。 图二是我和丈母娘看到有人在那里拍婚纱照，料定必有美景，便一同前往。碧玉般的湖水和青山，在红绿相间的枝叶半遮半掩之下，绘制出一番犹抱琵琶半遮面的羞涩意境，更惹人喜爱。连累得在九曲桥上休息的老婆和丈人，看了我手机拍下的照片，也想重新启程，亲览美景。 图三则是在返程的路上，路过一步长的小桥拍下的。九溪的美正如这张照片，不经意之间的一瞥，邂逅的可能就是百看不厌的传世画卷。]]></content>
      <categories>
        <category>足迹</category>
      </categories>
      <tags>
        <tag>九溪十八涧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[足迹：湘湖]]></title>
    <url>%2Fposts%2F2500110d%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[足迹：白马湖]]></title>
    <url>%2Fposts%2F58ecbb5a%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[足迹：千岛湖]]></title>
    <url>%2Fposts%2F20a3881c%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[足迹：乌镇]]></title>
    <url>%2Fposts%2F5f961822%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[足迹：迪士尼]]></title>
    <url>%2Fposts%2Fb2af91bf%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>足迹</category>
      </categories>
  </entry>
</search>
